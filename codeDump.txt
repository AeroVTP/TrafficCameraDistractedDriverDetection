

vector <KeyPoint> kMeansKeypoints(vector <KeyPoint> keypoints, int iterations)
{
	cout << " here " << endl;

	Mat labels;
	Mat centers;

	int K=2, flags = KMEANS_RANDOM_CENTERS;

	if(keypoints.size() <=  2)
	{
		K = keypoints.size();
	}
	TermCriteria tc;
	cout << "Size of Keypoints: " << keypoints.size() <<  endl;

	vector <Point> vectPoints;

	for(int v = 0 ; v < keypoints.size(); v++)
	{
		Point point = keypoints[v].pt;
		vectPoints.push_back(point);
	}

	Mat matROI = Mat(vectPoints);

	cout << "matROI.channels()=" << matROI.channels() << endl;
	cout << "DIMS" << matROI.dims << endl;
	cout << "Types" << type2str(matROI.type()) << endl;

	matROI.convertTo(matROI, CV_32F);

	vector <KeyPoint> destination;

	kmeans(matROI,K,labels,tc,iterations,flags, centers);

	Mat img;
	globalFrames[i].copyTo(img);
	img = Scalar::all(0);

	        for(int  v = 0; v < keypoints.size(); v++ )
	        {
	            int clusterIdx = labels.at<int>(v);
	            Point ipt = centers.at<Point2f>(v);
	            circle( img, ipt, 10, Scalar(255,255,0)); //, FILLED, LINE_AA );
	        }

	        displayFrame("KMeans", img);


	cout << "ASDF" << endl;

	return destination;


}

Mat drawBinaryKeypointImage(Mat srcFrame, vector<KeyPoint> keypoints)
{
	Mat destinationFrame;
	Mat viewKeypoints;
	srcFrame.copyTo(destinationFrame);
	srcFrame.copyTo(viewKeypoints);

	for(int v= 0; v < destinationFrame.rows; v++)
		for(int a = 0; a < destinationFrame.cols; a++)
		{
			destinationFrame.at<uchar>(v,a) = 0;
			viewKeypoints.at<uchar>(v,a) = 0;
		}

	drawKeypoints(viewKeypoints, keypoints, viewKeypoints, Scalar::all(-1), DrawMatchesFlags::DEFAULT );

	vector <KeyPoint> kMeansKeypoint  = kMeansKeypoints(keypoints , 30);

	displayFrame("Just Clean View Points", viewKeypoints);

	for(int v = 0; v < keypoints.size(); v++)
	{
		//if(keypoints.at(v).pt.x < destinationFrame.rows &&keypoints.at(v).pt.y < destinationFrame.cols)
			destinationFrame.at<uchar>(keypoints[v].pt) = 255;
	}

	return destinationFrame;
}


Mat surfObjectDetection(vector <KeyPoint>  keypoints, Mat srcFrame)
{
	Mat destinationFrame;
	srcFrame.copyTo(destinationFrame);
	destinationFrame = Mat::zeros(destinationFrame.rows, destinationFrame.cols, CV_8UC1);
	for(int v = 0; v <  keypoints.size(); v++)
	{
		Point2f currentKeyPoint  = keypoints.at(v).pt;
		int xCoordinate = currentKeyPoint.x;
		int yCoordinate = currentKeyPoint.y;

		cout << "(" << xCoordinate << "," << yCoordinate  << ")" << endl;

		cout << v << "v" << endl;
		cout << keypoints.size() << "size" << endl;

		if(xCoordinate < destinationFrame.rows  && yCoordinate < destinationFrame.cols )
		{
		//	for(int a = -5; a < 5; a++)
			int a = 0;
				destinationFrame.at<uchar>(xCoordinate + a, yCoordinate + a) = 254;

			//destinationFrame.at<uchar>(xCoordinate, yCoordinate) = 254;
		}
	}

	return destinationFrame;
}


Mat siftObjectDetection(Mat srcFrame)
{

	 Mat img1 = srcFrame; // globalFrames[i-1]; // mread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
	    Mat img2 = globalFrames[i]; // imread(argv[2], CV_LOAD_IMAGE_GRAYSCALE);

	    // detecting keypoints
	    SiftFeatureDetector detector(400);
	    vector<KeyPoint> keypoints1, keypoints2;
	    detector.detect(img1, keypoints1);
	    detector.detect(img2, keypoints2);
	    Mat tmpDisplaySIFT;

	    drawKeypoints(img1, keypoints1, tmpDisplaySIFT, Scalar::all(-1), DrawMatchesFlags::DEFAULT );

	   //Mat binaryKey = drawBinaryKeypointImage(img1, keypoints1);

	 //  displayFrame("binaryKey", binaryKey);
	    //displayFrame("SIFT", tmpDisplaySIFT);

	    Mat viewKeypoints;
	    globalGrayFrames[i].copyTo(viewKeypoints);

		for(int v= 0; v < viewKeypoints.rows; v++)
			for(int a = 0; a < viewKeypoints.cols; a++)
			{
				viewKeypoints.at<uchar>(v,a) = 0;
			}

		drawKeypoints(viewKeypoints, keypoints1, viewKeypoints, Scalar::all(-1), DrawMatchesFlags::DEFAULT );

		displayFrame("Just Clean View Points", viewKeypoints);

	    cout << " keypoints 1 .size(" << keypoints1.size() << ")" << endl;

	    if(keypoints1.size() != 0)
	    	kMeansKeypoints(keypoints1, 6);

	    

	    return globalFrames[i];
	

}

void haarClassifier()
{
	String face_cascade_name = "assets/cars3.xml"; //haarcascade_frontalface_alt.xml";
   // String eye_cascade_name = "haarcascade_eye_tree_eyeglasses.xml";
    CascadeClassifier face_cascade;
   // CascadeClassifier eyes_cascade;
    face_cascade.load(face_cascade_name);
	//eyes_cascade.load(eye_cascade_name)

	 Mat frame;
	        vector<Rect> faces;
	        vector<Rect> eyes;
	        Mat original;
	        Mat frame_gray;
	        Mat face;
	        Mat processedFace;

	        globalFrames.at(i).copyTo(original);
	      //   blurFrame("gaussian", globalFrames.at(i), 5).copyTo(original);
	            cvtColor(original, frame_gray, CV_BGR2GRAY);
	        equalizeHist(frame_gray, frame_gray);
face_cascade.detectMultiScale(frame_gray, faces,1.1, 1,
                    0 | CASCADE_SCALE_IMAGE, Size(100, 100)/*, Size(130, 130)*/);
cout << faces.size() << " size of faces" << endl;
if (faces.size() > 0)
		for(int v = 0; v < faces.size(); v++)
		{
				if(v == 0)
					cout << "(" << faces[v].x << " , " << faces[v].y << ")";

				int detectWidth = faces[v].width;
				int detectHeight = faces[v].height;



				Point point(faces[v].x + (detectWidth/2) , faces[v].y + (detectHeight / 2));

				circle(original, point, 5, Scalar(0, 255, 0), 1, 8,0);
                rectangle(original, faces[v], Scalar(0, 255, 0), 2, 8, 0);
		}
	displayFrame("Haar Classifier Big ", original);

}


void siftDetector()
{
	Mat input;
	globalFrames.at(i).copyTo(input);
	SiftFeatureDetector detector;
	vector<cv::KeyPoint> keypoints;
	detector.detect(input, keypoints);

	    // Add results to image and save.
	   Mat output;
	  drawKeypoints(input, keypoints, output);
	  displayFrame("sift_result.jpg", output);

}


vector <KeyPoint> surfFeatureDetection(Mat srcFrame)
{
	Mat destinationFrame;

	//setting constant integer minimum Hessian for SURF Recommended between 400-800
   const int minHessian = 500;
   //defining vector to contain all features
   vector <KeyPoint> vectKeyPoints;
   //saving global frame into surfFrame
   srcFrame.copyTo(destinationFrame);

   //running SURF detector
   SurfFeatureDetector detector(minHessian);
   detector.detect(destinationFrame, vectKeyPoints );

   return vectKeyPoints;
}


Mat surfFeatureOverlay(Mat srcFrame)
{
	Mat destinationFrame;

	//setting constant integer minimum Hessian for SURF Recommended between 400-800
   const int minHessian = 500;
   //defining vector to contain all features
   vector <KeyPoint> vectKeyPoints;
   //saving global frame into surfFrame
   srcFrame.copyTo(destinationFrame);

   //running SURF detector
   SurfFeatureDetector detector(minHessian);
   detector.detect(destinationFrame, vectKeyPoints );

   //drawing keypoints
   drawKeypoints(destinationFrame, vectKeyPoints, destinationFrame, Scalar::all(-1), DrawMatchesFlags::DEFAULT );

   return destinationFrame;
}

//method to calculate median of color image
void *calcMedianColorImage(void *threadarg)
{
	//defining data structure to read in info to new thread
	struct thread_data *data;
	data = (struct thread_data *) threadarg;

	//performing deep copy
	globalFrames[i].copyTo(backgroundFrameColorMedian);

	//variables to show percentage complete
	double displayPercentageCounter = 0;
	double activeCounter = 0;

	//calculating number of runs
	for(int j=0;j<backgroundFrameColorMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameColorMedian.cols;a++)
		{
			for (int t = (i - bufferMemory); t < i ; t++)
			{
				displayPercentageCounter++;
			}
		}
	}

	//iterate through pixels
	for(int j=0;j<backgroundFrameMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameMedian.cols;a++)
		{
			//vectors to hold BGR pixel values
			vector <int> pixelHistoryBlue;
			vector <int> pixelHistoryGreen;
			vector <int> pixelHistoryRed;

			//iterating through buffer
			for (int t = (i - bufferMemory); t < i ; t++)
			{
				//save pixel value into 3D vector
				Vec3b bgrPixel = globalFrames[i].at<Vec3b>(j, a);

				//create matrix to save frame to
				Mat currentFrameForMedianBackground;

				//perform deep copy of frame
				globalFrames.at(i-t).copyTo(currentFrameForMedianBackground);

				//save BGR pixel values
				pixelHistoryBlue.push_back((int) backgroundFrameColorMedian.at<cv::Vec3b>(j,a)[0]);
				pixelHistoryGreen.push_back((int) backgroundFrameColorMedian.at<cv::Vec3b>(j,a)[1]);
				pixelHistoryRed.push_back((int) backgroundFrameColorMedian.at<cv::Vec3b>(j,a)[2]);

				//increment progress counter
				activeCounter++;
			}

			//calculate medians and save in image
			backgroundFrameColorMedian.at<Vec3b>(j,a)[0] = calcMedian(pixelHistoryBlue);
			backgroundFrameColorMedian.at<Vec3b>(j,a)[1] = calcMedian(pixelHistoryGreen);
			backgroundFrameColorMedian.at<Vec3b>(j,a)[2] = calcMedian(pixelHistoryRed);

	   }

	   //display completion stats
	   if(debug)
		   cout << ((activeCounter / displayPercentageCounter) * 100) << "% Color Median Image Scanned" << endl;

	}
 
	//signal completion
	medianColorImageCompletion = 1; 
}



//method to handle color frame median
void colorFrameMedian()
{
	//instantiate thread object
	pthread_t medianImageColorThread;

	//instantiating multithread Data object
	struct thread_data threadData;

	//save i data
	threadData.data = i;

	//create thread
	pthread_create(&medianImageColorThread, NULL, calcMedianColorImage, (void *)&threadData);
 	 
	//write to file
	imwrite((currentDateTime() + "medianColorBackgroundImage.jpg"), backgroundFrameMedian);
}

Mat skeletonBlobs(Mat sourceFrame)
{
	if(debug)
				cout << " Entering rCB" << endl;

	threshold(sourceFrame, sourceFrame, 127, 255, THRESH_BINARY);

	Mat skel(sourceFrame.size(), CV_8UC1, Scalar(0));
	Mat temp(sourceFrame.size(), CV_8UC1);
	Mat eroded;

	Mat element = getStructuringElement(MORPH_CROSS, Size(3, 3));
	int counter  = 0;
	bool done;
	do
	{
		cout << " Count Non Zero " << countNonZero(sourceFrame) << endl;
		cout << " counter " << counter << endl;
		counter++;
		erode(sourceFrame, eroded, element);
		dilate(eroded, temp, element); // temp = open(img)
		subtract(sourceFrame, temp, temp);
		bitwise_or(skel, temp, skel);
		eroded.copyTo(sourceFrame);

		done = (countNonZero(sourceFrame) == 0);
	}	while (!done);

	if(debug)
			cout << " Leaving  rCB" << endl;

	return sourceFrame;
}


	//reading in current and previous frames
	//prevFrame = blurFrame("gaussian", globalFrames.at(i-1), 1);
	//imshow("RdF" , globalFrames[i]);
	//currFrame = blurFrame("gaussian", globalFrames.at(i), 1);


	Mat contoursGMMFrame;

					Point offset = Point(1, 1);

					 Mat canny_output;
					  vector<vector<Point> > contours;
						std::vector<cv::Point> convex_hull;

					  vector<Vec4i> hierarchy;
					  int thresh = 100;
					  int max_thresh = 255;
					  /// Detect edges using canny
					  Canny( thresholdFrameOFA, canny_output, thresh, thresh*2, 3 );
					  /// Find contours
					  findContours( canny_output, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0) );
					  /// Draw contours
					 	  Mat drawing = Mat::zeros( canny_output.size(), CV_8UC3 );
					 	  for( int v = 0; v< contours.size(); v++ )
					 	     {
					 		 // cout << "Number of Points " << contours.at(v).size() << endl;
					     	  //Point2f centerPoint = calculateCenterPointContour(contours);

					 	      if(contours.at(v).size() > 50)
					 	      {

					 	    	  for(int x = 0; x <  contours.at(v).size() ; x++)
					 	    	  {

									  vector <int> averagePoint = centerPoint(contours.at(v));

									  //Point p = (averagePoint.at(0), averagePoint.at(1));

									  Point p;
									  p.x = averagePoint.at(0);
									  p.y = averagePoint.at(1);

								//	  cout << " Center Point is (" << averagePoint.at(0) << "," << averagePoint.at(1) << ")" << endl;

				//					  cout << "(" << contours.at(v).at(0) << ", " << contours.at(v).at(1) << ")" << endl;


										  string	asdf =  "(" + to_string(averagePoint.at(0)) + "," + to_string(averagePoint.at(1)) + ")";
								//	putText(drawing, asdf, p, 1,1,Scalar(0,255,0),2);

					 	    	  }
					 	    	  //Scalar color = Scalar( 255, 0, 0 );

					 	    	 // drawContours( drawing, contours, v, color, 2, 8, hierarchy, 0, Point() );
					 	      }
					 	  }
			 	    	  //displayFrame("Contours OFA ", drawing);

//method to generate OFA heat map
void assembleOpticalFlowAnalysisIntensityMat(Mat cflow)
{
	//saving current global frame
	globalGrayFrames[i].copyTo(ofaThreshFrame);


	ofaThreshFrame  = removeShadow(globalGrayFrames[i]);

	//iterating through OFA pixels
	for(int j = 0; j < cflow.rows; j++)
	{
		for (int a = 0 ; a < cflow.cols; a++)
		{
			const Point2f& fxy = flow.at<Point2f>(j, a);

			ofaThreshFrame.at<uchar>(j,a) = sqrt((abs(fxy.x) * abs(fxy.y))) * 100;
			
		}
	}
	displayFrame("RAW FRAME", globalFrames[i]);
	displayFrame("intensityOFA", ofaThreshFrame);
	ofaThreshFrame = blurFrame("gaussian", ofaThreshFrame, 10);

	//ofaThreshFrame = blurFrame("gaussian", ofaThreshFrame, 10);
	ofaThreshFrame = morph(ofaThreshFrame, 1, "erode");
	//ofaThreshFrame = morph(ofaThreshFrame, 1, "blackhat");
	ofaThreshFrame = morph(ofaThreshFrame, 3, "closing");
	displayFrame("intensityOFAGauss", ofaThreshFrame);

	ofaThreshFrame = blobDetector(ofaThreshFrame);
	displayFrame("intensityOFAGaussBlob", ofaThreshFrame);
	const int thresholdValue = 100;
	threshold( ofaThreshFrame, ofaThreshFrame, thresholdValue, 255, 0 );
	displayFrame("intensityOFAGaussBlobThresh", ofaThreshFrame);
}


/*
	for(int v = 1 ; v < contours.size() ; v += 2)
	{
		Point p
		xTotal += contours.at(v-1);
		yTotal += contours.at(v);
	}
*/

//method to save vector to txt file
void saveToTxtFile(vector <double> vectorToPrint)
{
		if (debug)
			cout << " entering save to Txt File " << endl;

		////writing stats to txt file
		//initiating write stream
		ofstream writeToFile;

		//creating filename  ending
		string filenameAppend = "coordinates.txt";

		//string strI = to_string(i);

		//concanating and creating file name string
		string strFilename = /*strI*/ + filename + currentDateTime() + filenameAppend;

		//strFilename =  "coordinatesTestSave.txt";

		//open file stream and begin writing file
		writeToFile.open (strFilename);

		for(int v = 0; v < vectorToPrint.size(); v+=2)
		{
			//write video statistics
			writeToFile << "(" << vectorToPrint.at(v) << " , " << vectorToPrint.at(v+1) << ")" << endl;
		}

		//close file stream
		writeToFile.close();
}


void printVector(vector <double> vectorToPrint, bool save)
{
	if(!save)
	{
		if(debug)
			cout << "Size of Vector is " << vectorToPrint.size() << endl;
		for(int v = 0; v < vectorToPrint.size(); v+=2)
		{
			cout << "(" << vectorToPrint.at(v) << " , " << vectorToPrint.at(v+1) << ")" << endl;
		}
	}

	else
	{
		if(debug)
			cout << "Size of Vector is " << vectorToPrint.size() << endl;
		for(int v = 0; v < vectorToPrint.size(); v+=2)
		{
			cout << "(" << vectorToPrint.at(v) << " , " << vectorToPrint.at(v+1) << ")" << endl;
		}

		saveToTxtFile(vectorToPrint);

	}


}

//method to read coordinates of a blob
vector <double> readCoordinatesBlob(vector <KeyPoint> keypoints)
{
	vector <double> coordinates;
	for(int v = 0; v < keypoints.size(); v+=2)
	{
		coordinates.push_back(keypoints.at(v).pt.x);
		coordinates.push_back(keypoints.at(v).pt.y);
	}

	return coordinates;
}


//default constructors (.7, ( 2.5 * 2.5), (30 * .5), (.05));
//BackgroundSubtractorMOG(int history = 200, int nmixtures = 5, double backgroundRatio = .7, double noiseSigma=30 * .5)¶


/*
Point2f calculateCenterPointContour(vector < vector <Point> contours)
{

	CvMoments* mu;
	cvMoments(contours,  &mu, 0);
	vector<Point2f> mc( contours.size() );
	for( int i = 0; i < contours.size(); i++ )
	{
	    mc[i] = Point2f( mu[i].m10/mu[i].m00 , mu[i].m01/mu[i].m00 );
	}

	return [0.0,0.0];
}
*/


//method to handle binary blob detection
Mat blobDetector(Mat sourceFrame)
{
	if(debug)
		cout << " Entering blob detector" << endl;

	// Set up the detector with  parameters.
	SimpleBlobDetector:: Params params;
	params.filterByArea = true;
	/*
	params.filterByArea = true;
	params.minDistBetweenBlobs = 1.0f;
	params.filterByInertia = false;
	params.filterByConvexity = false;
	params.filterByColor = false;
	params.filterByCircularity = false;
	params.filterByArea = true;
	*/
	params.minArea = 1000.0f;
	//params.maxArea = 1500.0f;

	if(debug)
			cout << " About to run blob detector" << endl;

	SimpleBlobDetector detector(params);

	//detect blobs
	vector <KeyPoint> keypoints;
	vector <double> coordinates;

	//displayFrame("Before Skel",  gmmFrame);
	//gmmFrame  = skeletonBlobs(gmmFrame);
	//displayFrame("After Skel", gmmFrame);

	detector.detect( sourceFrame, keypoints);

	if(debug)
		cout << "Number of KeyPoints Found is :" << keypoints.size() << endl;

	Mat contoursGMMFrame;

	Point offset = Point(1, 1);

	 Mat canny_output;
	  vector<vector<Point> > contours;
		std::vector<cv::Point> convex_hull;

	  vector<Vec4i> hierarchy;
	  int thresh = 100;
	  int max_thresh = 255;
	  /// Detect edges using canny
	  Canny( sourceFrame, canny_output, thresh, thresh*2, 3 );
	  /// Find contours
	  findContours( canny_output, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0) );
	  /// Draw contours
	 	  Mat drawing = Mat::zeros( canny_output.size(), CV_8UC3 );
	 	  for( int v = 0; v< contours.size(); v++ )
	 	     {
	 		  cout << "Number of Points " << contours.at(v).size() << endl;
	     	  //Point2f centerPoint = calculateCenterPointContour(contours);

	 	      if(contours.at(v).size() > 50)
	 	      {

	 	    	  for(int x = 0; x <  contours.at(v).size() ; x++)
	 	    	  {

					  vector <int> averagePoint = centerPoint(contours.at(v));

					  //Point p = (averagePoint.at(0), averagePoint.at(1));

					  Point p;
					  p.x = averagePoint.at(0);
					  p.y = averagePoint.at(1);

					  cout << " Center Point is (" << averagePoint.at(0) << "," << averagePoint.at(1) << ")" << endl;

//					  cout << "(" << contours.at(v).at(0) << ", " << contours.at(v).at(1) << ")" << endl;


						  string	asdf =  "(" + to_string(averagePoint.at(0)) + "," + to_string(averagePoint.at(1)) + ")";
				//	putText(drawing, asdf, p, 1,1,Scalar(0,255,0),2);

	 	    	  }
	 	    	  Scalar color = Scalar( 255, 0, 0 );

	 	    	  drawContours( drawing, contours, v, color, 2, 8, hierarchy, 0, Point() );
	 	    	 // imshow("Contours", drawing);
	 	    	  /*
	 	    	  cv::convexHull(contours, convex_hull, false);

	 	      	cv::Moments mo = cv::moments(convex_hull);
	 	      		 				Point result = cv::Point(mo.m10/mo.m00 , mo.m01/mo.m00);
*/
/*
	 	      		 		  	std::stringstream buffer;
	 	      		 		  		  	buffer <<  result << std::endl;
	 	      		 		  		  	string asdf = buffer.str();*/
	 	      }
	 	  }

	 	  /*
	 	  //imshow("Drawing V1", drawing);
	 	  int max_area = 0;
	 		std::vector<cv::Point> large_contour;


	 	 if (contours.size() != 0)
	 	 {

	 		// find max area contours
	 			for (unsigned int asdf = 0; asdf < contours.size(); ++asdf) {
	 				int area = (int)cv::contourArea(contours[asdf]);
	 				if (area > max_area) {
	 					large_contour = contours[asdf];
	 					max_area = area;
	 				}
	 			}
	 			// simplify large contours
	 				cv::approxPolyDP(cv::Mat(large_contour), large_contour, 5, true);

	 				// convex hull
	 				cv::convexHull(large_contour, convex_hull, false);
	 				if (convex_hull.size() >= 3 ){

	 				// center of gravity
	 				cv::Moments mo = cv::moments(convex_hull);
	 				Point result = cv::Point(mo.m10/mo.m00 , mo.m01/mo.m00);

	  	cout << "Point is" << result << endl;
	  	std::stringstream buffer;
	  		  	buffer <<  result << std::endl;
	  		  	string asdf = buffer.str();
	*/
		//putText(drawing,asdf, result,1,1.5,Scalar(0,255,0),2);
	 	//  imshow("Drawing V2", drawing);
	 				//}
	// 	 }

	//findContours(gmmFrame, contoursGMMFrame, CV_RETR_LIST, CV_CHAIN_APPROX_NONE, offset);
	//drawContours()
	//displayFrame("contoursGMMFrame" , contoursGMMFrame);

	coordinates = readCoordinatesBlob(keypoints);

	printVector(coordinates, true);

	// Draw detected blobs as red circles.
	Mat frameWithBlobs;
	drawKeypoints( sourceFrame, keypoints, frameWithBlobs, Scalar(0,255,0), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );

	if(debug)
			cout << " Exiting blob detector" << endl;

	return sourceFrame;
}

Mat removeShadow(Mat sourceFrame)
{
	if(i > bufferMemory * 2)
	{

		cout << "BrS" << endl;
	cv::Mat frame = sourceFrame; //cv::imread("samples/frame.bmp");
			cv::Mat bg = backgroundFrameMedian; // cv::imread("samples/bg.bmp");
			cv::Mat fg = fgMask; //cv::imread("samples/fg.bmp", CV_LOAD_IMAGE_GRAYSCALE);

		// matrices to store the masks after shadow removal
		cv::Mat chrMask, phyMask, geoMask, srTexMask, lrTexMask;
		cout << "MrS" << endl;


		cout << "FcrS" << endl;

		/*
		// show results
		cv::imshow("frame", frame);

		cv::imshow("bg", bg);
		cv::imshow("fg", fg);

		cv::imshow("srTex", srTexMask);
		cv::imshow("lrTex", lrTexMask);
		*/

		cout << "FdrS" << endl;


		return sourceFrame;
	}
	else
	{
		return sourceFrame;
	}

}

//cout << sqrt((abs(fxy.x) * abs(fxy.y))) * 1000 << endl;
			//if movement is greater than threshold
			/*
			if((sqrt((abs(fxy.x) * abs(fxy.y))) * 10000) > threshold)
			{
				//write to binary image
				thresholdFrameOFA.at<uchar>(j,a) = 255;
			}
			else
			{
				//write to binary image
				thresholdFrameOFA.at<uchar>(j,a) = 0;
			}
			*/

	//thresholdFrame = blobDetector(thresholdFrame);

   // thresholdFrameOFA = morph(thresholdFrameOFA, 1 ,"gradient");
    //thresholdFrameOFA = morph(thresholdFrameOFA, 1 ,"opening");
	//thresholdFrameOFA = morph(thresholdFrameOFA, 1, "erode");

	//thresholdFrameOFA = morph(thresholdFrameOFA, 1, "erode");

	//thresholdFrameOFA = blobDetector(thresholdFrameOFA);
	//thresholdFrameOFA = blurFrame("gaussian", thresholdFrameOFA , 5);


void latentSVMObjectDetection()
{
	LatentSvmDetector lSVM;

}

//Copy (x,y) location of descriptor matches found from KeyPoint data structures into Point2f vectors
static void matches2points(const vector<DMatch>& matches, const vector<KeyPoint>& kpts_train,
                    const vector<KeyPoint>& kpts_query, vector<Point2f>& pts_train, vector<Point2f>& pts_query)
{
  pts_train.clear();
  pts_query.clear();
  pts_train.reserve(matches.size());
  pts_query.reserve(matches.size());
  for (size_t i = 0; i < matches.size(); i++)
  {
    const DMatch& match = matches[i];
    pts_query.push_back(kpts_query[match.queryIdx].pt);
    pts_train.push_back(kpts_train[match.trainIdx].pt);
  }

}

static double match(const vector<KeyPoint>& /*kpts_train*/, const vector<KeyPoint>& /*kpts_query*/, DescriptorMatcher& matcher,
            const Mat& train, const Mat& query, vector<DMatch>& matches)
{

  double t = (double)getTickCount();
  matcher.match(query, train, matches); //Using features2d
  return ((double)getTickCount() - t) / getTickFrequency();
}

void bagOfWordsObjectDetection()
{

	  FastFeatureDetector detector(90);
	  BriefDescriptorExtractor extractor(16); //this is really 32 x 8 matches since they are binary matches packed into bytes

	  vector<KeyPoint> kpts_1, kpts_2;
	  detector.detect(globalGrayFrames.at(i), kpts_1);
	  detector.detect(globalGrayFrames.at(i-1), kpts_2);
	  cout << "kpts size" << kpts_2.size() << endl;
	  drawKeypoints(globalGrayFrames.at(i), kpts_1, globalGrayFrames.at(i), (0,225,0));
	  imshow("ASDF", globalGrayFrames.at(i));
	  waitKey(0);
	  Mat desc_1, desc_2;
	  extractor.compute(globalGrayFrames.at(i), kpts_1, desc_1);
	  extractor.compute(globalGrayFrames.at(i-1), kpts_2, desc_2);


	  BFMatcher matcher_popcount(NORM_HAMMING);
	  vector<DMatch> matches_popcount;
	  vector<Point2f> mpts_1, mpts_2;

	  matches2points(matches_popcount, kpts_1, kpts_2, mpts_1, mpts_2);
	  vector<char> outlier_mask;
	   Mat H = findHomography(mpts_2, mpts_1, RANSAC, 1, outlier_mask);

	   Mat outimg;
	   drawMatches(globalGrayFrames.at(i-1), kpts_2, globalGrayFrames.at(i), kpts_1, matches_popcount, outimg, Scalar::all(-1), Scalar::all(-1), outlier_mask);
	   imshow("matches - popcount - outliers removed", outimg);


	   Mat warped;
	   Mat diff;
	   warpPerspective(globalGrayFrames.at(i-1), warped, H, globalGrayFrames.at(i).size());
	   imshow("warped", warped);
	   absdiff(globalGrayFrames.at(i),warped,diff);
	   imshow("diff", diff);

}



void detectRedObjects()
{
	int iLowH = 0;
	 int iHighH = 179;

	  int iLowS = 0;
	 int iHighS = 255;

	  int iLowV = 200;
	 int iHighV = 255;

	 if(i == bufferMemory)
	 {

	 cvCreateTrackbar("LowH", "Control", &iLowH, 179); //Hue (0 - 179)
	 cvCreateTrackbar("HighH", "Control", &iHighH, 179);

	  cvCreateTrackbar("LowS", "Control", &iLowS, 255); //Saturation (0 - 255)
	 cvCreateTrackbar("HighS", "Control", &iHighS, 255);

	  cvCreateTrackbar("LowV", "Control", &iLowV, 255); //Value (0 - 255)
	 cvCreateTrackbar("HighV", "Control", &iHighV, 255);
	 }

	  Mat imgHSV;

	   cvtColor(globalFrames.at(i), imgHSV, COLOR_BGR2HSV); //Convert the captured frame from BGR to HSV

	  Mat imgThresholded;

	   inRange(imgHSV, Scalar(iLowH, iLowS, iLowV), Scalar(iHighH, iHighS, iHighV), imgThresholded); //Threshold the image

	   erode(imgThresholded, imgThresholded, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );
	    dilate( imgThresholded, imgThresholded, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );

	     //morphological closing (fill small holes in the foreground)
	    dilate( imgThresholded, imgThresholded, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );
	    erode(imgThresholded, imgThresholded, getStructuringElement(MORPH_ELLIPSE, Size(5, 5)) );

	     imshow("Thresholded Image", imgThresholded); //show the thresholded image
	     imshow("asdf Image", globalFrames.at(i)); //show the thresholded image


	     waitKey(0);

}

void hierarchialClustering()
{
	  Mat image = Mat::zeros(globalFrames.at(i).rows, globalFrames.at(i).cols, CV_8UC3);


	    // Set up training data
	    float labels[4] = {1.0, -1.0, -1.0, -1.0};
	    Mat labelsMat(4, 1, CV_32FC1, labels);
	   float trainingData[4][2] = { {501, 10}, {255, 10}, {501, 255}, {10, 501} };
	        Mat trainingDataMat(4, 2, CV_32FC1, trainingData);
	        CvSVMParams params;
	           params.svm_type    = CvSVM::C_SVC;
	           params.kernel_type = CvSVM::LINEAR;
	           params.term_crit   = cvTermCriteria(CV_TERMCRIT_ITER, 100, 1e-6);
	           CvSVM SVM;
	              SVM.train(trainingDataMat, labelsMat, Mat(), Mat(), params);
	              Vec3b green(0,255,0), blue (255,0,0);
	              for (int i = 0; i < image.rows; ++i)
	                     for (int j = 0; j < image.cols; ++j)
	                     {
	                         Mat sampleMat = (Mat_<float>(1,2) << j,i);
	                         float response = SVM.predict(sampleMat);

	                         if (response == 1)
	                             image.at<Vec3b>(i,j)  = green;
	                         else if (response == -1)
	                              image.at<Vec3b>(i,j)  = blue;
	                     }
	              int thickness = -1;
	                  int lineType = 8;
	                  circle( image, Point(501,  10), 5, Scalar(  0,   0,   0), thickness, lineType);
	                  circle( image, Point(255,  10), 5, Scalar(255, 255, 255), thickness, lineType);
	                  circle( image, Point(501, 255), 5, Scalar(255, 255, 255), thickness, lineType);
	                  circle( image, Point( 10, 501), 5, Scalar(255, 255, 255), thickness, lineType);

	                  thickness = 2;
	                   lineType  = 8;
	                   int c     = SVM.get_support_vector_count();

	                   for (int i = 0; i < c; ++i)
	                   {
	                       const float* v = SVM.get_support_vector(i);
	                       circle( image,  Point( (int) v[0], (int) v[1]),   6,  Scalar(128, 128, 128), thickness, lineType);
	                   }


	                   imshow("SVM Simple Example", image); // show it to the user
	

}


void newBackgroundSubtractor()
{
	cout << " entering " << endl;
	std::vector<std::vector<cv::Point> > contours;

	 Mat frame; //current frame
	 globalGrayFrames[i].copyTo(frame);
	 Mat resizeF;
	 Mat fgMaskMOG; //fg mask generated by MOG method
	 Mat blob;
	 Mat back;
	 Ptr< BackgroundSubtractor>asdfpMOG;
	 	 asdfpMOG = new BackgroundSubtractorMOG();

	 Mat element = getStructuringElement(MORPH_RECT, Size(3, 3), Point(1,1) );
	 resizeF = frame;
	 //resize(frame, resizeF, Size(frame.size().width/2, frame.size().height/2) );
	 asdfpMOG->operator()(resizeF, fgMaskMOG);
	 asdfpMOG->getBackgroundImage(back);

	 cout << " we " << endl;
	  cv::erode(fgMaskMOG,fgMaskMOG,cv::Mat());
	  cv::dilate(fgMaskMOG,fgMaskMOG,cv::Mat());
	  cv::findContours(fgMaskMOG,contours,CV_RETR_EXTERNAL,CV_CHAIN_APPROX_NONE);
	        cv::cvtColor(fgMaskMOG,blob,CV_GRAY2RGB);
	        cv::drawContours(blob,contours,-1,cv::Scalar(255,255,255),CV_FILLED,8);
	         int cmin= 500; //min connected contours
	        int cmax= 10000; //max connected contours
	        std::vector<std::vector<cv::Point> >::iterator itc=contours.begin();
cout << " reaced " << endl;
		while (itc!=contours.end()) {
	                    if (itc->size() > cmin || itc->size() < cmax){
	                        std::vector<cv::Point> pts = *itc;
	                        cv::Mat pointsMatrix = cv::Mat(pts);
	                        cv::Scalar color( 0, 255, 0 );
	                        cv::Rect r0= cv::boundingRect(pointsMatrix);
	                        cv::rectangle(resizeF,r0,color,2);
	                        ++itc;
	                    }else{++itc;}
	        }
	        displayFrame("Origin", resizeF);
	        displayFrame("MOG", fgMaskMOG);
	        displayFrame("Blob",blob);
}


//Ptr<BackgroundSubtractorMOG> backgroundSubtractorGMM = Algorithm::create<BackgroundSubtractorMOG>("BackgroundSubtractor.GMG");

/*

	FastFeatureDetector detector(90);
		  BriefDescriptorExtractor extractor(16); //this is really 32 x 8 matches since they are binary matches packed into bytes

		  vector<KeyPoint> kpts_1, kpts_2;
		  detector.detect(globalGrayFrames.at(i), kpts_1);
		  detector.detect(globalGrayFrames.at(i-1), kpts_2);
		  cout << "kpts size" << kpts_2.size() << endl;

		  */

	//	cout << " Ted Cruz" << endl;
		//gmmFrame = morph(gmmFrame, 1, "closing");
			//gmmFrame = morph(gmmFrame, 1000000, "opening");

void backgroundSubtractorV2()
{
	//BackgroundSubtractorMOG asdf = new BackgroundSubtractorMOG(25, 1, 1);
}

	/*
	Mat frame;
	globalGrayFrames[i].copyTo(frame);
	 Mat fgMaskMOG; //fg mask generated by MOG method
	 Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	Ptr<BackgroundSubtractor> pMOG; //MOG Background subtractor
	Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
	Ptr<BackgroundSubtractorMOG> apMOG; //MOG Background subtractor
	Ptr<BackgroundSubtractorMOG2> apMOG2; //MOG2 Background subtractor

	pMOG= new BackgroundSubtractorMOG(200,5,0.7,0); //MOG approach
	    // pMOG= new BackgroundSubtractorMOG(); //MOG approach
	     pMOG2 = new BackgroundSubtractorMOG2(); //MOG2 approach
	 //    pMOG = createBackgroundSubtractorMOG(); //MOG approach
	 //    pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	Mat morphKernel;
	morphKernel = getStructuringElement(CV_SHAPE_RECT, Size(3, 3), Point(1, 1));

	pMOG->operator()(frame, fgMaskMOG, 0);
	pMOG2->operator()(frame, fgMaskMOG2, 0);
	 erode(fgMaskMOG2, fgMaskMOG2, morphKernel);
	 threshold(fgMaskMOG2, fgMaskMOG2, 200, 255, THRESH_BINARY);
	 Scalar suma = sum(fgMaskMOG2);
	 rectangle(fgMaskMOG2, cv::Point(10, 2), cv::Point(100,20),cv::Scalar(255,255,255), -1);

	 displayFrame("frame v1 bcksub", fgMaskMOG2);
//	 dilate(fgMaskMOG, fgMaskMOG, morphKernel, 1);
	//pMOG->operator()(frame, fgMaskMOG);
	// pMOG2->apply(frame, fgMaskMOG2);
	*/


		//gmmFrameRaw = blurFrame("gaussian", gmmFrameRaw , 10);
//cout << "Midwat" << endl;
			//	newBack = asdf.getBackgroundImage();
//imshow("newGMM", newGMM);
		//putText(disp,to_string(i),Point(0,50),1,2.5,Scalar(0,255,0),2);


		//gmmFrameRaw = blurFrame("gaussian" , gmmFrameRaw, 1);
		//globalGrayFrames[i].copyTo(gmmFrameRaw);
		//gmmFrameRaw = blurFrame("gaussian" , gmmFrameRaw, 5);

		//cout << "C N F" << endl;


   if(debug)
    	//cout << "Entering GMM" << endl;

   // backgroundSubtractorV2();
    //newBackgroundSubtractor();

    /*
    //if first run through scan all images
	if(!firstTimeGMMModel)
	{

		//step through all frames
		for(int v = i - bufferMemory; v < i; v++)
		{
			//perform deep copy
			globalFrames.at(v).copyTo(gmmFrameRaw);

			//gmmFrameRaw = blurFrame( "gaussian", gmmFrameRaw, 7);

			//perform GMM
			(*backgroundSubtractorGMM)(gmmFrameRaw, binaryGMMFrame);

			//save into tmp frame
			gmmFrameRaw.copyTo(gmmTempSegmentFrame);

			//add movement mask
			add(gmmFrameRaw, Scalar(100, 100, 0), gmmTempSegmentFrame, binaryGMMFrame);

			cout << " Morph 0 " << endl;

			//perform morphology
			binaryGMMFrame = morph(binaryGMMFrame, 1000000, "closing");
			gmmFrame = morph(gmmFrame, 1000000, "closing");
			gmmFrame = morph(gmmFrame, 1000000, "opening");
			//gmmFrame = morph(gmmFrame, 1000000, "closing");

			cout << " Morph 1 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 1000000, "opening");
			cout << " Morph 2 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 1000000, "closing");
			cout << " Morph 3 " << endl;

			/*
			binaryGMMFrame = morph(binaryGMMFrame, 1000000, "opening");
			cout << " Morph 4 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 1000000, "closing");
			cout << " Morph 5 " << endl;

			binaryGMMFrame = morph(binaryGMMFrame, 1000000, "opening");
			*/
    /*
			cout << " Morph 6 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 100, "gradient");

			//save into display file
			gmmFrame = gmmTempSegmentFrame;

			//display frame
			displayFrame("GMM Frame", gmmFrame);

			gmmFrame = binaryGMMFrame;
			binaryGMMFrame = blobDetector(binaryGMMFrame);


			displayFrame("GMM Binary Frame A Blob", binaryGMMFrame);



			if(v % 1 == 0)
			{
				if(debug)
						    	cout << "Entering GMM Frame " <<  v  << " Remaining: " <<  i - (v + (i - bufferMemory)) << endl;
			}
		}
		welcome(false);
		//firstTimeGMMModel = false;
	}
	*/
	//if run time
	//else

			/*
			Mat contoursGMMFrame;

				Point offset = Point(1, 1);

				 Mat canny_output;
				  vector<vector<Point> > contours;
					std::vector<cv::Point> convex_hull;

				  vector<Vec4i> hierarchy;
				  int thresh = 100;
				  int max_thresh = 255;
				  /// Detect edges using canny
				  Canny( gmmFrame, canny_output, thresh, thresh*2, 3 );
				  /// Find contours
				  findContours( canny_output, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0) );
				  /// Draw contours
				 	  Mat drawing = Mat::zeros( canny_output.size(), CV_8UC3 );
				 	  for( int v = 0; v< contours.size(); v++ )
				 	     {
				 		  //cout << "Number of Points " << contours.at(v).size() << endl;
				     	  //Point2f centerPoint = calculateCenterPointContour(contours);

				 	      if(contours.at(v).size() > 50)
				 	      {

				 	    	  for(int x = 0; x <  contours.at(v).size() ; x++)
				 	    	  {

								  vector <int> averagePoint = centerPoint(contours.at(v));

								  //Point p = (averagePoint.at(0), averagePoint.at(1));

								  Point p;
								  p.x = averagePoint.at(0);
								  p.y = averagePoint.at(1);

								 // cout << " Center Point is (" << averagePoint.at(0) << "," << averagePoint.at(1) << ")" << endl;

			//					  cout << "(" << contours.at(v).at(0) << ", " << contours.at(v).at(1) << ")" << endl;


									  string	asdf =  "(" + to_string(averagePoint.at(0)) + "," + to_string(averagePoint.at(1)) + ")";
							//	putText(drawing, asdf, p, 1,1,Scalar(0,255,0),2);

				 	    	  }
				 	    	  //Scalar color = Scalar( 255, 0, 0 );


				 	    	//  drawContours( drawing, contours, v, color, 2, 8, hierarchy, 0, Point() );

				 	    	  cv::convexHull(contours, convex_hull, false);

				 	      	cv::Moments mo = cv::moments(convex_hull);
				 	      		 				Point result = cv::Point(mo.m10/mo.m00 , mo.m01/mo.m00);


				 	      		 		  	std::stringstream buffer;
				 	      		 		  		  	buffer <<  result << std::endl;
				 	      		 		  		  	string asdf = buffer.str();
				 	      }
				 	  }
					*/
		 	    	  //displayFrame("Contours", drawing);


void num2str(char *str, int length, int num)
{
    for(int i = 0; i < length-1; i++)
    {
        str[length-i-2] = '0'+num%10;
        num /= 10;
    }
    str[length-1] = 0;
}

void cannyContourDetector()
{
	Mat cannyFrame;
		vector<Vec4i> hierarchy;
		typedef vector<vector<Point> > TContours;
		TContours contours;
		//run canny edge detector
		Canny(globalFrames.at(i), cannyFrame, 115, 115);
		findContours(cannyFrame, contours, hierarchy, CV_RETR_CCOMP, CV_CHAIN_APPROX_NONE);
		//return number of contours detected
		//imshow("globalFrames", contours);
		displayFrame("Canny", cannyFrame);

}

void cmtKeypointTrack()
{

		int numLength = 5;
		    char numString[numLength+1];
		    int start = bufferMemory;

		    Point2f initTopLeft(772,538);
		    Point2f initBottomDown(911,656);



    /*
    Point2f initTopLeft(1,2);
    Point2f initBottomDown(3,4);
    */

    CMT cmt;


    	        Mat img;// = cv::imread(filename);
    	        globalFrames.at(i).copyTo(img);
    	        cv::Mat im_gray;
    	        cv::cvtColor(img, im_gray, CV_BGR2GRAY);
    	        globalGrayFrames.at(i).copyTo(im_gray);
    	        if(i == start)
    	        {
    	        	cout << "entered" << endl;
    	        	cmt.initialise(im_gray, initTopLeft, initBottomDown);

    	        }

    	        cmt.processFrame(im_gray);

    	        for(int i = 0; i<cmt.trackedKeypoints.size(); i++)
    	            cv::circle(img, cmt.trackedKeypoints[i].first.pt, 3, cv::Scalar(255,255,255));
    	        cv::line(img, cmt.topLeft, cmt.topRight, cv::Scalar(255,255,255));
    	        cv::line(img, cmt.topRight, cmt.bottomRight, cv::Scalar(255,255,255));
    	        cv::line(img, cmt.bottomRight, cmt.bottomLeft, cv::Scalar(255,255,255));
    	        cv::line(img, cmt.bottomLeft, cmt.topLeft, cv::Scalar(255,255,255));

    	        displayFrame("frame", img);


}


/*
void detect(IplImage *img)
{
  CvSize img_size = cvGetSize(img);
  CvSeq *object = cvHaarDetectObjects(
    img,
    cascade,
    storage,
    1.1, //1.1,//1.5, //-------------------SCALE FACTOR
    1, //2        //------------------MIN NEIGHBOURS
    0, //CV_HAAR_DO_CANNY_PRUNING
    cvSize(0,0),//cvSize( 30,30), // ------MINSIZE
    img_size //cvSize(70,70)//cvSize(640,480)  //---------MAXSIZE
    );

  std::cout << "Total: " << object->total << " cars" << std::endl;
  for(int i = 0 ; i < ( object ? object->total : 0 ) ; i++)
  {
    CvRect *r = (CvRect*)cvGetSeqElem(object, i);
    cvRectangle(img,
      cvPoint(r->x, r->y),
      cvPoint(r->x + r->width, r->y + r->height),
      CV_RGB(255, 0, 0), 2, 8, 0);
  }
  cvShowImage("video", img);

}
*/

void ccvClassifier()
{
	imwrite("tmpImage.png", globalFrames.at(i));
	cout << " START " << endl;
	ccv_dense_matrix_t** image = 0;//new ccv_dense_matrix_t(0);
	 //ccv_scd_classifier_cascade_t* cascade = ccv_scd_classifier_cascade_read("test");
	//ccv_read("tmpImage.png", image, CCV_IO_ANY_FILE);
	//ccv_write(image, "tmpCCVImage.png", 0, CCV_IO_PNG_FILE, 0);
	size_t sizeInBytes = globalFrames.at(i).step[0] * globalFrames.at(i).rows;
	//ccv_read(image, image, CCV_IO_ANY_RAW,  globalFrames.at(i).rows, globalFrames.at(i).cols, sizeInBytes );
	cout << " END " << endl;

}


/*
	CascadeClassifier CascadeClassifiervehicle_classifier = CascadeClassifier('cascade.xml');
	CascadeClassifiervehicle_classifier.detectMultiScale(globalFrames.at(i), 1.1, 2,(100,100));

	CvCapture *capture;
	  IplImage  *frame;
	  int input_resize_percent = 100;

	  cascade = (CvHaarClassifierCascade*) cvLoad("cars3.xml", 0, 0, 0);

storage = cvCreateMemStorage(0);
frame = cvCreateImage(cvSize(globalFrames.at(i).cols, globalFrames.at(i).rows), 8, 3);
IplImage ipltemp = globalFrames.at(i);
cvCopy(&ipltemp, frame);

//frame = cvCloneImage(&(IplImage)globalFrames.at(i));
detect(frame);
*/

	//input.convertTo(output, CV_32F)

	//float data[keypoints.size()][2] = keypoints;

	//Mat points(keypoints.size(),2, CV_32FC1, keypoints);

	/*
	for(int v = 0; v < centers.cols; v++)
	{
		for(int a = 0; a < centers.rows; a++)
		{

			//destination.push_back((KeyPoint)(centers.at<uchar>(v,a)));
		}
	}
	*/


	//displayFrame("points", points);

	//waitKey(0);

	//Mat points  = Mat(keypoints.size(), 2, CV_32F);

	//points = (Mat) keypoints;

	/*
	vector <Point> points2fKeyPoints;


	for(int v = 0; v < keypoints.size(); v++)
	{
		Point point = keypoints[v].pt;
		points2fKeyPoints.push_back(point);
	}
	*/

	//kmeans(points,K,labels,tc,iterations,flags, centers);


	/*
	for( size_t v = 0; i < keypoints.size(); v++ ) {
	  keypoints.push_back(cv::Keypoint(inputs[v], 1.f));
	}
	*/

	//return keypoints;

	/*
	kmeans(points2fKeyPoints,K,labels,tc,iterations,flags, centers);

	for ( int i=0; i<labels.rows; i++ )
	{
	    int idx = labels.at<int>(i);
	    Point2f original_point = keypoints[i].pt;
	    Point2f clustered_center;
	    clustered_center.x = centers.at<float>( idx,0 );
	    clustered_center.y = centers.at<float>( idx,1 );
	    cerr << i << " " << idx << " " << original_point << " " << clustered_center << endl;
	}

	return centers;
	*/
	//return globalFrames[i];

	/*
	//Mat keypoints;
	//Mat centers;

	Mat labels;

	Mat points;
	fitLine(Mat(keypoints), points, CV_DIST_L2, 0.0, 0.01, 0.01);
	Mat centers(6, 1, points.type());

	//Mat point(points, 1, CV_32FC2);

	kmeans(points, 6,  labels, TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 10, 1.0), iterations, KMEANS_RANDOM_CENTERS, centers);

	for(int v= 0 ; v < centers.cols; v++)
	{
		cout << centers.at<uchar>(v, 0) << endl;
	}

	//cout <<< centers << "centers" << endl;
	return keypoints;
	*/


Mat kMeansKeypoints( Mat descriptor, int iterations)
{

	return globalFrames[i];

	/*
	Mat labels;

		Mat points;
		fitLine(descriptor, points, CV_DIST_L2, 0.0, 0.01, 0.01);
		Mat centers(6, 1, points.type());

		//Mat point(points, 1, CV_32FC2);

		kmeans(points, 6,  labels, TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 10, 1.0), iterations, KMEANS_RANDOM_CENTERS, centers);

		return points;
		*/

/*
	//Mat keypoints;
	//Mat centers;

	Mat labels;

	Mat points;
	fitLine(Mat(keypoints), points, CV_DIST_L2, 0.0, 0.01, 0.01);
	Mat centers(6, 1, points.type());

	//Mat point(points, 1, CV_32FC2);

	kmeans(points, 6,  labels, TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 10, 1.0), iterations, KMEANS_RANDOM_CENTERS, centers);

	for(int v= 0 ; v < centers.cols; v++)
	{
		cout << centers.at<uchar>(v, 0) << endl;
	}

	//cout <<< centers << "centers" << endl;
	return keypoints;
*/
}

	    /*
	    // computing descriptors
	    SiftDescriptorExtractor extractor;
	    Mat descriptors1, descriptors2;
	    extractor.compute(img1, keypoints1, descriptors1);
	    extractor.compute(img2, keypoints2, descriptors2);

	    //Mat kMeansKeypointsFrame = kMeansKeypoints(descriptors1, 1);

	    // matching descriptors
	    BFMatcher matcher(NORM_L2);
	    vector<DMatch> matches;
	    matcher.match(descriptors1, descriptors2, matches);

	    // drawing the results
	    namedWindow("matches", 1);
	    Mat img_matches;
	    drawMatches(img1, keypoints1, img2, keypoints2, matches, img_matches);
	    displayFrame("matches", img_matches);


	    return img_matches;
*/

	    /*
	Ptr<Feature2D> f2d = xfeatures2d::SIFT::create();
	std::vector<KeyPoint> keypoints_1, keypoints_2;
  f2d->detect( globalFrames[i], keypoints_1 );
  f2d->detect( globalFrames[i-1], keypoints_2 );

	SIFT siftFeatures = SIFT::SIFT(0 , 3, 0.04, 10, 1.6);

	Mat siftMask;

	vector <KeyPoint> keypoints;
	Mat descriptors;
	SIFT::operator()(globalFrames[i], siftMask, keypoints,descriptors,false);
	*/

	//displayFrame("fgMask" , fgmask);

	/*
	for(double v = 0; v < .1; v+=.01)
	{
		pMOG2->operator()(frameToResize , fgmask, v);

		String dF = "fgMask" + to_string(v);
			displayFrame(dF , fgmask);
	}
	*/

		/*
		Mat fgMaskShadowWindow = slidingWindowNeighborDetector(fgmaskShadow, 160, 320);
		Mat fgMaskShadowWindowNorm = slidingWindowDetector(fgmaskShadow, 40, 80);
		*/


		//displayFrame("SIFT Frame", siftObjectDetection(fgmaskShadow));

		/*
		displayFrame("surfFrame" , surfFeatureOverlay(fgMaskShadowWindow));
		displayFrame("surfFrameNew" , surfFeatureOverlay(fgmaskShadow));

		displayFrame("surfObjectDetection", surfObjectDetection(surfFeatureDetection(fgmaskShadow), fgmaskShadow));


		displayFrame("fgMAskShadowWindow",fgMaskShadowWindow );
		displayFrame("fgMAskShadowWindowNorm",fgMaskShadowWindowNorm);
		*/
/*

		Mat canny;
		Mat cannyFrame;
			vector<Vec4i> hierarchy;
			typedef vector<vector<Point> > TContours;
			TContours contours;
			//run canny edge detector
			//Canny( morph(fgMaskShadowWindow, 1, "gradient") , cannyFrame, 115, 115);
			findContours(cannyFrame, contours, hierarchy, CV_RETR_CCOMP, CV_CHAIN_APPROX_NONE);
			//return number of contours detected
			//imshow("globalFrames", contours);
			cout << "contours " << contours.size() << endl;
			for(int v = 0; v < contours.size(); v++)
			drawContours( cannyFrame, contours, v, (0,255,0), 2, 8, hierarchy, 0, Point() );

			displayFrame("Canny", cannyFrame);
			*/
		/*
		for(double v = 0; v < .1; v+=.01)
			{
			pMOG2Shadow->operator()(frameToResizeShadow , fgmaskShadow, v);

				String dF = "fgMaskShadow" + to_string(v);
					displayFrame(dF , fgmask);
			}
			*/
		//displayFrame("fgMaskShadow" , fgmaskShadow);

		//displayFrame("Morph fgMaskShadow", morph(fgMaskShadowWindow, 1, "gradient"));

	//pMOG2->apply(globalFrames[i], fgmask);

	//bckSubMOG2::operator()(globalFrames[i] , fgmask, .01);


Mat slidingWindowDetector(Mat srcFrame, int numRowSections, int numColumnSections)
{
	if(numRowSections == -1 || numColumnSections == -1)
	{
		numRowSections = srcFrame.rows;
		numColumnSections = srcFrame.cols;
	}
	cout << "Entering sWD" << endl;
	//displayFrame("srcOrgFrame", srcFrame);
	Mat sourceFrame;
	vibeBckFrame.copyTo(sourceFrame);
	srcFrame.copyTo(sourceFrame);

	//displayFrame("srcFrame", sourceFrame);
	/*
	const int numRowSections = 5;
	const int numColumnSections = 20;
	*/

	/*
	const int numRowSections = 72; //720
	const int numColumnSections = 128; //1280
	*/

	//sourceFrame = morph(sourceFrame, 1, "closing");

	double percentage = 0;


	int windowWidth = sourceFrame.rows / numRowSections;
	int windowHeight = sourceFrame.cols / numColumnSections;

	//Mat destinationFrame;// = new Mat();
	//Mat destinationFrame;// = new Mat();
	//globalGrayFrames.at(i).copyTo(destinationFrame);
	//sourceFrame->copyTo(destinationFrame);

	Mat destinationFrame = Mat(sourceFrame.rows, sourceFrame.cols, CV_8UC1);

	/*
	for(int a = 0 ; a< destinationFrame.rows ; a++ )
	{
		for(int y = 0; y < destinationFrame.cols  ; y++)
		{
			//destinationFrame.at<uchar>(a,y)  = 127;
		}
	}
	*/
	cout << "Entering sWD 2" << endl;

	for(int v = 0; v <= sourceFrame.rows - 1; v+= windowWidth)
	{
		for(int j = 0; j <= sourceFrame.cols - 1; j+=windowHeight)
		{
			if(sourceFrame.at<uchar>(v, j) > 127)
			{
				//destinationFrame.at<uchar>(v,j)  = 0; }
			}
			else
			{
				//destinationFrame.at<uchar>(v,j) = 255;
			}
			double totalCounter = 0;
			double detectCounter = 0;
			//destinationFrame.at<uchar>(v,j) = 0;

			for(int x =  v; x < windowWidth  + v; x++)
			{
				for(int k = j; k < windowHeight + j; k++)
				{
					if(sourceFrame.at<uchar>(x,k) > 127)
					{
						detectCounter++;
					}
					totalCounter++;
				}
			}

			if(totalCounter != 0)
				percentage = detectCounter / totalCounter;
			else
				cout << "ERROR 4" << endl;

			if(percentage >  .15)
			{
				for(int x =  v; x < windowWidth  + v; x++)
				{
					for(int k = j; k < windowHeight + j; k++)
					{
						destinationFrame.at<uchar>(x,k) = 255;
					}
				}
				//cout << "Writing" << endl;
				//destinationFrame.at<uchar>(v, j) = 0;
			}

			else
			{
				for(int x =  v; x < windowWidth  + v; x++)
				{
					for(int k = j; k < windowHeight + j; k++)
					{
						destinationFrame.at<uchar>(x,k) = 0;
					}
				}
				//cout << "Writing" << endl;
				//destinationFrame.at<uchar>(v,j) = 0;
			}

		}
	}

	//displayFrame("destinationFrame", destinationFrame);

	/*
	if(i > bufferMemory * 1)
	{
		numRowSections /= 2;
		numColumnSections /= 2;

		if(numRowSections > 2 && numColumnSections  > 2)
		{
			cout << numRowSections << "Num Row" << endl;
			cout << numColumnSections << "Column Row" << endl;


			if(numRowSections % 2 != 0)
				numRowSections++;

			if(numColumnSections % 2 != 0)
				numColumnSections++;

			cout << numRowSections << " Corr Num Row" << endl;
			cout << numColumnSections << "Corr Column Row" << endl;

			 std::this_thread::sleep_for (std::chrono::seconds(1));

			 displayFrame("Morph", morph(morph(destinationFrame, 1, "erode"), 1, "closing"));

			slidingWindowDetector(destinationFrame, numRowSections , numColumnSections);
		}
	}

	*/

	return destinationFrame;

	/*
	for(int x = v - windowWidth / numSections; x < windowWidth/numSections + v; x++)
	{
		for(int k = j - windowHeight/numSections; k < windowHeight/numSections + j; k++)
		{
			totalCounter++;

			//cout << " ENTER " << endl;
			if(sourceFrame.at<uchar>(v, j) > 127)
			{
					//cout << "INSIDE" << endl;
				detectCounter++;
				//destinationFrame.at<uchar>(x,k) = 0;
			}
			else
			{
			//	cout << "OUTSIDE" << endl;

				//destinationFrame.at<uchar>(x,k) = 254;
			}

		}
	}

	*/

	/*
	for(int sourceFrameWidthCounter = windowWidth; sourceFrameWidthCounter < sourceFrame.cols - windowWidth; sourceFrameWidthCounter++)
	{
		for(int sourceFrameHeightCounter = windowHeight; sourceFrameHeightCounter < sourceFrame.rows - windowHeight; sourceFrameHeightCounter++)
		{

			int totalCounter = 0;
			int detectCounter = 0;

			for(int sourceFrameWindowWidthCounter = sourceFrameWidthCounter; sourceFrameWindowWidthCounter < sourceFrameWidthCounter + windowWidth; sourceFrameWindowWidthCounter++)
			{
				for(int sourceFrameWindowHeightCounter = sourceFrameHeightCounter; sourceFrameWindowHeightCounter < sourceFrameHeightCounter + windowHeight; sourceFrameWindowHeightCounter++)
				{
					totalCounter++;

					if(sourceFrameWidthCounter <= sourceFrame.cols && sourceFrameHeightCounter <= sourceFrame.rows)
					{
						if(sourceFrame.at<uchar>(sourceFrameWidthCounter, sourceFrameHeightCounter) == 255)
						{
							detectCounter++;
						}
					}

					else{
						cout << " ERROR 1 " << endl;
					}
				}
			}

			double percentage;
			if(totalCounter != 0)
				percentage = detectCounter / totalCounter;
			else
				cout << "ERROR 4" << endl;

			cout << "The percentage is " << percentage << endl;
			waitKey(0);
			/*
			if(percentage < .5)
			{
				int tmpXCoordinate = windowWidth/2 + sourceFrameWidthCounter;
				int tmpYCoordinate = windowHeight/2 + sourceFrameHeightCounter;

				cout << "WORG: (" << sourceFrame.cols << "," << sourceFrame.rows << ")" << endl;
								cout << "WNEW: (" << tmpXCoordinate << "," << tmpYCoordinate << ")" << endl;
				if(tmpXCoordinate >= destinationFrame.cols || tmpYCoordinate >=  destinationFrame.rows)
				{cout << " ERROR 2 " << endl;}
				else
					destinationFrame.at<uchar>(tmpXCoordinate, tmpYCoordinate)  =  0;
			}

			else
			{
				int tmpXCoordinate = windowWidth/2 + sourceFrameWidthCounter;
				int tmpYCoordinate = windowHeight/2 + sourceFrameHeightCounter;
				cout << "ORG: (" << sourceFrame.cols << "," << sourceFrame.rows << ")" << endl;
				cout << "NEW: (" << tmpXCoordinate << "," << tmpYCoordinate << ")" << endl;
				if(tmpXCoordinate != 723 && tmpYCoordinate !=  240)
				{
					if(tmpXCoordinate >= destinationFrame.cols || tmpYCoordinate >=  destinationFrame.rows)
					{cout << " ERROR 3 " << endl;}
					else
						destinationFrame.at<uchar>(tmpXCoordinate, tmpYCoordinate)  = 254;
				}


				cout << "ASDF" << endl;

			}
			*/
	//return destinationFrame;
}


	/*
	for(int x = v - windowWidth / numSections; x < windowWidth/numSections + v; x++)
	{
		for(int k = j - windowHeight/numSections; k < windowHeight/numSections + j; k++)
		{
			totalCounter++;

			//cout << " ENTER " << endl;
			if(sourceFrame.at<uchar>(v, j) > 127)
			{
					//cout << "INSIDE" << endl;
				detectCounter++;
				//destinationFrame.at<uchar>(x,k) = 0;
			}
			else
			{
			//	cout << "OUTSIDE" << endl;

				//destinationFrame.at<uchar>(x,k) = 254;
			}

		}
	}

	*/

	/*
	for(int sourceFrameWidthCounter = windowWidth; sourceFrameWidthCounter < sourceFrame.cols - windowWidth; sourceFrameWidthCounter++)
	{
		for(int sourceFrameHeightCounter = windowHeight; sourceFrameHeightCounter < sourceFrame.rows - windowHeight; sourceFrameHeightCounter++)
		{

			int totalCounter = 0;
			int detectCounter = 0;

			for(int sourceFrameWindowWidthCounter = sourceFrameWidthCounter; sourceFrameWindowWidthCounter < sourceFrameWidthCounter + windowWidth; sourceFrameWindowWidthCounter++)
			{
				for(int sourceFrameWindowHeightCounter = sourceFrameHeightCounter; sourceFrameWindowHeightCounter < sourceFrameHeightCounter + windowHeight; sourceFrameWindowHeightCounter++)
				{
					totalCounter++;

					if(sourceFrameWidthCounter <= sourceFrame.cols && sourceFrameHeightCounter <= sourceFrame.rows)
					{
						if(sourceFrame.at<uchar>(sourceFrameWidthCounter, sourceFrameHeightCounter) == 255)
						{
							detectCounter++;
						}
					}

					else{
						cout << " ERROR 1 " << endl;
					}
				}
			}

			double percentage;
			if(totalCounter != 0)
				percentage = detectCounter / totalCounter;
			else
				cout << "ERROR 4" << endl;

			cout << "The percentage is " << percentage << endl;
			waitKey(0);
			/*
			if(percentage < .5)
			{
				int tmpXCoordinate = windowWidth/2 + sourceFrameWidthCounter;
				int tmpYCoordinate = windowHeight/2 + sourceFrameHeightCounter;

				cout << "WORG: (" << sourceFrame.cols << "," << sourceFrame.rows << ")" << endl;
								cout << "WNEW: (" << tmpXCoordinate << "," << tmpYCoordinate << ")" << endl;
				if(tmpXCoordinate >= destinationFrame.cols || tmpYCoordinate >=  destinationFrame.rows)
				{cout << " ERROR 2 " << endl;}
				else
					destinationFrame.at<uchar>(tmpXCoordinate, tmpYCoordinate)  =  0;
			}

			else
			{
				int tmpXCoordinate = windowWidth/2 + sourceFrameWidthCounter;
				int tmpYCoordinate = windowHeight/2 + sourceFrameHeightCounter;
				cout << "ORG: (" << sourceFrame.cols << "," << sourceFrame.rows << ")" << endl;
				cout << "NEW: (" << tmpXCoordinate << "," << tmpYCoordinate << ")" << endl;
				if(tmpXCoordinate != 723 && tmpYCoordinate !=  240)
				{
					if(tmpXCoordinate >= destinationFrame.cols || tmpYCoordinate >=  destinationFrame.rows)
					{cout << " ERROR 3 " << endl;}
					else
						destinationFrame.at<uchar>(tmpXCoordinate, tmpYCoordinate)  = 254;
				}


				cout << "ASDF" << endl;

			}
			*/
	//return destinationFrame;

	//displayFrame("destinationFrame", destinationFrame);

	/*
	if(i > bufferMemory * 1)
	{
		numRowSections /= 2;
		numColumnSections /= 2;

		if(numRowSections > 2 && numColumnSections  > 2)
		{
			cout << numRowSections << "Num Row" << endl;
			cout << numColumnSections << "Column Row" << endl;


			if(numRowSections % 2 != 0)
				numRowSections++;

			if(numColumnSections % 2 != 0)
				numColumnSections++;

			cout << numRowSections << " Corr Num Row" << endl;
			cout << numColumnSections << "Corr Column Row" << endl;

			 std::this_thread::sleep_for (std::chrono::seconds(1));

			 displayFrame("Morph", morph(morph(destinationFrame, 1, "erode"), 1, "closing"));

			slidingWindowDetector(destinationFrame, numRowSections , numColumnSections);
		}
	}

	*/

/*
	for(int a = 0 ; a< destinationFrame.rows ; a++ )
	{
		for(int y = 0; y < destinationFrame.cols  ; y++)
		{
			//destinationFrame.at<uchar>(a,y)  = 127;
		}
	}
	*/
//Mat destinationFrame;// = new Mat();
	//Mat destinationFrame;// = new Mat();
	//globalGrayFrames.at(i).copyTo(destinationFrame);
	//sourceFrame->copyTo(destinationFrame);

//displayFrame("srcFrame", sourceFrame);
	/*
	const int numRowSections = 5;
	const int numColumnSections = 20;
	*/

	/*
	const int numRowSections = 72; //720
	const int numColumnSections = 128; //1280
	*/

	//sourceFrame = morph(sourceFrame, 1, "closing");

void bgsBackgroundSubtractionTest()
{
	//WeightedMovingMeanBGS wmmBGS;
	Mat wmmBGSFrame;
	Mat wmmBGSModelFrame;

	//wmmBGS.process(globalFrames[i], wmmBGSFrame, 	wmmBGSModelFrame);
	displayFrame("wmmBGSFrame", wmmBGSFrame);
	displayFrame("wmmBGSModelFrame", wmmBGSModelFrame);


}


void grabCutBS(bool buffer)
{

	const Scalar RED = Scalar(0,0,255);
	const Scalar PINK = Scalar(230,130,255);
	const Scalar BLUE = Scalar(255,0,0);
	const Scalar LIGHTBLUE = Scalar(255,255,160);
	const Scalar GREEN = Scalar(0,255,0);

	Mat grabCutFrame;
	Mat bgdModel;
	Mat fgdModel;

	bgdModel = Mat::zeros(globalFrames[i]. rows,globalFrames[i]. cols, CV_64FC1);
	fgdModel = Mat::zeros(globalFrames[i]. rows,globalFrames[i]. cols, CV_64FC1);

	bgdModel = Mat::zeros(1, 13, CV_64FC1);
	fgdModel = Mat::zeros(1, 13, CV_64FC1);

	int border = 100;
	int border2 = border + border;
	cv::Rect rectangle(border,border,globalFrames[i].cols-border2,globalFrames[i].rows-border2);

	cv::Mat result; // segmentation result (4 possible values)
	    cv::Mat bgModel,fgModel;

	cv::grabCut(globalFrames[i],    // input image
	        result,   // segmentation result
	        rectangle,// rectangle containing foreground
	        bgModel,fgModel, // models
	        1,        // number of iterations
	        cv::GC_INIT_WITH_RECT); // use rectangle

	cv::compare(result,cv::GC_PR_FGD,result,cv::CMP_EQ);
	    // Generate output image
	    cv::Mat foreground(globalFrames[i].size(),CV_8UC3,cv::Scalar(255,255,255));
	    globalFrames[i].copyTo(foreground,result); // bg pixels not copied

	    // draw rectangle on original image
	    cv::rectangle(globalFrames[i], rectangle, cv::Scalar(255,255,255),1);
	    cv::namedWindow("Image");
	    cv::imshow("Image",globalFrames[i]);

	    // display result
	    cv::namedWindow("Segmented Image");
	    cv::imshow("Segmented Image",foreground);

}


/*
static void getBinMask( const Mat& comMask, Mat& binMask )
{
    if( comMask.empty() || comMask.type()!=CV_8UC1 )
        CV_Error( Error::StsBadArg, "comMask is empty or has incorrect type (not CV_8UC1)" );
    if( binMask.empty() || binMask.rows!=comMask.rows || binMask.cols!=comMask.cols )
        binMask.create( comMask.size(), CV_8UC1 );
    binMask = comMask & 1;
}
*/


	/*
	  //MultiLayerBGS* bgs = new MultiLayerBGS;
	  cv::Mat img_input(globalFrames[i]);
	    cv::resize(img_input,img_input,cv::Size(320,240));
	    cv::imshow("input", img_input);
	    Mat img_bkgmodel;
	    cv::Mat img_mask;
	    //bgs->process(img_input, img_mask, img_bkgmodel);

	 IBGS *bgs;

	 Mat img_mask;
	 Mat img_bkgmodel;
	  bgs = new FrameDifferenceBGS;
	  bgs->process(globalFrames.at(i), img_mask, img_bkgmodel);
	  */

	/*
	globalGrayFrames[i].copyTo(bgdModel);
	globalGrayFrames[i].copyTo(fgdModel);
	*/

	/*
	Point topLeft(0 , globalFrames[i]. rows -2);
	Point topRight(globalFrames[i]. cols - 2, 0);

	Rect rectangleAllPoints( topLeft, topRight);

	//grabCut(globalFrames[i], grabCutFrame, rect, bgdModel, fgdModel, 1 );

	grabCut(globalFrames[i], grabCutFrame, rectangleAllPoints, bgdModel, fgdModel,  1, GC_EVAL);
	*/

	/*
	//perform simple image subtraction
	double alpha = 0.5; double beta; double input;

	 Mat src1, src2, dst;
	 src1  = thresholdFrameOFA;
	 src2 = gmmFrame;
	 beta = ( 1.0 - alpha );


	// addWeighted( src1, alpha, src2, beta, 0.0, dst);
*/
	 //namedWindow("GMM FRAME", CV_WINDOW_NORMAL);

	// imshow("GMM FRAME", gmmFrame);
/*
	 //displayFrame( "COMB 1", dst );
	 Mat comb1;

	 dst.copyTo(comb1);
	 Mat comb1Blob;

	 comb1Blob = blobDetector(comb1);

	 displayFrame("Comb 1 Blob", comb1Blob);

	 //imwrite("currentCOMB1.TIFF", dst);


	 //addWeighted( dst, alpha, imgDiff, beta, 0.0, dst);
	 displayFrame( "COMB 2", dst );
*/
	// imwrite("currentCOMB2.TIFF", dst);

//	displayFrame("IMG DIFF", imgDiff);

	if(debug){}
			//cout << "Completed iS" << endl;


/*
	descExtractor->compute(&globalFrames.at(i), &descriptors, &descriptorsMat);


	BOWKMeansTrainer bowKMeansTrainer;
	BOWImgDescriptorExtractor bowEx;
	BOWTrainer::cluster bowTrainer;

	bowTrainer.add();

*/


/*
	vector<KeyPoint> keypoints;
	Mat response_hist;
	Mat img;
	string filepath;
	map<string,Mat> classes_training_data;

	Ptr<FeatureDetector > detector(new SurfFeatureDetector());
	Ptr<DescriptorMatcher > matcher(new BruteForceMatcher<L2<float> >());
	Ptr<DescriptorExtractor > extractor(new OpponentColorDescriptorExtractor(Ptr<DescriptorExtractor>(new SurfDescriptorExtractor())));
	Ptr<BOWImgDescriptorExtractor> bowide(new BOWImgDescriptorExtractor(extractor,matcher));
	bowide->setVocabulary(vocabulary);

	#pragma omp parallel for schedule(dynamic,3)
   img = imread(filepath);
	   detector->detect(img,keypoints);
	   bowide.compute(img, keypoints, response_hist);

	   #pragma omp critical
	   {
	      if(classes_training_data.count(class_) == 0) { //not yet created...
	         classes_training_data[class_].create(0,response_hist.cols,response_hist.type());
	         classes_names.push_back(class_);
	      }
	      classes_training_data[class_].push_back(response_hist);
	   }
	   total_samples++;


	BOWKMeansTrainer bowtrainer(1000); //num clusters
	bowtrainer.add(training_descriptors);
	Mat vocabulary = bowtrainer.cluster();



	SurfFeatureDetector detector(400);
	Mat training_descriptors(1,extractor->descriptorSize(),extractor->descriptorType());
	Ptr extractor(
	   new OpponentColorDescriptorExtractor(
	      Ptr(new SurfDescriptorExtractor())
	   )
	);
*/


/*
#include "package_bgs/FrameDifferenceBGS.h"
#include "package_bgs/StaticFrameDifferenceBGS.h"
#include "package_bgs/WeightedMovingMeanBGS.h"
#include "package_bgs/WeightedMovingVarianceBGS.h"
#include "package_bgs/MixtureOfGaussianV1BGS.h"
#include "package_bgs/MixtureOfGaussianV2BGS.h"
#include "package_bgs/AdaptiveBackgroundLearning.h"
#include "package_bgs/AdaptiveSelectiveBackgroundLearning.h"

#if CV_MAJOR_VERSION >= 2 && CV_MINOR_VERSION >= 4 && CV_SUBMINOR_VERSION >= 3
#include "package_bgs/GMG.h"
#endif

#include "package_bgs/dp/DPAdaptiveMedianBGS.h"
#include "package_bgs/dp/DPGrimsonGMMBGS.h"
#include "package_bgs/dp/DPZivkovicAGMMBGS.h"
#include "package_bgs/dp/DPMeanBGS.h"
#include "package_bgs/dp/DPWrenGABGS.h"
#include "package_bgs/dp/DPPratiMediodBGS.h"
#include "package_bgs/dp/DPEigenbackgroundBGS.h"
#include "package_bgs/dp/DPTextureBGS.h"

#include "package_bgs/tb/T2FGMM_UM.h"
#include "package_bgs/tb/T2FGMM_UV.h"
#include "package_bgs/tb/T2FMRF_UM.h"
#include "package_bgs/tb/T2FMRF_UV.h"
#include "package_bgs/tb/FuzzySugenoIntegral.h"
#include "package_bgs/tb/FuzzyChoquetIntegral.h"

#include "package_bgs/lb/LBSimpleGaussian.h"
#include "package_bgs/lb/LBFuzzyGaussian.h"
#include "package_bgs/lb/LBMixtureOfGaussians.h"
#include "package_bgs/lb/LBAdaptiveSOM.h"
#include "package_bgs/lb/LBFuzzyAdaptiveSOM.h"

#include "package_bgs/ck/LbpMrf.h"
#include "package_bgs/jmo/MultiLayerBGS.h"
// The PBAS algorithm was removed from BGSLibrary because it is
// based on patented algorithm ViBE
// http://www2.ulg.ac.be/telecom/research/vibe/
//#include "package_bgs/pt/PixelBasedAdaptiveSegmenter.h"
#include "package_bgs/av/VuMeter.h"
#include "package_bgs/ae/KDE.h"
#include "package_bgs/db/IndependentMultimodalBGS.h"
#include "package_bgs/sjn/SJN_MultiCueBGS.h"
#include "package_bgs/bl/SigmaDeltaBGS.h"
*/

/*
#include "package_bgs/pl/SuBSENSE.h"
#include "package_bgs/pl/LOBSTER.h"
*/



//======================================================================================================
// Name        : TrafficCameraDistractedDriverDetection.cpp
// Author      : Vidur Prasad
// Version     : 0.2.4
// Copyright   : Institute for the Development and Commercialization of Advanced Sensor Technology Inc.
// Description : Detect Drunk, Distracted, and Anomalous Driving Using Traffic Cameras
//======================================================================================================

//include opencv library files
#include "opencv2/highgui/highgui.hpp"
#include <opencv2/objdetect/objdetect.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/video/tracking.hpp>
#include "opencv2/nonfree/nonfree.hpp"
#include "opencv2/gpu/gpu.hpp"
#include <opencv2/nonfree/ocl.hpp>
#include <opencv/cv.h>
#include <opencv2/video/background_segm.hpp>
#include <opencv2/core/core.hpp>

//include c++ files
#include <iostream>
#include <fstream>
#include <ctime>
#include <time.h>
#include <thread>
#include <chrono>
#include <stdio.h>
#include <stdlib.h>
#include <limits>
#include <math.h>
#include <algorithm>
#include <vector>
#include <pthread.h>
#include <cstdlib>

//namespaces for convenience
using namespace cv;
using namespace std;

////global variables////

//multithreading global variables
vector <Mat> globalFrames;
vector <Mat> globalGrayFrames;

//global frame properties
int FRAME_HEIGHT;
int FRAME_WIDTH;

//global counter
int i = 0;

//global completion variables for multithreading
int medianImageCompletion = 0;
int medianColorImageCompletion = 0;
int opticalFlowThreadCompletion = 0;
int opticalFlowAnalysisObjectDetectionThreadCompletion = 0;
int gaussianMixtureModelCompletion = 0;

//gaussian mixture model 
//Ptr<BackgroundSubtractorMOG> backgroundSubtractorGMM = Algorithm::create<BackgroundSubtractorMOG>("BackgroundSubtractor.GMG");

Ptr<BackgroundSubtractorGMG> backgroundSubtractorGMM = Algorithm::create<BackgroundSubtractorGMG>("BackgroundSubtractor.GMG");

bool firstTimeGMMModel = true;
Mat gmmFrame;

BackgroundSubtractor asdf;// = new BackgroundSubtractor();
		Mat newBack;

		Mat newGMM;

Mat ofaThreshFrame;

//optical flow density
int opticalFlowDensityDisplay = 5;

//Mat objects to hold background frames
Mat backgroundFrameMedian;

//Mat for color background frame
Mat backgroundFrameColorMedian;

//Mat subtracted image
Mat subtractedImage;

//Mat for thresholded binary image
Mat binaryFrame;

//Mat for optical flow
Mat flow;
Mat cflow;
Mat optFlow;

bool objectOFAFirstTime = true;

//Mat to hold temp GMM models
Mat gmmFrameRaw, binaryGMMFrame, gmmTempSegmentFrame;

//Buffer memory size
const int bufferMemory = 10;

//boolean to decide if preprocessed median should be used
bool readMedianImg = false;

//controls all cout statements
bool debug = false;

bool useMedians = true;

//setting constant filename to read form
//const char* filename = "assets/testRecordingSystemTCD3TCheck.mp4";
//const char* filename = "assets/ElginHighWayTCheck.mp4";
//const char* filename = "assets/SCDOTTestFootageTCheck.mov";
const char* filename = "assets/sussexGardensPaddingtonLondonShortElongtedTCheck.mp4";

//defining format of data sent to threads 
struct thread_data{
   //include int for data passing
   int data;
};	

//method to display frame
void displayFrame(string filename, Mat matToDisplay)
{
	//if debug mode enabled display frame
	if(debug){imshow(filename, matToDisplay);}
}

//method to display frame overriding debug
void displayFrame(string filename, Mat matToDisplay, bool override)
{
	//if debug mode enabled display frame
	if(override){imshow(filename, matToDisplay);}
}

//method to draw optical flow, only should be called during demos
static void drawOptFlowMap(const Mat& flow, Mat& cflowmap,
                    double, const Scalar& color)
{
	//iterating through each pixel and drawing vector
    for(int y = 0; y < cflowmap.rows; y += opticalFlowDensityDisplay)
    {
    	for(int x = 0; x < cflowmap.cols; x += opticalFlowDensityDisplay)
        {
            const Point2f& fxy = flow.at<Point2f>(y, x);
            line(cflowmap, Point(x,y), Point(cvRound(x+fxy.x), cvRound(y+fxy.y)),
                 color);
            circle(cflowmap, Point(x,y), 0, color, -1);
        }
   	}

    //display optical flow map
    displayFrame("RFDOFA", cflowmap);
    imshow("RFDOFA" ,cflowmap);

}

vector <double> readCoordinatesBlob(vector <KeyPoint> keypoints)
{
	vector <double> coordinates;
	for(int v = 0; v < keypoints.size(); v+=2)
	{
		coordinates.push_back(keypoints.at(v).pt.x);
		coordinates.push_back(keypoints.at(v).pt.y);
	}

	return coordinates;
}

//method that returns date and time as a string to tag txt files
const string currentDateTime()
{
	//creating time object that reads current time
    time_t now = time(0);

    //creating time structure
    struct tm tstruct;

    //creating a character buffer of 80 characters
    char buf[80];

    //checking current local time
    tstruct = *localtime(&now);

    //writing time to string
    strftime(buf, sizeof(buf), "%Y-%m-%d.%X", &tstruct);

    //returning the string with the time
    return buf;
}

void saveToTxtFile(vector <double> vectorToPrint)
{
		if (debug)
			cout << " entering save to Txt File " << endl;

		////writing stats to txt file
		//initiating write stream
		ofstream writeToFile;

		//creating filename  ending
		string filenameAppend = "coordinates.txt";

		//string strI = to_string(i);

		//concanating and creating file name string
		string strFilename = /*strI*/ + filename + currentDateTime() + filenameAppend;

		//strFilename =  "coordinatesTestSave.txt";

		//open file stream and begin writing file
		writeToFile.open (strFilename);

		for(int v = 0; v < vectorToPrint.size(); v+=2)
		{
			//write video statistics
			writeToFile << "(" << vectorToPrint.at(v) << " , " << vectorToPrint.at(v+1) << ")" << endl;
		}

		//close file stream
		writeToFile.close();
}

void printVector(vector <double> vectorToPrint, bool save)
{
	if(!save)
	{
		if(debug)
			cout << "Size of Vector is " << vectorToPrint.size() << endl;
		for(int v = 0; v < vectorToPrint.size(); v+=2)
		{
			cout << "(" << vectorToPrint.at(v) << " , " << vectorToPrint.at(v+1) << ")" << endl;
		}
	}

	else
	{
		if(debug)
			cout << "Size of Vector is " << vectorToPrint.size() << endl;
		for(int v = 0; v < vectorToPrint.size(); v+=2)
		{
			cout << "(" << vectorToPrint.at(v) << " , " << vectorToPrint.at(v+1) << ")" << endl;
		}

		saveToTxtFile(vectorToPrint);

	}


}

//method to apply morphology
Mat morph(Mat sourceFrame, int amplitude, string type)
{
	//using default values
	int morph_elem = 0;
	int morph_size = 0;

	//constructing manipulation Mat
	Mat element = getStructuringElement( morph_elem, Size( 2*morph_size + 1, 2*morph_size+1 ), Point( morph_size, morph_size ) );

	//if performing morphological closing
	if(type == "closing")
	{
		//repeat for increased effect
	    for(int v = 0; v < amplitude; v++)
		{
			 morphologyEx(sourceFrame, sourceFrame, MORPH_CLOSE, element,
					 Point(-1,-1), 20, BORDER_CONSTANT, morphologyDefaultBorderValue());
		}
	}

	//if performing morphological opening
	else if(type == "opening")
	{
		for(int v = 0; v < amplitude; v++)
		{
			//repeat for increased effect
			morphologyEx(sourceFrame, sourceFrame, MORPH_OPEN, element,
					Point(-1,-1), 20, BORDER_CONSTANT, morphologyDefaultBorderValue());

		}
	}

	//if performing morphological gradient
	else if(type == "gradient")
	{
		//repeat for increased effect
		for(int v = 0; v < amplitude; v++)
		{
			 morphologyEx(sourceFrame, sourceFrame, MORPH_GRADIENT, element,
					 Point(-1,-1), 20, BORDER_CONSTANT, morphologyDefaultBorderValue());
		}
	}

	//if performing morphological tophat
	else if(type == "tophat")
	{
		//repeat for increased effect
		for(int v = 0; v < amplitude; v++)
		{
			 morphologyEx(sourceFrame, sourceFrame, MORPH_TOPHAT, element,
					 Point(-1,-1), 20, BORDER_CONSTANT, morphologyDefaultBorderValue());
		}
	}

	//if performing morphological blackhat
	else if(type == "blackhat")
	{
		//repeat for increased effect
		for(int v = 0; v < amplitude; v++)
		{
		morphologyEx(sourceFrame, sourceFrame, MORPH_BLACKHAT, element,
							 Point(-1,-1), 20, BORDER_CONSTANT, morphologyDefaultBorderValue());
		}
	}

	//if current morph operation is not availble
	else
	{
		//report cannot be done
		if(debug)
			cout << type <<  " type of morphology not implemented yet" << endl;
	}

	//return edited frame
    return sourceFrame;
}

/*
Point2f calculateCenterPointContour(vector < vector <Point> contours)
{

	CvMoments* mu;
	cvMoments(contours,  &mu, 0);
	vector<Point2f> mc( contours.size() );
	for( int i = 0; i < contours.size(); i++ )
	{
	    mc[i] = Point2f( mu[i].m10/mu[i].m00 , mu[i].m01/mu[i].m00 );
	}

	return [0.0,0.0];
}
*/

vector <int> centerPoint(vector <Point> contours)
{
	int xTotal = 0;
	int yTotal = 0;

	vector <int> centerPoint;


	for(int v = 0 ; v < contours.size() ; v++)
	{
		Point p = contours.at(v);

		xTotal += p.x;
			yTotal += p.y;
	}

/*
	for(int v = 1 ; v < contours.size() ; v += 2)
	{
		Point p
		xTotal += contours.at(v-1);
		yTotal += contours.at(v);
	}
*/
	centerPoint.push_back(xTotal / (contours.size()/2));
	centerPoint.push_back(yTotal / (contours.size()/2));

	return centerPoint;
}

//method to handle binary blob detection
Mat blobDetector(Mat sourceFrame)
{
	if(debug)
		cout << " Entering blob detector" << endl;

	// Set up the detector with  parameters.
	SimpleBlobDetector:: Params params;
	params.filterByArea = true;
	/*
	params.filterByArea = true;
	params.minDistBetweenBlobs = 1.0f;
	params.filterByInertia = false;
	params.filterByConvexity = false;
	params.filterByColor = false;
	params.filterByCircularity = false;
	params.filterByArea = true;
	*/
	params.minArea = 50.0f;
	//params.maxArea = 1500.0f;

	sourceFrame =  morph(sourceFrame, 1000000, "closing");

	if(debug)
			cout << " About to run blob detector" << endl;

	SimpleBlobDetector detector(params);

	//detect blobs
	vector <KeyPoint> keypoints;
	vector <double> coordinates;

	//displayFrame("Before Skel",  gmmFrame);
	//gmmFrame  = skeletonBlobs(gmmFrame);
	//displayFrame("After Skel", gmmFrame);

	detector.detect( sourceFrame, keypoints);

	if(debug)
		cout << "Number of KeyPoints Found is :" << keypoints.size() << endl;

	Mat contoursGMMFrame;

	Point offset = Point(1, 1);

	 Mat canny_output;
	  vector<vector<Point> > contours;
		std::vector<cv::Point> convex_hull;

	  vector<Vec4i> hierarchy;
	  int thresh = 100;
	  int max_thresh = 255;
	  /// Detect edges using canny
	  Canny( sourceFrame, canny_output, thresh, thresh*2, 3 );
	  /// Find contours
	  findContours( canny_output, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0) );
	  /// Draw contours
	 	  Mat drawing = Mat::zeros( canny_output.size(), CV_8UC3 );
	 	  for( int v = 0; v< contours.size(); v++ )
	 	     {
	 		  cout << "Number of Points " << contours.at(v).size() << endl;
	     	  //Point2f centerPoint = calculateCenterPointContour(contours);

	 	      if(contours.at(v).size() > 50)
	 	      {

	 	    	  for(int x = 0; x <  contours.at(v).size() ; x++)
	 	    	  {

					  vector <int> averagePoint = centerPoint(contours.at(v));

					  //Point p = (averagePoint.at(0), averagePoint.at(1));

					  Point p;
					  p.x = averagePoint.at(0);
					  p.y = averagePoint.at(1);

					  cout << " Center Point is (" << averagePoint.at(0) << "," << averagePoint.at(1) << ")" << endl;

					  cout << "(" << contours.at(v).at(0) << ", " << contours.at(v).at(1) << ")" << endl;


						  string	asdf =  "(" + to_string(averagePoint.at(0)) + "," + to_string(averagePoint.at(1)) + ")";
					putText(drawing, asdf, p, 1,1,Scalar(0,255,0),2);

	 	    	  }
	 	    	  Scalar color = Scalar( 255, 0, 0 );

	 	    	  drawContours( drawing, contours, v, color, 2, 8, hierarchy, 0, Point() );

	 	    	  /*
	 	    	  cv::convexHull(contours, convex_hull, false);

	 	      	cv::Moments mo = cv::moments(convex_hull);
	 	      		 				Point result = cv::Point(mo.m10/mo.m00 , mo.m01/mo.m00);
*/
/*
	 	      		 		  	std::stringstream buffer;
	 	      		 		  		  	buffer <<  result << std::endl;
	 	      		 		  		  	string asdf = buffer.str();*/
	 	      }
	 	  }

	 	  imshow("Drawing V1", drawing);
	 	  int max_area = 0;
	 		std::vector<cv::Point> large_contour;


	 	 if (contours.size() != 0)
	 	 {

	 		// find max area contours
	 			for (unsigned int asdf = 0; asdf < contours.size(); ++asdf) {
	 				int area = (int)cv::contourArea(contours[asdf]);
	 				if (area > max_area) {
	 					large_contour = contours[asdf];
	 					max_area = area;
	 				}
	 			}
	 			// simplify large contours
	 				cv::approxPolyDP(cv::Mat(large_contour), large_contour, 5, true);

	 				// convex hull
	 				cv::convexHull(large_contour, convex_hull, false);
	 				if (convex_hull.size() >= 3 ){

	 				// center of gravity
	 				cv::Moments mo = cv::moments(convex_hull);
	 				Point result = cv::Point(mo.m10/mo.m00 , mo.m01/mo.m00);

	  	cout << "Point is" << result << endl;
	  	std::stringstream buffer;
	  		  	buffer <<  result << std::endl;
	  		  	string asdf = buffer.str();

		//putText(drawing,asdf, result,1,1.5,Scalar(0,255,0),2);
	 	  imshow("Drawing V2", drawing);
	 				}
	 	 }

	//findContours(gmmFrame, contoursGMMFrame, CV_RETR_LIST, CV_CHAIN_APPROX_NONE, offset);
	//drawContours()
	//displayFrame("contoursGMMFrame" , contoursGMMFrame);

	coordinates = readCoordinatesBlob(keypoints);

	printVector(coordinates, true);

	// Draw detected blobs as red circles.
	Mat frameWithBlobs;
	drawKeypoints( sourceFrame, keypoints, frameWithBlobs, Scalar(0,255,0), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );

	if(debug)
			cout << " Exiting blob detector" << endl;

	return sourceFrame;
}

//method to blur Mat using custom kernel size
Mat blurFrame(string blurType, Mat sourceDiffFrame, int blurSize)
{
	//Mat to hold blurred frame
	Mat blurredFrame;

	//if gaussian blur
	if(blurType == "gaussian")
	{
		//blur frame using custom kernel size
		blur(sourceDiffFrame, blurredFrame, Size (blurSize,blurSize), Point(-1,-1));

		//display blurred frame
		//displayFrame("Gauss Frame", blurredFrame);

		//return blurred frame
		return blurredFrame;
	}

	//if blur type not implemented
	else
	{
		//report not implemented
		if(debug)
			cout << blurType <<  " type of blur not implemented yet" << endl;

		//return original frame
		return sourceDiffFrame;
	}

}

//method to perform OFA threshold on Mat
void *computeOpticalFlowAnalysisObjectDetection(void *threadarg)
{
	//reading in data sent to thread into local variable
	struct opticalFlowThreadData *data;
	data = (struct opticalFlowThreadData *) threadarg;

	//matrix holding temporary frame after threshold
	Mat thresholdFrame;


	//deep copy grayscale frame
	globalGrayFrames.at(i-1).copyTo(thresholdFrame);

	//set threshold
	const double threshold = 1000;

	//iterating through OFA pixels
	for(int j = 0; j < cflow.rows; j++)
	{
		for (int a = 0 ; a < cflow.cols; a++)
		{
			const Point2f& fxy = flow.at<Point2f>(j, a);

			//cout << sqrt((abs(fxy.x) * abs(fxy.y))) * 1000 << endl;
			//if movement is greater than threshold
			if((sqrt((abs(fxy.x) * abs(fxy.y))) * 1000) > threshold)
			{
				//write to binary image
				thresholdFrame.at<uchar>(j,a) = 255;
			}
			else
			{
				//write to binary image
				thresholdFrame.at<uchar>(j,a) = 0;
			}
		}
	}


	//thresholdFrame = blobDetector(thresholdFrame);

	cout << "HERE" << endl;
	thresholdFrame = morph(thresholdFrame, 1000000, "closing");
	thresholdFrame = blobDetector(thresholdFrame);
	thresholdFrame = blurFrame("gaussian", thresholdFrame , 5);
	thresholdFrame = morph(thresholdFrame, 1000000, "closing");
	imshow("OFA OBJ", thresholdFrame);



	displayFrame("OFA OBJ",  thresholdFrame);

	ofaThreshFrame = thresholdFrame;

	//signal thread completion
   	opticalFlowAnalysisObjectDetectionThreadCompletion = 1;
}

//method to handle OFA threshold on Mat thread
void opticalFlowAnalysisObjectDetection(Mat& cflowmap, Mat& flow)
{
	//instantiating multithread object
	pthread_t opticalFlowAnalysisObjectDetectionThread;

	//instantiating multithread Data object
	struct thread_data threadData;

	//saving data to pass
	threadData.data = i;

	//creating optical flow object thread
	pthread_create(&opticalFlowAnalysisObjectDetectionThread, NULL, computeOpticalFlowAnalysisObjectDetection, (void *)&threadData);

	//wait for completion
	while(opticalFlowAnalysisObjectDetectionThreadCompletion == 0) {}

	//reset completion variable
	opticalFlowAnalysisObjectDetectionThreadCompletion = 0;
}

//method to perform optical flow analysis
void *computeOpticalFlowAnalysisThread(void *threadarg)
{
	//reading in data sent to thread into local variable
	struct thread_data *data;
	data = (struct thread_data *) threadarg;
	int temp = data->data;

	//defining local variables for FDOFA
	Mat prevFrame, currFrame;
	Mat gray, prevGray;

	displayFrame("Accurate Frame", globalFrames.at(i));

	cout << "ACCESS FRAME" << endl;
	//reading in current and previous frames
	prevFrame = blurFrame("gaussian", globalFrames.at(i-2), 5);
imshow("PRdF", globalFrames.at(i-1));
	//imshow("RdF" , globalFrames.at(i));
	currFrame = blurFrame("gaussian", globalFrames.at(i-1), 5);
	cout << "DONE ACCESS FRAME" << endl;

	//converting to grayscale
	cvtColor(currFrame, gray,COLOR_BGR2GRAY);
	cvtColor(prevFrame, prevGray, COLOR_BGR2GRAY);

	//calculating optical flow
	calcOpticalFlowFarneback(prevGray, gray, flow, 0.5, 3, 15, 3, 5, 1.2, 0);

	//converting to display format
	cvtColor(prevGray, cflow, COLOR_GRAY2BGR);

	//perform OFA threshold
    opticalFlowAnalysisObjectDetection(flow, cflow);

    //draw optical flow map
	if(!debug)
	{
		//drawing optical flow vectors
		drawOptFlowMap(flow, cflow, 1.5, Scalar(0, 0, 255));
	}

	//signal thread completion
	opticalFlowThreadCompletion = 1;
	
}

//method to handle OFA thread
void opticalFlowFarneback()
{
	cout << "ENTERING OFF" << endl;
	//instantiate thread object
	pthread_t opticalFlowFarneback;

	//instantiating multithread Data object
	struct thread_data threadData;

	//saving data to pass
	threadData.data = i;

	//create OFA thread
	pthread_create(&opticalFlowFarneback, NULL, computeOpticalFlowAnalysisThread, (void *)&threadData);

	//wait till finished
	while(opticalFlowThreadCompletion == 0){}
}

//write initial statistics about the video
void writeInitialStats(int NUMBER_OF_FRAMES, int FRAME_RATE, int FRAME_WIDTH, int FRAME_HEIGHT, const char* filename)
{
	////writing stats to txt file
	//initiating write stream
	ofstream writeToFile;

	//creating filename  ending
	string filenameAppend = "Stats.txt";

	//concanating and creating file name string
	string strFilename = filename + currentDateTime() + filenameAppend;

	//open file stream and begin writing file
	writeToFile.open (strFilename);

	//write video statistics
	writeToFile << "Stats on video >> There are = " << NUMBER_OF_FRAMES << " frames. The frame rate is " << FRAME_RATE
	<< " frames per second. Resolution is " << FRAME_WIDTH << " X " << FRAME_HEIGHT;

	//close file stream
	writeToFile.close();

	if(debug)
	{
		//display video statistics
		cout << "Stats on video >> There are = " << NUMBER_OF_FRAMES << " frames. The frame rate is " << FRAME_RATE
				<< " frames per second. Resolution is " << FRAME_WIDTH << " X " << FRAME_HEIGHT << endl;;
	}
}

//display welcome message and splash screen
void welcome(bool open)
{
	if(open)
	{
		//display welcome images
		imshow("Welcome", imread("assets/TCD3.png"));

	}
	else
	{
		//close welcome image
		destroyWindow("Welcome");
	}
}

//calculate time for each iteration
double calculateFPS(clock_t tStart, clock_t tFinal)
{
	//return frames per second
	return 1/((((float)tFinal-(float)tStart) / CLOCKS_PER_SEC));
}

//method to calculate runtime
void computeRunTime(clock_t t1, clock_t t2, int framesRead)
{
	//subtract from start time
	float diff ((float)t2-(float)t1);

	//calculate frames per second
	double frameRateProcessing = (framesRead / diff) * CLOCKS_PER_SEC;

	//display amount of time for run time
	cout << (diff / CLOCKS_PER_SEC) << " seconds of run time." << endl;

	//display number of frames processed per second
	cout << frameRateProcessing << " frames processed per second." << endl;
	cout << framesRead << " frames read." << endl;
}

//method to calculate median of vector of integers
double calcMedian(vector<int> integers)
{
	//double to store non-int median
	double median;

	//read size of vector
	size_t size = integers.size();

	//sort array
    sort(integers.begin(), integers.end());

    //if even number of elements
	if (size % 2 == 0)
	{
		//median is middle elements averaged
		median = (integers[size / 2 - 1] + integers[size / 2]) / 2;
	}

	//if odd number of elements
	else
	{
		//median is middle element
		median = integers[size / 2];
	}

	//return the median value
	return median;
}

//method to calculate mean of vector of integers
double calcMean(vector <int> integers)
{
	//total of all elements
	int total = 0;

	//step through vector
	for (int v = 0; v < integers.size(); v++)
	{
		//total all values
		total += integers.at(v);
	}

	//return mean value
	return total/integers.size();
}

//method to identify type of Mat based on identifier
string type2str(int type) {

	//string to return type of mat
	string r;

	//stats about frame
	uchar depth = type & CV_MAT_DEPTH_MASK;
	uchar chans = 1 + (type >> CV_CN_SHIFT);

	//switch to determine Mat type
	switch ( depth ) {
		case CV_8U:  r = "8U"; break;
		case CV_8S:  r = "8S"; break;
		case CV_16U: r = "16U"; break;
		case CV_16S: r = "16S"; break;
		case CV_32S: r = "32S"; break;
		case CV_32F: r = "32F"; break;
		case CV_64F: r = "64F"; break;
		default:     r = "User"; break;
    }

	//append formatting
	r += "C";
	r += (chans+'0');

	//return Mat type
	return r;
}

//thread to calculate median of image
void *calcMedianImage(void *threadarg)
{
	//defining data structure to read in info to new thread
	struct thread_data *data;
	data = (struct thread_data *) threadarg;

	//performing deep copy
	globalGrayFrames.at(i).copyTo(backgroundFrameMedian);

	//variables to display completion
	double displayPercentageCounter = 0;
	double activeCounter = 0;

	//calculating number of runs
	for(int j=0;j<backgroundFrameMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameMedian.cols;a++)
		{
			for (int t = (i - bufferMemory); t < i ; t++)
			{
				displayPercentageCounter++;
			}
		}
	}

	//stepping through all pixels
	for(int j=0;j<backgroundFrameMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameMedian.cols;a++)
		{
			//saving all pixel values
			vector <int> pixelHistory;

			//moving through all frames stored in buffer
			for (int t = (i - bufferMemory); t < i ; t++)
			{
				//Mat to store current frame to process
				Mat currentFrameForMedianBackground;

				//copy current frame
				globalGrayFrames.at(i-t).copyTo(currentFrameForMedianBackground);

				//save pixel into pixel history
				pixelHistory.push_back(currentFrameForMedianBackground.at<uchar>(j,a));

				//increment for load calculations
				activeCounter++;
			}

			//calculate median value and store in background image
			backgroundFrameMedian.at<uchar>(j,a) = calcMedian(pixelHistory);
	   }

	   //display percentage completed
	   if(debug)
		   cout << ((activeCounter / displayPercentageCounter) * 100) << "% Median Image Scanned" << endl;

	}

	//signal thread completion
    medianImageCompletion = 1;
}

//calculate max value in frame for debug
int maxMat(Mat sourceFrame)
{
	//variable for current max
	int currMax = INT_MIN;

	//step through pixels
	for(int j=0;j<sourceFrame.rows;j++)
	{
	    for (int a=0;a<sourceFrame.cols;a++)
	    {
	    	//if current value is larger than previous max
	    	if(sourceFrame.at<uchar>(j,a) > currMax)
	    	{
	    		//store current value as new max
	    		currMax = sourceFrame.at<uchar>(j,a);
	    	}
	    }
	}

	//return max value in matrix
	return currMax;
}

//method to threshold standard frame
Mat thresholdFrame(Mat sourceDiffFrame)
{
	//Mat to hold frame
	Mat thresholdFrame;

	//perform deep copy into destination Mat
	sourceDiffFrame.copyTo(thresholdFrame);

	//threshold value
	const int threshold = 25;

	//steping through pixels
	for(int j=0;j<sourceDiffFrame.rows;j++)
	{
	    for (int a=0;a<sourceDiffFrame.cols;a++)
	    {
	    	//if pixel value greater than threshold
	    	if(sourceDiffFrame.at<uchar>(j,a) > threshold)
	    	{
	    		//write to binary image
	    		thresholdFrame.at<uchar>(j,a) = 0;
	    	}
	    	else
	    	{
	    		//write to binary image
	    		thresholdFrame.at<uchar>(j,a) = 255;
	    	}
	    }
	}

	//perform morphology
	thresholdFrame = morph(thresholdFrame, 10000000, "closing");

	//display frame
	//displayFrame("SBckSub Bin Frame", thresholdFrame);

	//return thresholded frame
	return thresholdFrame;
}

//method to perform simple image subtraction
Mat imageSubtraction()
{
	//subtract, perform blur, threshold, apply morphology, and return
	return thresholdFrame((blurFrame("gaussian", (globalGrayFrames.at(i) - backgroundFrameMedian), 5)));
}

//method to perform median on grayscale images
void grayScaleFrameMedian()
{
	if(debug)
		cout << "Enterd gray sale median" << endl;
	//instantiating multithread object
	pthread_t medianImageThread;

	//instantiating multithread Data object
	struct thread_data threadData;

	//saving data into multithread
	threadData.data = i;

	//creating thread to calculate median of image
	pthread_create(&medianImageThread, NULL, calcMedianImage, (void *)&threadData);

	//wait for completion
	while(medianImageCompletion != 1){}

	//reset completion variable
	medianImageCompletion = 0;

	//display grayscale median
	//displayFrame("GrayScale Median Background Image", backgroundFrameMedian);

	//save median image
	imwrite((currentDateTime() + "medianBackgroundImage.jpg"), backgroundFrameMedian);
}

//method to calculate median of color image
void *calcMedianColorImage(void *threadarg)
{
	//defining data structure to read in info to new thread
	struct thread_data *data;
	data = (struct thread_data *) threadarg;

	//performing deep copy
	globalFrames[i].copyTo(backgroundFrameColorMedian);

	//variables to show percentage complete
	double displayPercentageCounter = 0;
	double activeCounter = 0;

	//calculating number of runs
	for(int j=0;j<backgroundFrameColorMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameColorMedian.cols;a++)
		{
			for (int t = (i - bufferMemory); t < i ; t++)
			{
				displayPercentageCounter++;
			}
		}
	}

	//iterate through pixels
	for(int j=0;j<backgroundFrameMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameMedian.cols;a++)
		{
			//vectors to hold BGR pixel values
			vector <int> pixelHistoryBlue;
			vector <int> pixelHistoryGreen;
			vector <int> pixelHistoryRed;

			//iterating through buffer
			for (int t = (i - bufferMemory); t < i ; t++)
			{
				//save pixel value into 3D vector
				Vec3b bgrPixel = globalFrames.at(i).at<Vec3b>(j, a);

				//create matrix to save frame to
				Mat currentFrameForMedianBackground;

				//perform deep copy of frame
				globalFrames.at(i-t).copyTo(currentFrameForMedianBackground);

				//save BGR pixel values
				pixelHistoryBlue.push_back((int) backgroundFrameColorMedian.at<cv::Vec3b>(j,a)[0]);
				pixelHistoryGreen.push_back((int) backgroundFrameColorMedian.at<cv::Vec3b>(j,a)[1]);
				pixelHistoryRed.push_back((int) backgroundFrameColorMedian.at<cv::Vec3b>(j,a)[2]);

				//increment progress counter
				activeCounter++;
			}

			//calculate medians and save in image
			backgroundFrameColorMedian.at<Vec3b>(j,a)[0] = calcMedian(pixelHistoryBlue);
			backgroundFrameColorMedian.at<Vec3b>(j,a)[1] = calcMedian(pixelHistoryGreen);
			backgroundFrameColorMedian.at<Vec3b>(j,a)[2] = calcMedian(pixelHistoryRed);

	   }

	   //display completion stats
	   if(debug)
		   cout << ((activeCounter / displayPercentageCounter) * 100) << "% Color Median Image Scanned" << endl;

	}

	//display color median
	//displayFrame("Background Frame Color Median", backgroundFrameColorMedian);

	//signal completion
	medianColorImageCompletion = 1;
}

void newBackgroundSubtractor()
{
	cout << " entering " << endl;
	std::vector<std::vector<cv::Point> > contours;

	 Mat frame; //current frame
	 globalGrayFrames.at(i).copyTo(frame);
	 Mat resizeF;
	 Mat fgMaskMOG; //fg mask generated by MOG method
	 Mat blob;
	 Mat back;
	 Ptr< BackgroundSubtractor>asdfpMOG;
	 	 asdfpMOG = new BackgroundSubtractorMOG();

	 Mat element = getStructuringElement(MORPH_RECT, Size(3, 3), Point(1,1) );
	 resizeF = frame;
	 //resize(frame, resizeF, Size(frame.size().width/2, frame.size().height/2) );
	 asdfpMOG->operator()(resizeF, fgMaskMOG);
	 asdfpMOG->getBackgroundImage(back);

	 cout << " we " << endl;
	  cv::erode(fgMaskMOG,fgMaskMOG,cv::Mat());
	  cv::dilate(fgMaskMOG,fgMaskMOG,cv::Mat());
	  cv::findContours(fgMaskMOG,contours,CV_RETR_EXTERNAL,CV_CHAIN_APPROX_NONE);
	        cv::cvtColor(fgMaskMOG,blob,CV_GRAY2RGB);
	        cv::drawContours(blob,contours,-1,cv::Scalar(255,255,255),CV_FILLED,8);
	         int cmin= 500; //min connected contours
	        int cmax= 10000; //max connected contours
	        std::vector<std::vector<cv::Point> >::iterator itc=contours.begin();
cout << " reaced " << endl;
		while (itc!=contours.end()) {
	                    if (itc->size() > cmin || itc->size() < cmax){
	                        std::vector<cv::Point> pts = *itc;
	                        cv::Mat pointsMatrix = cv::Mat(pts);
	                        cv::Scalar color( 0, 255, 0 );
	                        cv::Rect r0= cv::boundingRect(pointsMatrix);
	                        cv::rectangle(resizeF,r0,color,2);
	                        ++itc;
	                    }else{++itc;}
	        }
	        displayFrame("Origin", resizeF);
	        displayFrame("MOG", fgMaskMOG);
	        displayFrame("Blob",blob);
	/*
	Mat frame;
	globalGrayFrames.at(i).copyTo(frame);
	 Mat fgMaskMOG; //fg mask generated by MOG method
	 Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	Ptr<BackgroundSubtractor> pMOG; //MOG Background subtractor
	Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
	Ptr<BackgroundSubtractorMOG> apMOG; //MOG Background subtractor
	Ptr<BackgroundSubtractorMOG2> apMOG2; //MOG2 Background subtractor

	pMOG= new BackgroundSubtractorMOG(200,5,0.7,0); //MOG approach
	    // pMOG= new BackgroundSubtractorMOG(); //MOG approach
	     pMOG2 = new BackgroundSubtractorMOG2(); //MOG2 approach
	 //    pMOG = createBackgroundSubtractorMOG(); //MOG approach
	 //    pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	Mat morphKernel;
	morphKernel = getStructuringElement(CV_SHAPE_RECT, Size(3, 3), Point(1, 1));

	pMOG->operator()(frame, fgMaskMOG, 0);
	pMOG2->operator()(frame, fgMaskMOG2, 0);
	 erode(fgMaskMOG2, fgMaskMOG2, morphKernel);
	 threshold(fgMaskMOG2, fgMaskMOG2, 200, 255, THRESH_BINARY);
	 Scalar suma = sum(fgMaskMOG2);
	 rectangle(fgMaskMOG2, cv::Point(10, 2), cv::Point(100,20),cv::Scalar(255,255,255), -1);

	 displayFrame("frame v1 bcksub", fgMaskMOG2);
//	 dilate(fgMaskMOG, fgMaskMOG, morphKernel, 1);
	//pMOG->operator()(frame, fgMaskMOG);
	// pMOG2->apply(frame, fgMaskMOG2);
	*/
}

void backgroundSubtractorV2()
{
	//BackgroundSubtractorMOG asdf = new BackgroundSubtractorMOG(25, 1, 1);
}

//method to calculate Gaussian image difference
void *calcGaussianMixtureModel(void *threadarg)
{


   if(debug)
    	cout << "Entering GMM" << endl;

   // backgroundSubtractorV2();
    //newBackgroundSubtractor();

    /*
    //if first run through scan all images
	if(!firstTimeGMMModel)
	{

		//step through all frames
		for(int v = i - bufferMemory; v < i; v++)
		{
			//perform deep copy
			globalFrames.at(v).copyTo(gmmFrameRaw);

			//gmmFrameRaw = blurFrame( "gaussian", gmmFrameRaw, 7);

			//perform GMM
			(*backgroundSubtractorGMM)(gmmFrameRaw, binaryGMMFrame);

			//save into tmp frame
			gmmFrameRaw.copyTo(gmmTempSegmentFrame);

			//add movement mask
			add(gmmFrameRaw, Scalar(100, 100, 0), gmmTempSegmentFrame, binaryGMMFrame);

			cout << " Morph 0 " << endl;

			//perform morphology
			binaryGMMFrame = morph(binaryGMMFrame, 1000000, "closing");
			gmmFrame = morph(gmmFrame, 1000000, "closing");
			gmmFrame = morph(gmmFrame, 1000000, "opening");
			//gmmFrame = morph(gmmFrame, 1000000, "closing");

			cout << " Morph 1 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 1000000, "opening");
			cout << " Morph 2 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 1000000, "closing");
			cout << " Morph 3 " << endl;

			/*
			binaryGMMFrame = morph(binaryGMMFrame, 1000000, "opening");
			cout << " Morph 4 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 1000000, "closing");
			cout << " Morph 5 " << endl;

			binaryGMMFrame = morph(binaryGMMFrame, 1000000, "opening");
			*/
    /*
			cout << " Morph 6 " << endl;

			//binaryGMMFrame = morph(binaryGMMFrame, 100, "gradient");

			//save into display file
			gmmFrame = gmmTempSegmentFrame;

			//display frame
			displayFrame("GMM Frame", gmmFrame);

			gmmFrame = binaryGMMFrame;
			binaryGMMFrame = blobDetector(binaryGMMFrame);


			displayFrame("GMM Binary Frame A Blob", binaryGMMFrame);



			if(v % 1 == 0)
			{
				if(debug)
						    	cout << "Entering GMM Frame " <<  v  << " Remaining: " <<  i - (v + (i - bufferMemory)) << endl;
			}
		}
		welcome(false);
		//firstTimeGMMModel = false;
	}
	*/
	//if run time
	//else
    	if(i > 200)
    	{
    		welcome(false);
    	}

	{
		//perform deep copy
		globalFrames.at(i).copyTo(gmmFrameRaw);



		asdf.operator()(gmmFrameRaw, newGMM, 0);
	//	newBack = asdf.getBackgroundImage();
//imshow("newGMM", newGMM);
		Mat disp;
		globalFrames.at(i).copyTo(disp);
		putText(disp,to_string(i),Point(0,50),1,2.5,Scalar(0,255,0),2);

		imshow("raw frame", disp);
		gmmFrameRaw = blurFrame("gaussian" , gmmFrameRaw, 10);

		//update model
		(*backgroundSubtractorGMM)(gmmFrameRaw, binaryGMMFrame);

		//save into tmp frame
		gmmFrameRaw.copyTo(gmmTempSegmentFrame);

		//add movement mask
		add(gmmFrameRaw, Scalar(0, 255, 0), gmmTempSegmentFrame, binaryGMMFrame);

		binaryGMMFrame = morph(binaryGMMFrame, 10000000, "opening");
			gmmFrame = morph(gmmFrame, 10000000, "opening");
			//gmmFrame = morph(gmmFrame, 1000000, "opening");

//save into display file
			gmmFrame = gmmTempSegmentFrame;

			//display frame
			displayFrame("GMM Frame", gmmFrame);

			imshow("GMM FRAME" , gmmFrame);

			gmmFrame = binaryGMMFrame;
			binaryGMMFrame = blobDetector(binaryGMMFrame);
			imshow("BiGMM FRAME", binaryGMMFrame);

			displayFrame("GMM Binary Frame", binaryGMMFrame);
	}

	//signal thread completion
	gaussianMixtureModelCompletion = 1;
}

Mat skeletonBlobs(Mat sourceFrame)
{
	if(debug)
				cout << " Entering rCB" << endl;

	threshold(sourceFrame, sourceFrame, 127, 255, THRESH_BINARY);

	Mat skel(sourceFrame.size(), CV_8UC1, Scalar(0));
	Mat temp(sourceFrame.size(), CV_8UC1);
	Mat eroded;

	Mat element = getStructuringElement(MORPH_CROSS, Size(3, 3));
	int counter  = 0;
	bool done;
	do
	{
		cout << " Count Non Zero " << countNonZero(sourceFrame) << endl;
		cout << " counter " << counter << endl;
		counter++;
		erode(sourceFrame, eroded, element);
		dilate(eroded, temp, element); // temp = open(img)
		subtract(sourceFrame, temp, temp);
		bitwise_or(skel, temp, skel);
		eroded.copyTo(sourceFrame);

		done = (countNonZero(sourceFrame) == 0);
	}	while (!done);

	if(debug)
			cout << " Leaving  rCB" << endl;

	return sourceFrame;
}

//method to handle GMM thread
void gaussianMixtureModel()
{

	if(debug)
	{
		cout << "EnGMM" << endl;
	}
	//instantiate thread object
	pthread_t gaussianMixtureModelThread;

	//instantiating multithread Data object
	struct thread_data threadData;

	//save i data
	threadData.data = i;

	//create thread
	pthread_create(&gaussianMixtureModelThread, NULL, calcGaussianMixtureModel, (void *)&threadData);

	//wait for finish
	while(gaussianMixtureModelCompletion != 1){}

	if(debug)
	{
		cout << "FiGMM" << endl;
	}

	//reset completion variable
	gaussianMixtureModelCompletion = 0;

	//flag first time run complete
	//firstTimeGMMModel = false;
}

//method to handle color frame median
void colorFrameMedian()
{
	//instantiate thread object
	pthread_t medianImageColorThread;

	//instantiating multithread Data object
	struct thread_data threadData;

	//save i data
	threadData.data = i;

	//create thread
	pthread_create(&medianImageColorThread, NULL, calcMedianColorImage, (void *)&threadData);

	//wait for finish
	while(medianColorImageCompletion != 1)	{}

	//reset completion variable
	medianColorImageCompletion = 0;
	
	//display colormedian image
	displayFrame("Median Color Background Image", backgroundFrameColorMedian);

	//write to file
	imwrite((currentDateTime() + "medianColorBackgroundImage.jpg"), backgroundFrameMedian);
}

//method to handle all background image generation
void generateBackgroundImage(int FRAME_RATE)
{
	//if post-processing
	if(readMedianImg || !useMedians)
	{
		backgroundFrameMedian = imread("/Users/Vidur/OneDrive/EX/Internships/ID\ CAST/Traffic\ Camera\ Distracted\ Driver\
				Detection/C\ Workspace/Traffic\ Camera\ Distracted\ Driver\ Detection/2015-06-24.12\:29\:43medianBackgroundImage.jpg");
	}

	//if real-time calculation
	else
	{
		//after initial buffer read
		if(i == bufferMemory)
		{
			//performing initialGMM
			gaussianMixtureModel();

			//calculating medians
			if(useMedians)
			{
				//colorFrameMedian();
				grayScaleFrameMedian();

			}
		}
		//every minute
		if (i % (FRAME_RATE * 60) == 0 && i > 0)
		{
			//calculate new medians
			//colorFrameMedian();
			grayScaleFrameMedian();
		}
	}
}

//method to handle all image processing object detection
void objectDetection(int FRAME_RATE)
{
	if(debug)
		cout << "entering object detection" << endl;

	//updating gaussian model
	gaussianMixtureModel();

	//if(i % 100 == 0) { grayScaleFrameMedian(); }


	if(debug)
			cout << "Completed GMM" << endl;

	//gmmFrame = blobDetector(gmmFrame);

	if(debug)
			cout << "Completed bD" << endl;

	//create background image
	//generateBackgroundImage(FRAME_RATE);


	if(debug)
			cout << "Completed gBI" << endl;

	//perform OFA for motion object detection
	opticalFlowFarneback();

	if(debug)
			cout << "Completed OFA" << endl;

	//perform simple image subtraction
	//Mat imgDiff = imageSubtraction();
	double alpha = 0.5; double beta; double input;

	 Mat src1, src2, dst;
	 src1  = gmmFrame;
	 src2 = ofaThreshFrame;
	 beta = ( 1.0 - alpha );

	// addWeighted( src1, alpha, src2, beta, 0.0, dst);

	// imshow("GMM FRAME", gmmFrame);

	 displayFrame( "COMB 1", dst );
	 Mat comb1;

	 dst.copyTo(comb1);
	 Mat comb1Blob;

	 //comb1Blob = blobDetector(comb1);

	 //displayFrame("Comb 1 Blob", comb1Blob);

	 //imwrite("currentCOMB1.TIFF", dst);



	 displayFrame("GL @ CUR", globalFrames.at(i));


	 //addWeighted( dst, alpha, imgDiff, beta, 0.0, dst);
	 displayFrame( "COMB 2", dst );

	// imwrite("currentCOMB2.TIFF", dst);

	//displayFrame("IMG DIFF", imgDiff);

	if(debug)
			cout << "Completed iS" << endl;
}

//method to initalize Mats on startup
void initilizeMat()
{
	//if first run
	if(i == 0)
	{

		//initialize background subtractor object
		backgroundSubtractorGMM->set("initializationFrames", bufferMemory);
		backgroundSubtractorGMM->set("decisionThreshold", 0.999999999);

		//save gray value to set Mat parameters
		backgroundFrameMedian = globalGrayFrames.at(i);
	}
}

//method to process exit of software
bool processExit(VideoCapture capture, clock_t t1, char keyboardClick)
{
	//if escape key is pressed
	if(keyboardClick==27)
	{
		//display exiting message
		cout << "Exiting" << endl;

		//compute total run time
		computeRunTime(t1, clock(), (int) capture.get(CV_CAP_PROP_POS_FRAMES));

		//delete entire vector
		globalFrames.erase(globalFrames.begin(), globalFrames.end());

		//report file finished writing
		cout << "Finished writing file, Goodbye." << endl;

		//exit program
		return true;
	}

	else
	{
		return false;
	}
}

//main method
int main() {

	//display welcome message if production code
	//if(!debug)
		welcome(true);

	//creating initial and final clock objects
	//taking current time when run starts
	clock_t t1=clock();

	//random number generator
	RNG rng(12345);

	//defining VideoCapture object and filename to capture from
	VideoCapture capture(filename);

	//collecting statistics about the video
	//constants that will not change
	const int NUMBER_OF_FRAMES =(int) capture.get(CV_CAP_PROP_FRAME_COUNT);
	const int FRAME_RATE = (int) capture.get(CV_CAP_PROP_FPS);
	FRAME_WIDTH = capture.get(CV_CAP_PROP_FRAME_WIDTH);
	FRAME_HEIGHT = capture.get(CV_CAP_PROP_FRAME_HEIGHT);

	writeInitialStats(NUMBER_OF_FRAMES, FRAME_RATE, FRAME_WIDTH, FRAME_HEIGHT, filename);

	// declaring and initially setting variables that will be actively updated during runtime
	int framesRead = (int) capture.get(CV_CAP_PROP_POS_FRAMES);
	double framesTimeLeft = (capture.get(CV_CAP_PROP_POS_MSEC)) / 1000;

	//creating placeholder object
	Mat placeHolder = Mat::eye(1, 1, CV_64F);

	//vector to store execution times
	vector <string> FPS;

	//string to display execution time
	string strActiveTimeDifference;

	//actual run time, while video is not finished
	while(framesRead < NUMBER_OF_FRAMES)
	{
		clock_t tStart = clock();

		//read in current key press
		//char keyboardClick = cvWaitKey(33);

		//create pointer to new object
		Mat * frameToBeDisplayed = new Mat();

		//creating pointer to new object
		Mat * tmpGrayScale = new Mat();

		//reading in current frame
		capture.read(*frameToBeDisplayed);


		//for initial buffer read
		while(i < bufferMemory)
		{
			//create pointer to new object
			Mat * frameToBeDisplayed = new Mat();

			//creating pointer to new object
			Mat * tmpGrayScale = new Mat();

			//reading in current frame
			capture.read(*frameToBeDisplayed);

			//adding current frame to vector/array list of matricies
			globalFrames.push_back(*frameToBeDisplayed);

			//convert to gray scale frame
			cvtColor(globalFrames.at(i), *tmpGrayScale, CV_BGR2GRAY);

			//save grayscale frame
			globalGrayFrames.push_back(*tmpGrayScale);

			//initilize Mat objects
			initilizeMat();

			//display buffer progress
			if(!debug)
				cout << "Buffering frame " << i << ", " << (bufferMemory - i) << " frames remaining." << endl;

			//incrementing global counter
			i++;
		}

		//adding current frame to vector/array list of matricies
		globalFrames.push_back(*frameToBeDisplayed);

		Mat dispFrame;
		globalFrames.at(i).copyTo(dispFrame);
		putText(dispFrame,to_string(i),Point(0,50),1,1,Scalar(0,255,0),2);

		//display raw frame
		//displayFrame("RCFrame", globalFrames.at(i));
		displayFrame("RCFrame", dispFrame);

		//convert to gray scale
		cvtColor(globalFrames.at(i), *tmpGrayScale, CV_BGR2GRAY);

		//save gray scale frames
		globalGrayFrames.push_back(*tmpGrayScale);

		//gather real time statistics
		framesRead = (int) capture.get(CV_CAP_PROP_POS_FRAMES);
		framesTimeLeft = (capture.get(CV_CAP_PROP_POS_MSEC)) / 1000;

		//clocking end of run time
		clock_t tFinal = clock();

		//calculate time
		strActiveTimeDifference = (to_string(calculateFPS(tStart, tFinal))).substr(0, 4);

		//display performance
		if(debug)
			cout << "FPS is " << (to_string(1/(calculateFPS(tStart, tFinal)))).substr(0, 4) << endl;

		//saving FPS values
		FPS.push_back(strActiveTimeDifference);
		
		//running image analysis
		objectDetection(FRAME_RATE);

		//display frame number
		if(!debug)
			{cout << "Currently processing frame number " << i << "." << endl;}

		//method to process exit
	//	if(processExit(capture,  t1, keyboardClick))
		//	return 0;

		//deleting current frame from RAM
   		delete frameToBeDisplayed;

   		//incrementing global counter
   		i++;
	}

	//delete entire vector
   	globalFrames.erase(globalFrames.begin(), globalFrames.end());

	//compute run time
	computeRunTime(t1, clock(),(int) capture.get(CV_CAP_PROP_POS_FRAMES));

	//display finished, promt to close program
	cout << "Execution finished, file written, click to close window. " << endl;

	//wait for button press to proceed
	waitKey(0);

	//return code is finished and ran successfully
	return 0;
}

















==============
void drawObject(int x, int y,Mat &frame){

	//use some of the openCV drawing functions to draw crosshairs
	//on your tracked image!

    //UPDATE:JUNE 18TH, 2013
    //added 'if' and 'else' statements to prevent
    //memory errors from writing off the screen (ie. (-25,-25) is not within the window!)

	circle(frame,Point(x,y),20,Scalar(0,255,0),2);
    if(y-25>0)
    line(frame,Point(x,y),Point(x,y-25),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(x,0),Scalar(0,255,0),2);
    if(y+25<FRAME_HEIGHT)
    line(frame,Point(x,y),Point(x,y+25),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(x,FRAME_HEIGHT),Scalar(0,255,0),2);
    if(x-25>0)
    line(frame,Point(x,y),Point(x-25,y),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(0,y),Scalar(0,255,0),2);
    if(x+25<FRAME_WIDTH)
    line(frame,Point(x,y),Point(x+25,y),Scalar(0,255,0),2);
    else line(frame,Point(x,y),Point(FRAME_WIDTH,y),Scalar(0,255,0),2);

	putText(frame,to_string(x)+","+to_string(y),Point(x,y+30),1,1,Scalar(0,255,0),2);

}

void morphOps(Mat &thresh){

	//create structuring element that will be used to "dilate" and "erode" image.
	//the element chosen here is a 3px by 3px rectangle

	Mat erodeElement = getStructuringElement( MORPH_RECT,Size(3,3));
    //dilate with larger element so make sure object is nicely visible
	Mat dilateElement = getStructuringElement( MORPH_RECT,Size(8,8));

	erode(thresh,thresh,erodeElement);
	erode(thresh,thresh,erodeElement);


	dilate(thresh,thresh,dilateElement);
	dilate(thresh,thresh,dilateElement);



}

void trackFilteredObject(int &x, int &y, Mat threshold, Mat &cameraFeed){

	Mat HSV;
	int H_MIN = 0;
	int H_MAX = 256;
	int S_MIN = 0;
	int S_MAX = 256;
	int V_MIN = 0;
	int V_MAX = 256;
	cvtColor(cameraFeed,HSV,COLOR_BGR2HSV);
	//filter HSV image between values and store filtered image to
	//threshold matrix
	inRange(HSV,Scalar(H_MIN,S_MIN,V_MIN),Scalar(H_MAX,S_MAX,V_MAX),threshold);
	morphOps(threshold);


	const int MAX_NUM_OBJECTS = 15;
	const int MIN_OBJECT_AREA = 50;
	const int MAX_OBJECT_AREA = 1000;

	Mat temp;
	threshold.copyTo(temp);
	//these two vectors needed for output of findContours
	vector< vector<Point> > contours;
	vector<Vec4i> hierarchy;
	//find contours of filtered image using openCV findContours function
	findContours(temp,contours,hierarchy,CV_RETR_CCOMP,CV_CHAIN_APPROX_SIMPLE );
	//use moments method to find our filtered object
	double refArea = 0;
	bool objectFound = false;
	if (hierarchy.size() > 0) {
		int numObjects = hierarchy.size();
        //if number of objects greater than MAX_NUM_OBJECTS we have a noisy filter
        if(numObjects<MAX_NUM_OBJECTS){
			for (int index = 0; index >= 0; index = hierarchy[index][0]) {

				Moments moment = moments((cv::Mat)contours[index]);
				double area = moment.m00;

				//if the area is less than 20 px by 20px then it is probably just noise
				//if the area is the same as the 3/2 of the image size, probably just a bad filter
				//we only want the object with the largest area so we safe a reference area each
				//iteration and compare it to the area in the next iteration.
                if(area>MIN_OBJECT_AREA && area<MAX_OBJECT_AREA && area>refArea){
					x = moment.m10/area;
					y = moment.m01/area;
					objectFound = true;
					refArea = area;
				}else objectFound = false;


			}
			//let user know you found an object
			if(objectFound ==true){
				putText(cameraFeed,"Tracking Object",Point(0,50),2,1,Scalar(0,255,0),2);
				//draw object location on screen
				drawObject(x,y,cameraFeed);}

		}else putText(cameraFeed,"TOO MUCH NOISE! ADJUST FILTER",Point(0,50),1,2,Scalar(0,0,255),2);
	}
}



			//globalFrames.at(i).convertTo(globalGrayFrames.at(i), CV_8U);

void displayWindows()
{
	Mat * dispMat = new Mat();

	*dispMat = globalFrames.at(i);

	putText(*dispMat, to_string(i), cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1, cvScalar(0,255,0), 1, CV_AA, false);

	imshow("Raw Frame",*dispMat );

	imshow("Raw Car Image", subtractedImage);
}

//globalFrames.at(i).convertTo(globalGrayFrames.at(i), CV_8U);


// DrawMatchesFlags::DRAW_RICH_KEYPOINTS flag ensures the size of the circle corresponds to the size of blob

/*
	for(int v = 0; v < backgroundFrameColorMedian.rows; v++)
	{
	    for(int j = 0; j < backgroundFrameColorMedian.cols; j++)
	    {
	        Vec3b bgrPixel = backgroundFrameColorMedian.at<Vec3b>(v, j);
	    }
	}
	*/

/*
if(i % 10 == 0 && i > 9)
{
	destroyWindow("Median Background Image");
	destroyWindow("Mean Background Image");
}
*/

//imshow("Median Background Image", backgroundFrameMedian);
//destroyWindow("Mean Background Image");

//pthread_create(&meanImageThread, NULL, calcMeanImage, (void *)&threadData);

//backgroundFrameMedian = meanImage();
//backgroundFrameMedian = medianImage()
/*
	for(int j=0;j<cflow.rows;j++)
	{
		for (int a=0;a<cflow.cols;a++)
		{
			if(cflow.at<uchar>(j,a) > threshold)
			{
				thresholdFrame.at<uchar>(j,a) = 0;
				if(!debug){}
					//thresholdFrame = drawObjectLocation(j,a, thresholdFrame);
			}
			else
			{
				thresholdFrame.at<uchar>(j,a) = 255;
			}
		}
	}
	*/
	//displayFrame("FDOFA ObjDet", thresholdFrame);



	/*
	for(int y = 0; y < cflow.rows; y += opticalFlowDensityDisplay)
	{
	   	for(int x = 0; x < cflow.cols; x += opticalFlowDensityDisplay)
	    {
	   		counterCheck++;
	    }
	}

	//iterating through each pixel and drawing vector
    for(int y = 0; y < opticalFlowObject.rows; y += opticalFlowDensityDisplay)
    {
    	for(int x = 0; x < opticalFlowObject.cols; x += opticalFlowDensityDisplay)
        {
    		liveCounter++;

    		if(debug)
    		{
    			//cout << liveCounter << " live counter" << endl;
    			//cout << counterCheck << " counter check" << endl;
    		}

    		if(debug){}
    			//cout << "entered here adsf " << endl;

    		const Point2f& fxy = flow.at<Point2f>(y, x);
            if(debug){}
            	//cout << sqrt((abs(fxy.x) * abs(fxy.y))) << " size of x" << endl;

            //opticalFlowObject.at<uchar>(x,y) = (uchar) sqrt((abs(fxy.x) * abs(fxy.y)));
        }
   	}
	*/

/*
	if(i % 10 == 0 && i > 9)
	{
		destroyWindow("Median Background Image");
		destroyWindow("Mean Background Image");
	}
	*/

	//imshow("Median Background Image", backgroundFrameMedian);
	//destroyWindow("Mean Background Image");

//pthread_create(&meanImageThread, NULL, calcMeanImage, (void *)&threadData);

	//backgroundFrameMedian = meanImage();
	//backgroundFrameMedian = medianImage();
	//while(medianImageCompletion != 1 || medianImageCompletion !=  1) {}

/*
	 namedWindow("image", WINDOW_NORMAL);
	    namedWindow("foreground mask", WINDOW_NORMAL);
	    namedWindow("foreground image", WINDOW_NORMAL);
	    namedWindow("mean background image", WINDOW_NORMAL);

	    BackgroundSubtractorMOG2 bg_model;//(100, 3, 0.3, 5);

	    Mat img, fgmask, fgimg;    bool update_bg_model = true;

	    for(int v = 0; v < i; v++)
	    	    {
	    			img = globalGrayFrames.at(v);
	    if( fgimg.empty() )
	             fgimg.create(img.size(), img.type());

	           //update the model
	           bg_model(img, fgmask, update_bg_model ? -1 : 0);

	           fgimg = Scalar::all(0);
	           img.copyTo(fgimg, fgmask);

	           Mat bgimg;
	           bg_model.getBackgroundImage(bgimg);

	           gmmFrame = fgimg;

	    	    }
	    	    */	


	/*

	if(debug)
			cout << "enter gmm thread copy to" << endl;

	BackgroundSubtractorMOG gmmModel;

	Mat resizeF;
	Mat fgMaskMOG; //fg mask generated by MOG method
	Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	Mat fgMaskGMG; //fg mask fg mask generated by MOG2 method

	Ptr< BackgroundSubtractor> pMOG; //MOG Background subtractor
	Ptr< BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
	Ptr< BackgroundSubtractorGMG> pGMG; //MOG2 Background subtractor

	pMOG = new BackgroundSubtractorMOG();
	pMOG2 = new BackgroundSubtractorMOG2();
	pGMG = new BackgroundSubtractorGMG();

    Mat element = getStructuringElement(MORPH_RECT, Size(3, 3), Point(1,1) );

    //resize(gmmFrame, resizeF, Size(gmmFrame.size().width/4, gmmFrame.size().height/4) );
    resizeF = gmmFrame;

    pMOG->operator()(resizeF, fgMaskMOG);
    pMOG2->operator()(resizeF, fgMaskMOG2);
    pGMG->operator()(resizeF, fgMaskGMG);

    gmmFrame = fgMaskMOG;

    displayFrame("MOG" , fgMaskMOG);
    displayFrame("MOG2" , fgMaskMOG2);
    displayFrame("GMG" , fgMaskGMG);

*/
/*
	BackgroundSubtractorMOG2 bg;
     //  bg.nmixtures = 3;
      // bg.bShadowDetection = false;
       vector<std::vector<cv::Point> > contours;

    cv::Mat back;
        cv::Mat fore;
    bg.operator ()(gmmFrame,fore);
           bg.getBackgroundImage(back);
           cv::erode(fore,fore,cv::Mat());
           cv::dilate(fore,fore,cv::Mat());
           cv::findContours(fore,contours,CV_RETR_EXTERNAL,CV_CHAIN_APPROX_NONE);
           cv::drawContours(gmmFrame,contours,-1,cv::Scalar(0,0,255),2);
           cv::imshow("Background",back);

           cout << " pre disp" << endl;
           displayFrame("background" , back);
           cout << "finish disp" << endl;

           gmmFrame = back;

	*/
    /*
    imshow("Origin", resizeF);
    imshow("MOG", fgMaskMOG);
    imshow("MOG2", fgMaskMOG2);
    imshow("GMG", fgMaskGMG);
    */
	/*
	Mat mask,thresholdImage, output;
Mat fgmask;
BackgroundSubtractorMOG2 bgSubtractor(20,16,true);

	for(int v = 0; v < i; v++)
	{
		globalFrames.at(v).copyTo(gmmFrame);
		BackgroundSubtractorMOG bgSubtractor(20,10,0.5,false);
		bgSubtractor(gmmFrame,mask,0.001);
		//BackgroundSubtractorMOG::operator()(gmmFrame, fgmask, 0);
		cout << " V" << v << endl;
	}
			imshow("mask",mask);
	*/


	/*
	int counterTotal = 0;
	int activeCounter = 0;

	for(int i = 0; i < backgroundFrameColorMedian.rows; i++)
	{
		for(int j = 0; j < backgroundFrameColorMedian.cols; j++)
		{
			counterTotal++;
		}
	}

	for(int i = 0; i < backgroundFrameColorMedian.rows; i++)
	{
	    for(int j = 0; j < backgroundFrameColorMedian.cols; j++)
	    {
	    	for(int )
	    	cout << " asdf "  << (int) backgroundFrameColorMedian.at<cv::Vec3b>(i,j)[0] << endl;;
	    	cout << " Counter Total " << counterTotal << endl;

	    	cout << " Active Counter " << activeCounter << endl;

	    	activeCounter++;
	    	uint16_t* pixelPtr = (uint16_t*)backgroundFrameColorMedian.data;
	    		int cn = backgroundFrameColorMedian.channels();
	    		Scalar_<uint16_t> bgrPixel;

	        bgrPixel.val[0] = pixelPtr[i*backgroundFrameColorMedian.cols*cn + j*cn + 0]; // B
	        bgrPixel.val[1] = pixelPtr[i*backgroundFrameColorMedian.cols*cn + j*cn + 1]; // G
	        bgrPixel.val[2] = pixelPtr[i*backgroundFrameColorMedian.cols*cn + j*cn + 2]; // R
	        if(debug)
	     	        	cout << "Pixel value is " << bgrPixel[0] << "." << endl;

	        // do something with BGR values...
	    }
	}
	*/

globalMeanGrayFrames.push_back(*tmpGrayScale);
backgroundFrameMean = globalGrayFrames.at(i);
vector <Mat> globalMeanGrayFrames;
int meanImageCompletion = 0;
Mat backgroundFrameMean;

void *calcMeanImage(void *threadarg)
{
	struct thread_data *data;
	data = (struct thread_data *) threadarg;
	i = data->i;

    backgroundFrameMean = globalMeanGrayFrames.at(i);

	//create counter to calculate mean
	int total = 0;

	//change some pixel value
	for(int j=0;j<backgroundFrameMean.rows;j++)
	{
	    for (int a=0;a<backgroundFrameMean.cols;a++)
	    { 
			vector <int> pixelHistory;
		  	for (int t = 0; t < i ; t++)
		  	{
		    	Mat currentFrameForMeanBackground;
			  	total += currentFrameForMeanBackground.at<uchar>(j,a); //cvGetReal2D(&globalFrames.at(i-t), j, a);
				pixelHistory.push_back((globalMeanGrayFrames.at(i - t)).at<uchar>(j,a));
		  	}
		   
		    //backgroundFrameMean.at<uchar>(j,a) = calcMean(pixelHistory);
		    backgroundFrameMean.at<uchar>(j,a) = rand() % 250;

	    }
	}
	putText(backgroundFrameMean, to_string(i), cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1, cvScalar(0,255,0), 1, CV_AA, false);

    medianImageCompletion = 1;
}

Mat medianImage()
{
	Mat medianImage;

	medianImage = globalGrayFrames.at(i);

	Mat img = globalGrayFrames.at(i);
	//change some pixel value
	for(int j=0;j<img.rows;j++)
	{
	  for (int a=0;a<img.cols;a++)
	  {
		  vector <int> pixelHistory;

		  for (int t = 0; t < i ; t++)
		  {
			pixelHistory.push_back((globalGrayFrames.at(i-t)).at<uchar>(j,a));
		  }

		  medianImage.at<uchar>(j,a) = calcMedian(pixelHistory);
	  }
	}

	//putText(medianImage, to_string(i), cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1, cvScalar(0,255,0), 1, CV_AA, false);
	return medianImage;
}



//save temperatures at sensor point to txt files
void saveToTxtFile(double m_Emissivity)
{
	//instantiate new filestream
	ofstream file;

	//concanating and creating file name string
	string strVectFilename = to_string(m_Emissivity) + " temperatures.txt";

	//create file
	file.open (strVectFilename);

	//initializing counter
	int v = 0;

	//save txt file
	while(v < temperatures.size())
	{
		//file << "Temperature at sensor point " << temperatures.at(v) << " at T " << v << "." << endl;
		file <<  temperatures.at(v) << endl;
		v++;
	}

	//close file stream
	file.close();

}

/*
	 string line;
	 int test;
	 ifstream myfile (currFileName);
	 if (myfile.is_open())
	 {
		 //Enter input
		while(myfile.good())
		{
			myfile>>test;
			cout << test << endl;
		}//end while

		 while ( getline (myfile, test) )
		 {
			 cout << test << '\n';
		 }


		 myfile.close();
	 }

	 else cout << "Unable to open file";
	 */

//conversionFactor = 275 - 50;
		//cout << "Using default values for conversion factor..." << " Conversion Factor = " << conversionFactor << "\n" << endl;

/*
double checkAccuracy()
{
	//cout << "Length of temperatures is " << temperatures.size() <<" & groundTruth length is" <<groundTruth.size() << endl;

	double sumTotal = 0;
	vector <double> difference;

	cout << groundTruth.size() << endl;
	cout << temperatures.size() << endl;

	for(int i = 0; i < groundTruth.size(); i++)
	{
		difference.push_back(abs(temperatures.at(i) - groundTruth.at(i)));
	}

	for(int j = 0; j < difference.size(); j++)
	{
		sumTotal += difference.at(j);
	}

	return (sumTotal / difference.size());
}
*/

//cout << to_string(unsignedShortRawPixelValue) << "raw val" <<  endl;

//converting to unsigned short 
//ushort unsignedShortRawPixelValue = (unsigned short) unsignedCharacterRawPixelValue;


	//Mat Img_Destination8Bit_Gray(imgHeight,imgWidth,CV_8UC1);
	//Mat convertedFrame16Bit(imgHeight,imgWidth,CV_16UC1);

//save temperatures to text file
void saveToTxtFile(vector <float> vectorToSave, string vectFilenameAppend)
{
	//instantiate new filestream
	ofstream file;

	//concanating and creating file name string
	string strVectFilename = vectFilenameAppend + "temperatures.txt";

	//create file
	file.open (strVectFilename);

	//initializing counter
	int v = 0;

	//save txt file
	while(v < vectorToSave.size() - 3)
	{
		file << "Temperature is " << vectorToSave.at(v) << " at pixel location ";
		v++;
		file << vectorToSave.at(v) << " X ";
		v++;
		file << vectorToSave.at(v) << endl;
	}

	//close file stream
	file.close();
}



	//saving temperatures to txt file
	//saveToTxtFile(temperatures, to_string(i));
		
	//cout << " dimensions" << (s.height * s.width * 2) << endl;

	/*
	Mat test;

	rawImage.convertTo(test, CV_16SC1);

	imshow("test", test);
	*/

//saving character from initial image
			//uchar unsignedCharacterRawPixelValue = rawImage.at<ushort>(i,j);

			//cout << stoi(to_string(unsignedCharacterRawPixelValue)) << "raw val" << endl;

			counter++;
			//cout << counter << " counter " << endl;	

	//convertedTemperature = -1;
			//cout << convertedTemperature << " conv temp" << endl;
			//convertedTemperature = 300.0/257.0;
			//cout << convertedTemperature << endl;
			//cout << convertedTemperature << "conv val" << endl;



//save pixel data into vector
			//temperatures.push_back(i);
			//temperatures.push_back(j);

			//converting back to unsigned character 
			//unsignedCharacterRawPixelValue = (ushort) (convertedTemperature);



	//applying scaling	
	Img_Source16Bit_Gray.convertTo(Img_Destination8Bit_Gray, CV_8U, 100.0/(maxVal - minVal));

	//calculating scalar factor to rever convert to
	double scalarFactor =(maxVal - minVal) / 100.0;
	//double scalarFactor = 1;

	//for every row
	for (int i = 0; i < Img_Destination8Bit_Gray.rows; i++)
	{	
		//for every column
		for(int j = 0; j < Img_Destination8Bit_Gray.cols; j++)
		{	
			//undo scaling, cast to unsigned short, send to Tau To Temp function, and save new pixel value
			float tmp =  TauToTemp((ushort)stod(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j))));

			Img_Destination8Bit_Gray.at<uchar>(i,j)  = tmp;
			//Img_Destination8Bit_Gray.at<uchar>(i,j)  = TauToTemp((ushort)stod(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j))));
			//if(i == 200 && j == 200)


		}
	}

	//return converted matrix
	return Img_Destination8Bit_Gray;	





	//Mat test = Mat(imgHeight, imgWidth, CV_16U);
/*

    Mat lookUpTable(imgHeight, imgWidth, CV_16U);

    uchar* p = lookUpTable.data;
    /*
    for (int i = 0; i < (imgWidth * imgHeight) ;++i)
    {
    	//p[i] = table[i];
    }


    int v = 100;
        for( int w = 0 ; w < test.rows ; ++w )
        {
            for( int h = 0 ; h < test.cols ; ++h )
            {
            	cout << test.at<uchar>(w,h) << "num" << endl;
            	test.at<uchar>(w,h) = saturate_cast<uchar>(v) ;
                v++ ;
            }
        }
*/
    /*
    uchar* p1 = test.data ;    // p1 for normal way

        // normal way : one_by_one iteration
        // timing start
        for( int i = 0 ; i < imgHeight * imgWidth ; ++i )
        {
            p1[i] = (uchar)log10(( p1[i] )) ;
        }
        imwrite("wee.bmp", test);
        */
/*
std::for_each(test.begin<uchar>(), test.end<uchar>(), [](uchar& pixel) {
	pixel = 0;

			                });*/

/*
			counter++;
			//undo scaling, cast to unsigned short, send to Tau To Temp function, and save new pixel value
			double tmp =  TauToTemp((ushort)stod(to_string(Img_Source16Bit_Gray.at<uchar>(i,j))));
			//tmp = (int16_t) tmp;
			//cout << tmp << " at i = " << i << " and j = " << j << endl;
			//Img_Source16Bit_Gray.at<uchar>(i,j)  = 20;//(uchar) tmp;
			//cout << (tmp) * 1<< endl;
			//tmp *= 255;
			//tmp /= 65535;
			uchar myChar = saturate_cast<uchar>(tmp); //(unsigned char) tmp;
			stringstream s;
			s << myChar;

			string str_my_txt = s.str();
			//string my_std_string = (string) (myChar);
            //string sName(reinterpret_cast<uchar>(myChar));
			//cout << (str_my_txt )<<  "string of text" << endl;

			test.at<uchar>(i,j)  = saturate_cast<uchar>(tmp);
			cout << (test.at<uchar>(i, j)  < 290 )<< endl;

			//test[i[j]]= 100;
			//test.at<uchar>(i,j)  = (uchar) 10000; //(uchar) tmp;
			//cout << to_string(test.at<uchar>(i, j))  << " here is the value" << endl;
			//Img_Destination8Bit_Gray.at<uchar>(i,j)  = TauToTemp((ushort)stod(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j))));
			*/




/*
	//for every row
	for (int i = 0; i < convertedFrame16Bit.rows; i++)
	{
		//for every column
		for(int j = 0; j < convertedFrame16Bit.cols; j++)
		{
			//undo scaling, cast to unsigned short, send to Tau To Temp function, and save new pixel value
			float tmp =  TauToTemp((ushort)stod(to_string(convertedFrame16Bit.at<uchar>(i,j))));
			cout << tmp << endl;
			convertedFrame16Bit.at<uchar>(i,j)  = tmp;
			cout << to_string(convertedFrame16Bit.at<uchar>(i, j))  << " here is the value" << endl;
			//Img_Destination8Bit_Gray.at<uchar>(i,j)  = TauToTemp((ushort)stod(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j))));

		}
	}
	*/


//read RAW, convert and return final for further processing
Mat readConvertRAW2Mat(string filenameToRead)
{
	//defining matricies to hold images	with correct sizes
	Mat Img_Source16Bit_Gray(imgHeight,imgWidth,CV_16UC1);
	Mat Img_Destination8Bit_Gray(imgHeight,imgWidth,CV_8UC1);

	//defining file object
	FILE * fileToRead;

	//converting to constant char pointer
	const char* constCharFilenameToRead = filenameToRead.c_str();

	//pointing to image address
	fileToRead = fopen(constCharFilenameToRead,"rb");

	//checking if image has content
	if (!fileToRead)
	{
		//display error
	    cout << "Error 404: File Not Found" << endl;;

	}

	//declaring character array to hold pixels
	char16_t* pY16Pixels;

	//declaring array with enough space to hold all pixels
	pY16Pixels = new char16_t[imgWidth * imgHeight];

	//reading in all pixel values into array
	fread(pY16Pixels,imgWidth*imgHeight*2,1,fileToRead);

	//assembling into matrix
	Img_Source16Bit_Gray.data= reinterpret_cast<uchar*>(pY16Pixels);

	//declaring variables
	double minVal, maxVal;

	//identifying scalar factors	
	minMaxLoc(Img_Source16Bit_Gray, &minVal, &maxVal); 

	//applying scaling	
	Img_Source16Bit_Gray.convertTo(Img_Destination8Bit_Gray, CV_8U, 100.0/(maxVal - minVal));

	//calculating scalar factor to rever convert to
	double scalarFactor =(maxVal - minVal) / 100.0;
	//double scalarFactor = 1;


	//for every row
	for (int i = 0; i < Img_Destination8Bit_Gray.rows; i++)
	{	
		//for every column
		for(int j = 0; j < Img_Destination8Bit_Gray.cols; j++)
		{	
			//undo scaling, cast to unsigned short, send to Tau To Temp function, and save new pixel value
			float tmp =  TauToTemp((ushort)stod(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j))));
			if((int)tmp == 350)
			{
				cout << "i = " << i << endl;
				cout << "j = " << j << endl;
			}
			Img_Destination8Bit_Gray.at<uchar>(i,j)  = tmp;
			//Img_Destination8Bit_Gray.at<uchar>(i,j)  = TauToTemp((ushort)stod(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j))));
			//if(i == 200 && j == 200)
			if(tmp < 25
					)
			{
				cout << "Value is " << tmp << " at Water Coolant Area" << endl;
			}

		}
	}

	imwrite("test.TIFF", Img_Destination8Bit_Gray);

	//return converted matrix
	return Img_Destination8Bit_Gray;
}













====================

















//======================================================================================================
// Name        : TrafficCameraDistractedDriverDetection.cpp
// Author      : Vidur Prasad
// Version     : 0.2.0
// Copyright   : Institute for the Development and Commercialization of Advanced Sensor Technology Inc.
// Description : Detect Drunk, Distracted, and Anomlous Driving Using Traffic Cameras
//======================================================================================================

//include opencv library files
#include "opencv2/highgui/highgui.hpp"
#include <opencv2/objdetect/objdetect.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/video/tracking.hpp>
#include "opencv2/nonfree/nonfree.hpp"
#include "opencv2/gpu/gpu.hpp"
#include <opencv2/nonfree/ocl.hpp>
#include <opencv/cv.h>
#include <opencv2/video/background_segm.hpp>
#include <opencv2/core/core.hpp>


//include c++ files
#include <iostream>
#include <fstream>
#include <ctime>
#include <time.h>
#include <thread>
#include <chrono>
#include <stdio.h>
#include <stdlib.h>
#include <limits>
#include <math.h>
#include <algorithm>
#include <vector>
#include <string>
#include <pthread.h>
#include <cstdlib>


//namespaces for convenience
using namespace cv;
using namespace std;

//setting constant filename to read form
//const char* filename = "assets/testRecordingSystemTCD3TCheck.mp4";
//const char* filenamePrefix = "/Users/Vidur/OneDrive/EX/Internships/ID\ CAST/Honda\ Thermal/C\ Workspace/HondaThermal/assets/OSU_Thermal_Test/Test\ 10\ RrR/";
string filenamePrefix = "/Users/Vidur/OneDrive/EX/Internships/ID\ CAST/Honda\ Thermal/C\ Workspace/HondaThermal/assets/OSU_Thermal_Test/Test\ 10\ RtR/";


const int imgWidth = 320;
const int imgHeight =256;

////DECLARING TAU TO TEMP CONSTANTS////
//set during runtime
double m_K1;
double m_K2;

// Object parameters
double m_AmbTemp = 293.15f;
double m_ExtOptTemp = 293.15f;
double m_ExtOptTransm = 1.0f; // default
double m_ObjectDistance = 2.0; // default
double m_RelHum = 0.5; // default

// Spectral Response Parameters
double m_X = 1.9;
double m_alpha1 = 0.006569;
double m_beta1 = -0.002276;
double m_alpha2 = 0.01262;
double m_beta2 = -0.00667;

//start set values test 10
int m_R = 344749;
double m_B = 1428;
double m_O = 397.523;
double m_F = 1;
bool m_bMeasCapable = true;
double m_AtmTao = .999999995904;
double m_Emissivity = 0.699951169008;
double m_AtmTemp = 295.15;

////DECLARING TAU TO TEMP CONSTANTS////

//determine type of Mat for Debug
string type2str(int type) 
{
	//declaring string to hold return value
	string r;

	//stats about Mat
  	uchar depth = type & CV_MAT_DEPTH_MASK;
  	uchar chans = 1 + (type >> CV_CN_SHIFT);

  	//switch to choose based on depth
	switch ( depth ) 
	{
		case CV_8U:  r = "8U"; break;
		case CV_8S:  r = "8S"; break;
		case CV_16U: r = "16U"; break;
		case CV_16S: r = "16S"; break;
		case CV_32S: r = "32S"; break;
		case CV_32F: r = "32F"; break;
		case CV_64F: r = "64F"; break;
		default:     r = "User"; break;
	}

	//formatting type
	r += "C";
	r += (chans+'0');

 	return r;
}

//converting Kelvin to Celsius
double KtoC(double val, bool isDiffTemp)
{
	double Zero_C = 273.15;

	if (!isDiffTemp)
		val = val - Zero_C;

	return (val);
}

//calculating atmospheric contant
double DoCalcAtmTao()
{
    double tao, dtao;
    double H, T, sqrtD, X, a1, b1, a2, b2;
    double sqrtH20;
    double TT;
    double a1b1sqH20, a2b2sqH20, exp1, exp2;
    //Temperature C = new Temperature(TempUnit.Celsius);





    double H20_K1 = +1.5587e+0;
    double H20_K2 = +6.9390e-2;
    double H20_K3 = -2.7816e-4;
    double H20_K4 = +6.8455e-7;

    double TAO_TATM_MIN = -30.0;
    double TAO_TATM_MAX = 90.0;
    double TAO_SQRTH20MAX = 6.2365;
    double TAO_COMP_MIN = 0.400;
    double TAO_COMP_MAX = 1.000;

    H = m_RelHum;
    //C = new Temperature(m_AtmTemp); // TODO: Check to make sure conversion
    /// works correctly.
    //T = C.Value(); // We need Celsius to use constants defined above
    T = KtoC(m_AtmTemp, true);
    sqrtD = sqrt(m_ObjectDistance);
    X = m_X;
    a1 = m_alpha1;
    b1 = m_beta1;
    a2 = m_alpha2;
    b2 = m_beta2;

    if (T < TAO_TATM_MIN)
        T = TAO_TATM_MIN;
    else if (T > TAO_TATM_MAX)
        T = TAO_TATM_MAX;

    TT = T * T;

    sqrtH20 = sqrt(H * exp(H20_K1 + H20_K2 * T + H20_K3 * TT + H20_K4 * TT * T));

    if (sqrtH20 > TAO_SQRTH20MAX)
        sqrtH20 = TAO_SQRTH20MAX;

    a1b1sqH20 = (a1 + b1 * sqrtH20);
    a2b2sqH20 = (a2 + b2 * sqrtH20);
    exp1 = exp(-sqrtD * a1b1sqH20);
    exp2 = exp(-sqrtD * a2b2sqH20);

    tao = X * exp1 + (1 - X) * exp2;
    dtao = -(a1b1sqH20 * X * exp1 + a2b2sqH20 * (1 - X) * exp2);
    // The real D-derivative is also diveded by 2 and sqrtD.
    // Here we only want the sign of the slope!

    if (tao < TAO_COMP_MIN)
        tao = TAO_COMP_MIN; // below min value, clip

    else if (tao > TAO_COMP_MAX)
    {
        // check tao at 1 000 000 m dist
        tao = X * exp(-(1.0E3) * a1b1sqH20) + (1.0 - X) *  exp(-(1.0E3) * a2b2sqH20);

        if (tao > 1.0) // above max, staying up, assume \/ - shape
            tao = TAO_COMP_MIN;
        else
            tao = TAO_COMP_MAX; // above max, going down, assume /\ - shape
    }
    else if (dtao > 0.0 && m_ObjectDistance > 0.0)
        tao = TAO_COMP_MIN; // between max & min, going up, assume \/

    // else between max & min, going down => OK as it is

    return (tao);
}

//constant calculations
double DoCalcK1()
{
    double dblVal = 1.0;

    dblVal = m_AtmTao * m_Emissivity * m_ExtOptTransm;
    //cout << dblVal << " dblVal" << endl;
    if (dblVal > 0.0)
        dblVal = 1 / dblVal;

    return (dblVal);
}

//constant calculations
double DoCalcK2(double dAmbObjSig,
                        double dAtmObjSig,
                        double dExtOptTempObjSig)
{
    double emi;
    double temp1 = 0.0;
    double temp2 = 0.0;
    double temp3 = 0.0;

    emi = m_Emissivity;

    if (emi > 0.0)
    {
        temp1 = (1.0 - emi) / emi * dAmbObjSig;

        if (m_AtmTao > 0.0)
        {
            temp2 = (1.0 - m_AtmTao) / (emi * m_AtmTao) * dAtmObjSig;

            if (m_ExtOptTransm > 0.0 && m_ExtOptTransm < 1.0)
            {
                temp3 = (1.0 - m_ExtOptTransm) /
                    (emi * m_AtmTao * m_ExtOptTransm) * dExtOptTempObjSig;
            }
        }
    }

    return (temp1 + temp2 + temp3);
}

//converting temperature to signal
double tempToObjSig(double dblKelvin)
{
    double EXP_SAFEGUARD = 709.78;
    double ASY_SAFEGUARD = 1.0002;

    double objSign = 0.0;
    double dbl_reg = dblKelvin;

    // objSign = R / (ex(B/T) - F) + O

    if (dbl_reg > 0.0)
    {
        dbl_reg = m_B / dbl_reg;

        if (dbl_reg < EXP_SAFEGUARD)
        {
            dbl_reg = exp(dbl_reg);

            if (m_F <= 1.0)
            {
                if (dbl_reg < ASY_SAFEGUARD)
                    dbl_reg = ASY_SAFEGUARD; // don't get above a R/(1-F)
                // (horizontal) asymptote
            }
            else
            {
                // F > 1.0
                if (dbl_reg < m_F * ASY_SAFEGUARD)
                    dbl_reg = m_F * ASY_SAFEGUARD;
                // Don't get too close to a B/ln(F) (vertical) asymptote
            }

            objSign = m_R / (dbl_reg - m_F) + m_O;
        }
    }

    return objSign;
}

//calculating updated constants
void DoUpdateCalcConst()
{
    m_AtmTao = DoCalcAtmTao();
    m_K1 = DoCalcK1();
    m_K2 = DoCalcK2(tempToObjSig(m_AmbTemp),
                    tempToObjSig(m_AtmTemp),
                    tempToObjSig(m_ExtOptTemp));
}

//handling exponential nature VPrasad UPdated
double powToObjSig(double dPow)
{
	//calculating new constants explicitly while porting to C++
	DoUpdateCalcConst();

    return (m_K1 * dPow - m_K2);
}

//final method to convert RAW to temperature
float TauToTemp(ushort sig)
{
    float T;
    double objSig;
    objSig = powToObjSig((double)sig);

    T = (float)(m_B / log(abs(m_R / (objSig - m_O) + m_F)));

    return T;
}


//display welcome message and splash screen
void welcome(int time)
{
	//display welcome image
	imshow("Welcome", imread("assets/IDCAST.jpg"));

	//put thread to sleep until user is ready
	this_thread::sleep_for (std::chrono::seconds(time));

	//close welcome image
	destroyWindow("Welcome");
}

//read RAW, convert and return final for further processing
Mat readConvertRAW2Mat(string filenameToRead)
{
	const string helloWorld = filenameToRead; //"hello world";
	//fopen(helloWorld.c_str(), "W");
	//const char* test = "hello world";
	//converting variable character into constant pointer
	//const char *constCharFilename;// = new char(filenameToRead);//&filenameToRead;
	//const char* constCharFilename = "/Users/Vidur/OneDrive/EX/Internships/ID\ CAST/Honda\ Thermal/C\ Workspace/Traffic\ Camera\ Distracted\ Driver\ Detection/assets/OSU_Thermal_Test/Test\ 10\ Rename/" +"34.raw";
	//const char* asdf = strcat(*constCharFilename, *test);
	//defining matricies to hold images	with correct sizes
	Mat Img_Source16Bit_Gray(imgHeight,imgWidth,CV_16UC1);
	Mat Img_Destination8Bit_Gray(imgHeight,imgWidth,CV_8UC1);
	cout << "reached here" << endl;;
	//defining file object
	FILE * fileToRead;
	const char* test = filenameToRead.c_str();
	//const char* constFilename = *(char) filenameToRead;


	//pointing to image address
	fileToRead = fopen(test,"rb");
	cout << "Reacehd here" << endl;

	//checking if image has content
	if (!fileToRead)
	{
	    throw "File Not Found";

	}
	char16_t* pY16Pixels;//w-2592 h- 1944
	pY16Pixels = new char16_t[imgWidth * imgHeight];

	fread(pY16Pixels,imgWidth*imgHeight*2,1,fileToRead);
	Img_Source16Bit_Gray.data= reinterpret_cast<uchar*>(pY16Pixels);

	double minVal, maxVal;
	minMaxLoc(Img_Source16Bit_Gray, &minVal, &maxVal); //find minimum and maximum intensities
	Img_Source16Bit_Gray.convertTo(Img_Destination8Bit_Gray, CV_8U, 255.0/(maxVal - minVal));

/*
	//declaring character array to hold pixels
	char16_t* pY16Pixels;

	//declaring array with enough space to hold all pixels
	pY16Pixels = new char16_t[imgWidth * imgHeight];

	//reading in all pixel values into array
	fread(pY16Pixels, imgWidth*imgHeight * 2, 1, fileToRead);

	//assembling into matrix
	Img_Source16Bit_Gray.data= reinterpret_cast<uchar*>(pY16Pixels);

	//declaring variables
	double minVal, maxVal;

	//identifying scalar factors
	minMaxLoc(Img_Source16Bit_Gray, &minVal, &maxVal);

	//applying scaling
	Img_Source16Bit_Gray.convertTo(Img_Destination8Bit_Gray, CV_8UC1, 255.0/(maxVal - minVal));
*/
	double scalarFactor =(maxVal - minVal) / 255.0;

	//for every row
	for (int i = 0; i < Img_Destination8Bit_Gray.rows; i++)
	{	
		//for every column
		for(int j = 0; j < Img_Destination8Bit_Gray.cols; j++)
		{	

			//cout << "initial tmp value" << stoi(to_string(img.at<uchar>(i,j)))<< endl;
						double temp = stoi(to_string(scalarFactor * Img_Destination8Bit_Gray.at<uchar>(i,j)));
						ushort tempUShort = (ushort) temp;

						//cout << to_string(tempUShort) << " tempUShort" << endl;
						//cout << "after conversion" << TauToTemp(tempUShort) << endl;
						Img_Destination8Bit_Gray.at<uchar>(i,j) = TauToTemp(tempUShort);
						//cout << TauToTemp(tempUShort) << " tautotemp value" << endl;
						//tmps.push_back(TauToTemp(tempUShort));
		}
	}
	/*
			cout << stod(to_string(Img_Destination8Bit_Gray.at<uchar>(i,j)))<< endl;
			//undo scaling, cast to unsigned short, send to Tau To Temp function, and save new pixel value
			double temp = stod(to_string( scalarFactor* Img_Destination8Bit_Gray.at<uchar>(i,j)));
			cout << " Raw Temp :" << temp << endl;
			unsigned char uCharTemp = (unsigned char) temp;
			temp = TauToTemp(uCharTemp);
			Img_Destination8Bit_Gray.at<uchar>(i,j) = temp;

			//Img_Destination8Bit_Gray.at<uchar>(i,j) = TauToTemp((uchar)(stod(to_string((1/(255.0/(maxVal - minVal))) * Img_Destination8Bit_Gray.at<uchar>(i,j)))));

		}//(unsigned char)
	}
	*/



	imshow("Img", Img_Destination8Bit_Gray);
	//waitKey(0);
	//exit (EXIT_FAILURE);
	//return matrix
	return Img_Destination8Bit_Gray;
}

//main method
int main() {
	//cycling through every frame
	for(int i = 1; i <= 60; i++)
	{
		string strFilenameToRead;

		//concating file location for each frame
		if(i < 10)
		{
			strFilenameToRead = filenamePrefix + to_string(0) + to_string(i) + ".raw";
		}

		else
		{
			strFilenameToRead = filenamePrefix + to_string(i) + ".raw";
		}
		//generating character for fopen command
		//char nonConstFilenameToRead = *strFilenameToRead.c_str();

		cout << strFilenameToRead << endl;

		//running method toget Matrix
		Mat convertedFrame = readConvertRAW2Mat(strFilenameToRead);
		cout << "Completed " << i << " iterations." << endl;
		//display image
		imshow("Converted Image", convertedFrame);

		string filenameToSave = to_string(i) + ".TIFF";

		//write to disk
		imwrite(filenameToSave, convertedFrame);
	}
	//report code finished
	cout << "Execution Finished" << endl;

	//return code is finished and ran successfully
	return 0;
}




/*
	FILE * f = fopen(filename, "rb");
	if(!f)
	{
		cout << "Error 404" << endl;
	}

	//char pixels [ imgWidth * imgHeight];
	//fread(pixels, imgWidth*imgHeight, 1, f);
	char pixels [ imgHeight * imgWidth];
	fread(pixels, imgHeight*imgWidth, 1, f);
	fclose(f);

	Mat img = Mat(imgWidth,imgHeight, CV_8U,pixels).clone();
	for (int i = 0; i < img.cols; i++)
	{
		for(int j = 0; j < img.rows; j++)
		{
			//cout << "initial tmp value" << stoi(to_string(img.at<uchar>(i,j)))<< endl;
			double temp = stoi(to_string(img.at<uchar>(i,j)));
			ushort tempUShort = (ushort) temp;

			cout << to_string(tempUShort) << " tempUShort" << endl;
			//cout << "after conversion" << TauToTemp(tempUShort) << endl;
			img.at<uchar>(i,j) = TauToTemp(tempUShort);
			cout << TauToTemp(tempUShort) << " tautotemp value" << endl;
			tmps.push_back(TauToTemp(tempUShort));

		}
	}
	cout << sum(tmps)[0] / tmps.size() << " mean" << endl;
	cout << "median is " << calcMedian(tmps) << endl;

	Mat imgProper;
	double min, max;
	Point minLoc, maxLoc;
	minMaxLoc( img, &min, &max, &minLoc, &maxLoc );

	img.convertTo(imgProper,CV_8U,255.0/(max-min),-255.0/min);

	return img;
	/*
	Mat Img_Source16Bit_Gray(imgWidth, imgHeight,CV_16UC1);
	Mat Img_Destination8Bit_Gray;

	FILE * f;
	f = fopen(filename, "rb");
	if (!f)
	{
		cout << "Error 404 --> File Not Found" << endl;
	}

	char16_t* pY16Pixels;
	pY16Pixels = new char16_t[imgWidth * imgHeight];

	fread(pY16Pixels, imgWidth*imgHeight*2,1,f);
	Img_Source16Bit_Gray.data  = reinterpret_cast<uchar*>(pY16Pixels);

	double minVal, maxVal;
	minMaxLoc(Img_Source16Bit_Gray, &minVal, &maxVal);
	Img_Source16Bit_Gray.convertTo(Img_Destination8Bit_Gray, CV_8U, 255.0/(maxVal - minVal), -minVal * 255.0/(maxVal-minVal));

	namedWindow("Img_Source16Bit_Gray", WINDOW_NORMAL);
	namedWindow("Img_Destination8Bit_Gray", WINDOW_NORMAL);
	imshow("Img_Source16Bit_Gray", Img_Source16Bit_Gray);
    imshow("Img_Source16Bit_Gray", Img_Destination8Bit_Gray);
	*/
	//return imread(filenamejpg);

	/*
	Mat Img_Source16Bit_Gray(imgHeight,imgWidth,CV_16UC1);
	Mat Img_Destination8Bit_Gray(imgHeight,imgWidth,CV_8UC1);

	FILE * f;
	f=fopen(filename,"rb");
	if ( !f )
	{
	    cout << "File Not Found" << endl;
	}

	char16_t* pY16Pixels;//w-2592 h- 1944
	pY16Pixels = new char16_t[imgWidth * imgHeight];

	fread(pY16Pixels,imgWidth*imgHeight*2,1,f);
	Img_Source16Bit_Gray.data= reinterpret_cast<uchar*>(pY16Pixels);

	/*
	double minVal, maxVal;
	minMaxLoc(Img_Source16Bit_Gray, &minVal, &maxVal); //find minimum and maximum intensities
	Img_Source16Bit_Gray.convertTo(Img_Destination8Bit_Gray, CV_8U, 255.0/(maxVal - minVal), -minVal * 255.0/(maxVal - minVal));
	 */
/*
	Mat assemblyForDisplay(imgHeight, imgWidth, CV_16UC1);

	Mat tmp;
	imshow("source init", Img_Source16Bit_Gray);
	Img_Source16Bit_Gray.copyTo(tmp);
	cout << "Begin" << endl;
	int counter = 0;
	for (int i = 0; i < tmp.rows; i++)
	{
		for(int j = 0; j < tmp.cols; j++)
		{
			//cout << "initial tmp value" << stoi(to_string(img.at<uchar>(i,j)))<< endl;
			int temp = stoi(to_string( Img_Source16Bit_Gray.at<uchar>(i,j)));
			ushort tempUShort = (ushort) temp;
			//cout << "Raw Temperature : " << to_string(temp) << endl;
			cout << "Raw Readout : " << to_string(Img_Source16Bit_Gray.at<uchar>(i,j)) << endl;
			//cout << "after conversion" << TauToTemp(tempUShort) << endl;
			//tmp.at<uchar>(i,j) = TauToTemp(tempUShort);
			tmps.push_back(TauToTemp(tempUShort));
			unsigned char vOut = (unsigned char) TauToTemp(tempUShort);
			cout << vOut << "unsigned char to print" << endl;
			tmp.at<uchar>(i,j) = (double) TauToTemp(tempUShort);//vOut;//(unsigned char) 1234123134123414213 ; //TauToTemp(tempUShort);
			cout << "Processed Temperature : " << TauToTemp(tempUShort) << endl;
			counter++;

		}
	}

	cout  << (int)(Img_Source16Bit_Gray.at<uchar>(209, 155)) << endl;

	Mat tmp2;
	tmp.copyTo(tmp2);
	cout << "Times Should Run : " << (tmp.cols * tmp.rows) << endl;
	cout << "Times Ran = " << counter  << endl;
	imshow("created image", tmp);
	imwrite("createdImage.TIFF", tmp2);


	tmp.convertTo(tmp,CV_8UC1);
	imshow("Converted Image",tmp);


	cout << "STATS about Footage" << endl;
	cout << type2str(Img_Source16Bit_Gray.type()) << " type of Matrix" << endl;
	cout  << sum(tmps)[0] / tmps.size() << " mean of pixels" << endl;
	cout << calcMedian(tmps) <<  " median of pixels" << endl;

	//imshow("Img_Source16Bit_Gray",Img_Source16Bit_Gray);
	imwrite("SourceImage.TIFF", Img_Source16Bit_Gray);
	//imshow("Img_Destination8Bit_Gray",Img_Destination8Bit_Gray);
	//imshow("Assembly For Display", assemblyForDisplay);
	return assemblyForDisplay;
	*/

	//file read
	/*
		ifstream fs;
		fs.open(filename);
		unsigned short *tmp = new unsigned short [imgHeight*imgWidth];
		fs.seekg(256);
		fs.read((char*)tmp, imgHeight*imgWidth*2 );
		fs.close();
		cvReadImage
		 unsigned char*c = (unsigned char*)tmp;
		    for (int i = 0; i < imgHeight*imgWidth*2; i += 2)
		    swap(c[i], c[i + 1]);
		    Mat imAcq = Mat(imgHeight, imgWidth, CV_16UC1,tmp);// , tmp, 256 * 256 * sizeof(unsigned short));

		    for (int i = 0; i < imAcq.rows; i++)
		    	{
		    		for(int j = 0; j < imAcq.cols; j++)
		    		{
		    			int temp = stoi(to_string( imAcq.at<uchar>(i,j)));
		    			ushort tempUShort = (ushort) temp;
		    			cout << "Raw Readout : " << to_string(imAcq.at<uchar>(i,j)) << endl;
		    			tmps.push_back(TauToTemp(tempUShort));
		    			imAcq.at<uchar>(i,j) = (unsigned char) TauToTemp(tempUShort);//vOut;//(unsigned char) 1234123134123414213 ; //TauToTemp(tempUShort);
		    			cout << "Processed Temperature : " << TauToTemp(tempUShort) << endl;
		    		}
		    	}

		    //convert to 8bit for imshow
		       Mat img8bit;
		       imAcq.convertTo(img8bit,CV_16UC1);
		       namedWindow( "8bit normalised", WINDOW_AUTOSIZE );
		       imshow( "8bit normalised", imAcq );                   // Show image
		       imwrite("finalImage.TIFF", imAcq);
*/
	/*
	Mat img;
	FILE *fp = NULL;
	unsigned char *imagedata = NULL;
	int framesize = imgWidth * imgHeight;

	//Open raw Bayer image.
	fp = fopen(filename, "rb");

	//Memory allocation for bayer image data buffer.
	imagedata = (unsigned char*) malloc (sizeof(unsigned char) * framesize);

	//Read image data and store in buffer.
	fread(imagedata, sizeof(char), framesize, fp);


	//Image dimension.
	imageSize.height = imgWidth;
	imageSize.width = imgHeight;


	//Create Opencv mat structure for image dimension. For 8 bit bayer, type should be CV_8UC1.
	img.create(imgHeight, imgWidth, CV_16UC1);

	memcpy(img.data, imagedata, framesize);

	free(imagedata);

	fclose(fp);
	Mat image;
	//Perform demosaicing process
	cvtColor(img, image, CV_BayerBG2BGR);
	cvtColor(image, image, CV_BGR2GRAY);
	//cvtColor(image, image, CV_8UC1);

	cout << to_string(image.at<int>(162, 88)) << " first try" << endl;

	imshow("image", image);

	return image;
	*/   


	//downscaling image
	//resize(backgroundFrameMean, backgroundFrameMean, 0, .5, .5, INTER_LINEAR);
   
	/*
    backgroundFrameMedian = globalMedianGrayFrames.at(i);

	//change some pixel value
	for(int j=0;j<backgroundFrameMedian.rows;j++)
	{
		for (int a=0;a<backgroundFrameMedian.cols;a++)
		{
		    vector <int> pixelHistory;

		    for (int t = 0; t < i ; t++)
		    {
				pixelHistory.push_back((globalMedianGrayFrames.at(i - t)).at<uchar>(j,a));
		  	}
		  
		  	backgroundFrameMedian.at<uchar>(j,a) = calcMedian(pixelHistory);
	    }
	}

	putText(backgroundFrameMedian, to_string(i), cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1, cvScalar(0,255,0), 1, CV_AA, false);
    


	/*
	//change some pixel value
	for(int j=0;j<meanImage.rows;j++)
	{
	  for (int a=0;a<meanImage.cols;a++)
	  {
		  vector <int> pixelHistory;
		  for (int t = 0; t < i ; t++)
		  {
			pixelHistory.push_back((globalGrayFrames.at(t)).at<uchar>(j,a));
		  }

		  meanImage.at<uchar>(j,a) = calcMean(pixelHistory);
		  //meanImage.at<uchar>(j,a) = rand() % 250;
		  //cout << a << "A" << endl;

	  }
	  //cout << j << endl;
	}
	*/




    //blur( meanImage, meanImage, Size( 25, 25) );



		  //meanImage.at<uchar>(j,a) = calcMean(pixelHistory);
		  //meanImage.at<uchar>(j,a) = (int) (total/totalCounter);

		  //meanImage.at<uchar>(j,a) = rand() % 250;
		  //cout << a << "A" << endl;

Mat meanImage()
{
	//backgroundFrameMean = globalGrayFrames.at(i);
	globalGrayFrames.at(i).copyTo(backgroundFrameMean);
	//resize(backgroundFrameMean, backgroundFrameMean, 0, .5, .5, INTER_LINEAR);

	int total = 0;
    //blur( meanImage, meanImage, Size( 25, 25) );

	//change some pixel value
	for(int j=0;j<backgroundFrameMean.rows;j++)
	{
	  for (int a=0;a<backgroundFrameMean.cols;a++)
	  {
   		  int totalCounter = 1;
		  vector <int> pixelHistory;
		  for (int t = 0; t < i ; t++)
		  {
			  Mat currFrame;
			  globalGrayFrames.at(i-t).copyTo(currFrame);
			  total += currFrame.at<uchar>(j,a); //cvGetReal2D(&globalFrames.at(i-t), j, a);
			  pixelHistory.push_back(currFrame.at<uchar>(j,a));
			  totalCounter++;
		  }
		  backgroundFrameMean.at<uchar>(j,a) = calcMedian(pixelHistory);

		  //meanImage.at<uchar>(j,a) = calcMean(pixelHistory);
		  //meanImage.at<uchar>(j,a) = (int) (total/totalCounter);

		  //meanImage.at<uchar>(j,a) = rand() % 250;
		  //cout << a << "A" << endl;

	  }

	  cout << (backgroundFrameMean.rows - j) << endl;

	}

	/*
	//change some pixel value
	for(int j=0;j<meanImage.rows;j++)
	{
	  for (int a=0;a<meanImage.cols;a++)
	  {
		  vector <int> pixelHistory;
		  for (int t = 0; t < i ; t++)
		  {
			pixelHistory.push_back((globalGrayFrames.at(t)).at<uchar>(j,a));
		  }

		  meanImage.at<uchar>(j,a) = calcMean(pixelHistory);
		  //meanImage.at<uchar>(j,a) = rand() % 250;
		  //cout << a << "A" << endl;

	  }
	  //cout << j << endl;
	}
	*/
	putText(backgroundFrameMean, to_string(i), cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1, cvScalar(0,255,0), 1, CV_AA, false);
	//medianImage.at<uchar>(j,a) = rand() % 250;

	return backgroundFrameMean;
}


//create static
medianImage.at<uchar>(j,a) = rand() % 250;



Mat calculateBackgroundFrame(Mat backgroundFrame)
{
	Mat output;
	addWeighted( globalFrames.at(i), .5, globalFrames.at(i-1), .5, 0.0, output);

	BackgroundSubtractorMOG asdf = BackgroundSubtractorMOG(5, 1, 2, 0);
	//asdf.operator(globalFrames.at(i), output);
	Mat input;	globalFrames.at(i).convertTo(input, CV_8U);
	//accumulate(globalFrames.at(i), globalFrames.at(i-1), noArray());
	accumulateWeighted(input, backgroundFrame, 0.01);
	return backgroundFrame / (i+1);
}

//creating text to display
		strDisplay = "SURF: " + numberOfKeyPointsSURF + " Shi-Tomasi: " + strNumberOfShiTomasiCorners + " Harris: "
		+ strNumberOfHarrisCorners + + " Canny: " + strCanny + " FDOFA: " + strNumberOpticalFlowAnalysis +  " Frame Number: " +
		to_string(framesRead) +  " Rating: " + strRating +  " FPS: " + strActiveTimeDifference;

		//creating black empty image
		Mat pic = Mat::zeros(45,1910,CV_8UC3);

		//adding text to image
		putText(pic, strDisplay, cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1, cvScalar(0,255,0), 1, CV_AA, false);

		//displaying image
		imshow("Stats", pic);



	//close all windows
	destroyWindows();

normalizeRatings(vectNumberOfKeyPoints, numberOfShiTomasiKeyPoints, numberOfHarrisCorners, numberOfContours, opticalFlowAnalysisFarnebackNumbers);

	//save info in txt file
	saveToTxtFile(FRAME_RATE, vectNumberOfKeyPoints, numberOfShiTomasiKeyPoints, numberOfContours, numberOfHarrisCorners, opticalFlowAnalysisFarnebackNumbers, FPS, filename);


//normlize all ratings and metrics
				normalizeRatings(vectNumberOfKeyPoints, numberOfShiTomasiKeyPoints, numberOfHarrisCorners, numberOfContours, opticalFlowAnalysisFarnebackNumbers);

				//save data to txt file
				saveToTxtFile(FRAME_RATE, vectNumberOfKeyPoints, numberOfShiTomasiKeyPoints, numberOfContours, numberOfHarrisCorners, opticalFlowAnalysisFarnebackNumbers,FPS, filename);


//instantiating multithread objects
		pthread_t surfThread;
		pthread_t cannyThread;
		pthread_t shiTomasiThread;
		pthread_t harrisThread;
		pthread_t opticalFlowThread;

		//instantiating multithread Data object
		struct thread_data threadData;

		//saving data into data object
		threadData.i = i;

	    //creating threads
	    int surfThreadRC = pthread_create(&surfThread, NULL, computeSURFThread, (void *)&threadData);
	    int cannyThreadRC = pthread_create(&cannyThread, NULL, computeCannyThread, (void *)&threadData);
		int shiTomasiRC = pthread_create(&shiTomasiThread, NULL, computeShiTomasiThread, (void *)&threadData);
		int harrisRC = pthread_create(&harrisThread, NULL, computeHarrisThread, (void *)&threadData);

	    //check if all threads created
	    if (surfThreadRC || cannyThreadRC || shiTomasiRC || harrisRC)
	    {
	    	//throw error
	    	throw "Error:unable to create thread";

	    	//exit if issue
	    	exit(-1);
	    }

		//if ready for FDOFA
		if(i > 10)
		{
			int opticalFlowRC = pthread_create(&opticalFlowThread, NULL, computeOpticalFlowAnalysisThread, (void *)&threadData);

			if (opticalFlowRC)
			{
				cout << "Error:unable to create thread," << opticalFlowRC << endl;
				exit(-1);
			}
		}

		//check if OFA is being performed
		if(i<= 10)
		{
			//idle until all threads finished
			while(surfThreadCompletion == 0 || cannyThreadCompletion == 0 || shiTomasiThreadCompletion == 0 || harrisCornersThreadCompletion == 0)
			{
			}
		}
		else
		{
			//idle until all threads finished
			while(surfThreadCompletion == 0 || cannyThreadCompletion == 0 ||
								shiTomasiThreadCompletion == 0 || harrisCornersThreadCompletion == 0 || opticalFlowThreadCompletion == 0)
			{
			}
		}

		//writing that all threads are ready for next run
		shiTomasiThreadCompletion = 0;
		surfThreadCompletion = 0;
		cannyThreadCompletion = 0;
		harrisCornersThreadCompletion = 0;
		opticalFlowThreadCompletion = 0;

		//write Canny
		numberOfContours.push_back(numberOfContoursThread);
		String strCanny = to_string(realTimeNormalization(numberOfContours, i));

		//write ShiTomasi
		numberOfShiTomasiKeyPoints.push_back(shiTomasiFeatures);
		String strNumberOfShiTomasiCorners = to_string(realTimeNormalization(numberOfShiTomasiKeyPoints, i));

		//write SURF
		vectNumberOfKeyPoints.push_back(numberOfSURFFeatures);
		String numberOfKeyPointsSURF = to_string(realTimeNormalization(vectNumberOfKeyPoints, i));

		//write Harris
		numberOfHarrisCorners.push_back(numberOfHarrisCornersCounter);
		String strNumberOfHarrisCorners = to_string(realTimeNormalization(numberOfHarrisCorners, i));

		//if ready for OFA
		if(i > 10)
		{
			opticalFlowAnalysisFarnebackNumbers.push_back(sumOpticalFlow);
			strNumberOpticalFlowAnalysis = to_string(realTimeNormalization(opticalFlowAnalysisFarnebackNumbers, i-11));
			//compute FDOFA
			finalScores.push_back(computeFinalScore(vectNumberOfKeyPoints, numberOfHarrisCorners, numberOfShiTomasiKeyPoints, numberOfContours,
					opticalFlowAnalysisFarnebackNumbers, i));
			strRating = to_string(realTimeNormalization(finalScores, i-11));
		}
		//if not enough data has been generated for optical flow
		else if(i > 0 && i <= 3)
		{

			//creating text to display
			strDisplay = "SURF Features: " + numberOfKeyPointsSURF + " Shi-Tomasi: " + strNumberOfShiTomasiCorners + " Harris: "
			+ strNumberOfHarrisCorners + " Canny: " + strCanny + " Frame Number: " + to_string(framesRead);

			//creating black empty image
			Mat pic = Mat::zeros(45,1910,CV_8UC3);

			//adding text to image
			putText(pic, strDisplay, cvPoint(30,30),CV_FONT_HERSHEY_SIMPLEX, 1.25, cvScalar(0,255,0), 1, CV_AA, false);

			//displaying image
			imshow("Stats", pic);

		}



		//convert frame to grayscale
		cvtColor(globalFrames.at(i), globalGrayFrame, CV_BGR2GRAY);
		
	//declaring strings for all metrics
    string strRating, strNumberOfHarrisCorners, strNumberOfShiTomasiCorners, numberOfKeyPointsSURF, strCanny, strActiveTimeDifference;

    //initializing string to display blank
	string strDisplay =  "";
	string strNumberOpticalFlowAnalysis = "";

	//creating vectors to store all metrics
	vector <int> numberOfContours;
	vector <int> numberOfShiTomasiKeyPoints;
	vector <int> numberOfHarrisCorners;
	vector <double> opticalFlowAnalysisFarnebackNumbers;
	vector <int> vectNumberOfKeyPoints;
	vector <int> finalScores;
	vector <String> FPS;


//SURF Global Variables
static Mat surfFrame;
int surfThreadCompletion = 0;
int numberOfSURFFeatures = 0;

//canny Global Variables
int numberOfContoursThread = 0;
int cannyThreadCompletion = 0;
Mat cannyFrame;

//Shi Tomasi Global Variables
int shiTomasiFeatures = 0;
int shiTomasiThreadCompletion = 0;

//harris global variables
int numberOfHarrisCornersCounter = 0;
int harrisCornersThreadCompletion = 0;

//optical flow global variables
int sumOpticalFlow = 0;
int opticalFlowThreadCompletion = 0;
Mat optFlow;

//defining format of data sent to threads
struct thread_data{
   //include iteration number
   int i;
};

//declaring templates for use in max element function
template <typename T, size_t N> const T* mybegin(const T (&a)[N]) { return a; }
template <typename T, size_t N> const T* myend  (const T (&a)[N]) { return a+N; }

//method to draw optical flow, only should be called during demos
static void drawOptFlowMap(const Mat& flow, Mat& cflowmap, int step,
                    double, const Scalar& color)
{
	//iterating through each pixel and drawing vector
    for(int y = 0; y < cflowmap.rows; y += step)
        for(int x = 0; x < cflowmap.cols; x += step)
        {
            const Point2f& fxy = flow.at<Point2f>(y, x);
            line(cflowmap, Point(x,y), Point(cvRound(x+fxy.x), cvRound(y+fxy.y)),
                 color);
            circle(cflowmap, Point(x,y), 2, color, -1);
        }
}

//method that returns date and time as a string to tag txt files
const string currentDateTime()
{
	//creating time object that reads current time
    time_t now = time(0);
    //creating time structure
    struct tm tstruct;
    //creating a character buffer of 80 characters
    char buf[80];
    //checking current local time
    tstruct = *localtime(&now);
    //writing time to string
    strftime(buf, sizeof(buf), "%Y-%m-%d.%X", &tstruct);
    //returning the string with the time
    return buf;
}

//method to perform optical flow analysis
void *computeOpticalFlowAnalysisThread(void *threadarg)
{
	//reading in data sent to thread into local variable
	struct thread_data *data;
	data = (struct thread_data *) threadarg;
	int i = data->i;

	//defining local variables for FDOFA
	Mat prevFrame, currFrame;
	Mat gray, prevGray, flow,cflow;

	//reading in current and previous frames
	prevFrame = globalFrames.at(i-1);
	currFrame = globalFrames.at(i);

	//converting to grayscale
	cvtColor(currFrame, gray,COLOR_BGR2GRAY);
	cvtColor(prevFrame, prevGray, COLOR_BGR2GRAY);

	//calculating optical flow
	calcOpticalFlowFarneback(prevGray, gray, flow, 0.5, 3, 15, 3, 5, 1.2, 0);
	//converting to display format
	cvtColor(prevGray, cflow, COLOR_GRAY2BGR);
	//drawing optical flow vectors
	drawOptFlowMap(flow, cflow, 15, 1.5, Scalar(0, 255, 0));
	//saving to global variable for display
	optFlow = cflow;
	//returning sum of all movement in frame
	sumOpticalFlow = (abs(sum(flow)[0]));
	//signal thread completion
	opticalFlowThreadCompletion = 1;

}

//calculate number of Harris corners
void *computeHarrisThread(void *threadarg)
{
	//reading in data sent to thread into local variable
	struct thread_data *data;
	data = (struct thread_data *) threadarg;
	int i = data->i;

	//defining local variables for Harris
	numberOfHarrisCornersCounter = 0;
	int blockSize = 3;
	const int apertureSize = 3;
	double harrisMinValue;
	double harrisMaxValue;
	double harrisQualityLevel = 35;
	double maxQualityLevel = 100;

    //create frame formatted for use in Harris
    Mat harrisDST = Mat::zeros(globalGrayFrame.size(), CV_32FC(6) );
    Mat mc = Mat::zeros(globalGrayFrame.size(), CV_32FC1 );
    Mat harrisCornerFrame = globalGrayFrame;

    //run Corner Eigen Vals and Vecs to find corners
    cornerEigenValsAndVecs( globalGrayFrame, harrisDST, blockSize, apertureSize, BORDER_DEFAULT );

    //use Eigen values to step through each pixel individaully and finish applying equation
    for( int j = 0; j < globalGrayFrame.rows; j++ )
    {
    	for( int h = 0; h < globalGrayFrame.cols; h++ )
    	{
    		//apply algorithm
			float lambda_1 = harrisDST.at<Vec6f>(j, h)[0];
			float lambda_2 = harrisDST.at<Vec6f>(j, h)[1];
			mc.at<float>(j,h) = lambda_1*lambda_2 - 0.04f*pow( ( lambda_1 + lambda_2 ), 2 );
    	}
    }

    //find locations of minimums and maximums
    minMaxLoc( mc, &harrisMinValue, &harrisMaxValue, 0, 0, Mat() );

    //apply harris properly to every pixel
    for( int j = 0; j < globalGrayFrame.rows; j++ )
    {
    	for( int h = 0; h < globalGrayFrame.cols; h++ )
	    {
			if( mc.at<float>(j,h) > harrisMinValue + ( harrisMaxValue - harrisMinValue )* harrisQualityLevel/maxQualityLevel)
			{
				//apply algorithm, and increment counters
				numberOfHarrisCornersCounter++;
			}
		}
	}

	//signal completion
	harrisCornersThreadCompletion = 1;

}

//calculate number of Shi-Tomasi corners
void *computeShiTomasiThread(void *threadarg)
{
	//reading in data sent to thread into local variable
	struct thread_data *data;
    data = (struct thread_data *) threadarg;
    int i = data->i;

	//defining local variables for Shi-Tomasi
	vector<Point2f> cornersf;
	const double qualityLevel = 0.1;
	const double minDistance = 10;
	const int blockSize = 3;
	const double k = 0.04;

	//harris detector is used seperately
	const bool useHarrisDetector = false;

	//setting max number of corners to largest possible value
	const int maxCorners = numeric_limits<int>::max();

	//perform Shi-Tomasi algorithm
    goodFeaturesToTrack(globalGrayFrame, cornersf, maxCorners, qualityLevel, minDistance,
    Mat(), blockSize, useHarrisDetector,k);

    //return number of Shi Tomasi corners
    shiTomasiFeatures = cornersf.size();

    //signal completion
    shiTomasiThreadCompletion = 1;
}

//calculate number of SURF features
void *computeSURFThread(void *threadarg)
{
	//reading in data sent to thread into local variable
   struct thread_data *data;
   data = (struct thread_data *) threadarg;
   int i = data->i;

   //setting constant integer minimum Hessian for SURF Recommended between 400-800
   const int minHessian = 500;
   //defining vector to contain all features
   vector <KeyPoint> vectKeyPoints;
   //saving global frame into surfFrame
   globalFrames.at(i).copyTo(surfFrame);

   //running SURF detector
   SurfFeatureDetector detector(minHessian);
   detector.detect(surfFrame, vectKeyPoints );

   //drawing keypoints
   drawKeypoints(surfFrame, vectKeyPoints, surfFrame, Scalar::all(-1), DrawMatchesFlags::DEFAULT );
   numberOfSURFFeatures = vectKeyPoints.size();

   //signal completion
   surfThreadCompletion = 1;
}

//calculate number of contours
void *computeCannyThread(void *threadarg)
{
	vector<Vec4i> hierarchy;
	typedef vector<vector<Point> > TContours;
	TContours contours;
	struct thread_data *data;
	data = (struct thread_data *) threadarg;
	int i = data->i;
	//run canny edge detector
	Canny(globalFrames.at(i), cannyFrame, 115, 115);
	findContours(cannyFrame, contours, hierarchy, CV_RETR_CCOMP, CV_CHAIN_APPROX_NONE);
	//return number of contours detected
	//imshow("globalFrames", contours);

    numberOfContoursThread = contours.size();

    cannyThreadCompletion = 1;
}

//calculate mean of vector of ints
double calculateMeanVector(Vector <int> scores)
{
  double total;
  //sum all elements of vector
  for(int i = 0; i < scores.size(); i++)
  { total += abs(scores[i]); }
  //divide by number of elements
  return total / scores.size();
}

//calculate mean of vector of ints
double calculateMeanVector(vector <int> scores)
{
  double total;
  //sum all elements of vector
  for(int i = 0; i < scores.size(); i++)
  { total += abs(scores.at(i)); }
  //divide by number of elements
  return total / scores.size();
}

//calculate mean of vector of oubles
double calculateMeanVector(Vector <double> scores)
{
  double total;
  //sum all elements of vector
  for(int i = 0; i < scores.size(); i++)
  { total += abs(scores[i]); }
  //divide by number of elements
  return total / scores.size();
}

//method to save all metrics to file after processing
void saveToTxtFile(int FRAME_RATE, Vector <int> vectNumberOfKeyPoints, Vector <int> numberOfShiTomasiKeyPoints, Vector <int>
numberOfContours, Vector <int> numberOfHarrisCorners, Vector <double> opticalFlowAnalysisFarnebackNumbers, vector <string> FPS, const char* filename)
{
	//instantiating file stream
	ofstream file;

	//creating filename ending
	string vectFilenameAppend = " rawData.txt";

	//concanating and creating file name string
	string strVectFilename = filename + currentDateTime() + vectFilenameAppend;

	//creating file
	file.open (strVectFilename);

	//save txt file
	for(int v = 0; v < vectNumberOfKeyPoints.size() - 5; v++)
	{
		file << "Frame Number " << v << " at " << (v * (1.0 / FRAME_RATE)) << " seconds has ";
		file << vectNumberOfKeyPoints[v];
		file << " SURF key points & ";
		file << numberOfShiTomasiKeyPoints[v];
		file << " Shi-Tomasi key points";
		file << " & " << numberOfContours[v] << " contours & ";
		file << numberOfHarrisCorners[v];
		file << " Harris Corners & FDOFA is ";
		file << opticalFlowAnalysisFarnebackNumbers[v];
		file << ". FPS is ";
		file << FPS.at(v);
		file << ".\n";
	}

	//close file stream
	file.close();
}

//save final ratings to text file
void saveToTxtFile(vector <int> finalRatings, string vectFilenameAppend)
{
	//instantiate new filestream
	ofstream file;

	//concanating and creating file name string
	string strVectFilename = filename + currentDateTime() + vectFilenameAppend;

	//create file
	file.open (strVectFilename);

	//save txt file
	for(int v = 0; v < finalRatings.size() ; v++)
	{
		file << v << " " << finalRatings.at(v) << endl;
	}

	//close file stream
	file.close();
}

//method to calculate tootal run time
void computeRunTime(clock_t t1, clock_t t2, int framesRead)
{
	//subtract from start time
	float diff ((float)t2-(float)t1);

	//calculate frames per second
	double frameRateProcessing = (framesRead / diff) * CLOCKS_PER_SEC;

	//display amount of time for run time
	cout << (diff / CLOCKS_PER_SEC) << " seconds of run time." << endl;

	//display number of frames processed per second
	cout << frameRateProcessing << " frames processed per second." << endl;
	cout << framesRead << " frames read." << endl;
}





//normalize vector values in real time
int realTimeNormalization(Vector <int> vectorToNormalize, int i)
{
	//determine max and min values
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//perform normalization and return values
	return (((vectorToNormalize[i] - minElement) / (maxElement - minElement))*100);

}

//normalize vector values in real time
int realTimeNormalization(vector <int> vectorToNormalize, int i)
{
	//determine max and min values
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//perform normalization and return values
	return (((vectorToNormalize.at(i) - minElement) / (maxElement - minElement))*100);

}

//normalize vector values in real time
double realTimeNormalization(Vector <double> vectorToNormalize, int i)
{
	//determine max and min values
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//perform normalization and return values
	return (((vectorToNormalize[i] - minElement) / (maxElement - minElement))*100);

}

//normalize vector values in real time
double realTimeNormalization(vector <double> vectorToNormalize, int i)
{
	//determine max and min values
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//perform normalization and return values
	return (((vectorToNormalize[i] - minElement) / (maxElement - minElement))*100);

}

//method to compute raw final score and recieve vectors of metrics
int computeFinalScore(Vector <int> vectNumberOfKeyPoints,Vector <int> numberOfHarrisCorners,
	Vector <int> numberOfShiTomasiKeyPoints, Vector <int> numberOfContours, Vector <double> opticalFlowAnalysisFarnebackNumbers, int i)
{
	//normalize and weigh appropriately
	double numberOfKeyPointsNormalized = abs(3 * realTimeNormalization(vectNumberOfKeyPoints,i));
	double numberOfShiTomasiKeyPointsNormalized = abs(3 * realTimeNormalization(numberOfShiTomasiKeyPoints,i));
	double numberOfHarrisCornersNormalized = abs(3 * realTimeNormalization(numberOfHarrisCorners,i));
	double numberOfContoursNormalized = abs(1 * realTimeNormalization(numberOfContours,i));
	double opticalFlowAnalysisFarnebackNumbersNormalized = abs((1 * realTimeNormalization(opticalFlowAnalysisFarnebackNumbers,i)));

	//if FDOFA normalization fails
	if(opticalFlowAnalysisFarnebackNumbersNormalized > 1000)
	{
		//set FDOFA to tmp value
		opticalFlowAnalysisFarnebackNumbersNormalized = 100;
	}

	//determine final score by summing all values
	long int finalScore = abs(((numberOfKeyPointsNormalized + numberOfShiTomasiKeyPointsNormalized +
			numberOfHarrisCornersNormalized + numberOfContoursNormalized + opticalFlowAnalysisFarnebackNumbersNormalized))
				);

	//return final score
	return finalScore;
}

//normalize vector in postprocessing
vector <int> normalizeVector(vector <int> vectorToNormalize)
{
	//declaring vector to store normalized score
	vector <int> normalizedValues;

	//int maxElement = max_element(begin(finalScores), end(finalScores));
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//normalize every value
	for(int i = 0; i < vectorToNormalize.size(); i++)
	{
		normalizedValues.push_back(((vectorToNormalize.at(i) - minElement) / (maxElement - minElement))*100);
	}

	//return normalized vector
	return normalizedValues;
}

vector <int> normalizeVector(Vector <int> vectorToNormalize)
{
	//declaring vector to store normalized score
	vector <int> normalizedValues;

	//int maxElement = max_element(begin(finalScores), end(finalScores));
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//normalize every value
	for(int i = 0; i < vectorToNormalize.size(); i++)
	{
		normalizedValues.push_back(((vectorToNormalize[i] - minElement) / (maxElement - minElement))*100);
	}

	//return normalized vector
	return normalizedValues;
}

//normalize vector in postprocessing
vector <double> normalizeVector(Vector <double> vectorToNormalize)
{
	//declaring vector to store normalized score
	vector <double> normalizedValues;

	//int maxElement = max_element(begin(finalScores), end(finalScores));
	double maxElement = *max_element(vectorToNormalize.begin(), vectorToNormalize.end());
	double minElement = *min_element(vectorToNormalize.begin(), vectorToNormalize.end());

	//normalize every value
	for(int i = 0; i < vectorToNormalize.size(); i++)
	{
		normalizedValues.push_back(((vectorToNormalize[i] - minElement) / (maxElement - minElement))*100);
	}

	//return normalized vector
	return normalizedValues;
}

//normalize all ratings in post processing
void normalizeRatings(Vector <int> vectNumberOfKeyPoints, Vector <int> numberOfShiTomasiKeyPoints, Vector <int> numberOfHarrisCorners,
	Vector <int> numberOfContours, Vector <double> opticalFlowAnalysisFarnebackNumbers)
{
	//declaring vector to store normalized score
	vector <int> finalScoreNormalized;

	//normalize all metric vector
	vector <int> vectNumberOfKeyPointsNormalized = normalizeVector(vectNumberOfKeyPoints);
	vector <int> numberOfShiTomasiKeyPointsNormalized = normalizeVector(numberOfShiTomasiKeyPoints);
	vector <int> numberOfHarrisCornersNormalized = normalizeVector(numberOfHarrisCorners);
	vector <int> numberOfContoursNormalized = normalizeVector(numberOfContours);
	vector <double> opticalFlowAnalysisFarnebackNumbersNormalized = normalizeVector(opticalFlowAnalysisFarnebackNumbers);

	//calculate score for each frame
	for(int i = 11; i < vectNumberOfKeyPoints.size(); i++)
	{
		double score = vectNumberOfKeyPointsNormalized.at(i) * 3 + 	numberOfShiTomasiKeyPointsNormalized.at(i) * 3 +
		numberOfHarrisCornersNormalized.at(i) * 3 + numberOfContoursNormalized.at(i) + opticalFlowAnalysisFarnebackNumbersNormalized.at(i-11);
		score /= 11;
		finalScoreNormalized.push_back(score);
	}

	//normalize final ratings
	finalScoreNormalized = normalizeVector(finalScoreNormalized);

	//save normalized final score
	saveToTxtFile(finalScoreNormalized, " finalRatingsNormalized.txt");

}

//display all windows
void displayWindows(int i)
{
	//if all frames have data
	if(i > 12)
	{
		imshow("Raw Frame", globalGrayFrame);
		imshow("SURF Detection", surfFrame);
		imshow("Canny Contours", cannyFrame);
		//check optical flow section
		imshow("Farneback Dense Optical Flow Analysis", optFlow);
	}
}

//method to close all windows
void destroyWindows()
{
	//close windows
	destroyWindow("Raw Frame");
	destroyWindow("SURF Detection");
	destroyWindow("Canny Contours");
	destroyWindow("Farneback Dense Optical Flow Analysis");
}
